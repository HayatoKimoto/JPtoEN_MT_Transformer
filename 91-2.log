cuda
Epoch [1/500] Batch[200/12648] complete. train_loss = 64.18286197662354
Epoch [1/500] Batch[200/12648] complete. train_loss = 64.10319629669189
Epoch [1/500] Batch[400/12648] complete. train_loss = 57.803730459213256
Epoch [1/500] Batch[400/12648] complete. train_loss = 57.8347532749176
Epoch [1/500] Batch[600/12648] complete. train_loss = 54.41596952438354
Epoch [1/500] Batch[600/12648] complete. train_loss = 54.50028865178426
Epoch [1/500] Batch[800/12648] complete. train_loss = 52.25732452392578
Epoch [1/500] Batch[800/12648] complete. train_loss = 52.3693677854538
Epoch [1/500] Batch[1000/12648] complete. train_loss = 50.727520351409915
Epoch [1/500] Batch[1000/12648] complete. train_loss = 50.84605403137207
Epoch [1/500] Batch[1200/12648] complete. train_loss = 49.58614069302877
Epoch [1/500] Batch[1200/12648] complete. train_loss = 49.68932260195414
Epoch [1/500] Batch[1400/12648] complete. train_loss = 48.67371343067714
Epoch [1/500] Batch[1400/12648] complete. train_loss = 48.763983407701765
Epoch [1/500] Batch[1600/12648] complete. train_loss = 47.92897495031357
Epoch [1/500] Batch[1600/12648] complete. train_loss = 48.00378968238831
Epoch [1/500] Batch[1800/12648] complete. train_loss = 47.29442052841186
Epoch [1/500] Batch[1800/12648] complete. train_loss = 47.35455582936605
Epoch [1/500] Batch[2000/12648] complete. train_loss = 46.74351089477539
Epoch [1/500] Batch[2000/12648] complete. train_loss = 46.781440698623655
Epoch [1/500] Batch[2200/12648] complete. train_loss = 46.260202674865724
Epoch [1/500] Batch[2200/12648] complete. train_loss = 46.28685015591708
Epoch [1/500] Batch[2400/12648] complete. train_loss = 45.82318860054016
Epoch [1/500] Batch[2400/12648] complete. train_loss = 45.83791296482086
Epoch [1/500] Batch[2600/12648] complete. train_loss = 45.42343901854295
Epoch [1/500] Batch[2600/12648] complete. train_loss = 45.44733160459078
Epoch [1/500] Batch[2800/12648] complete. train_loss = 45.05556205613273
Epoch [1/500] Batch[2800/12648] complete. train_loss = 45.09490141051156
Epoch [1/500] Batch[3000/12648] complete. train_loss = 44.73485968017578
Epoch [1/500] Batch[3000/12648] complete. train_loss = 44.76270949427287
Epoch [1/500] Batch[3200/12648] complete. train_loss = 44.42370386838913
Epoch [1/500] Batch[3200/12648] complete. train_loss = 44.46169530391693
Epoch [1/500] Batch[3400/12648] complete. train_loss = 44.13296839657952
Epoch [1/500] Batch[3400/12648] complete. train_loss = 44.18168635761037
Epoch [1/500] Batch[3600/12648] complete. train_loss = 43.864666355980766
Epoch [1/500] Batch[3600/12648] complete. train_loss = 43.91569548500909
Epoch [1/500] Batch[3800/12648] complete. train_loss = 43.615277461001746
Epoch [1/500] Batch[3800/12648] complete. train_loss = 43.65697623804996
Epoch [1/500] Batch[4000/12648] complete. train_loss = 43.378363898277286
Epoch [1/500] Batch[4000/12648] complete. train_loss = 43.42130800437927
Epoch [1/500] Batch[4200/12648] complete. train_loss = 43.15427498953683
Epoch [1/500] Batch[4200/12648] complete. train_loss = 43.191704151516866
Epoch [1/500] Batch[4400/12648] complete. train_loss = 42.93403338952498
Epoch [1/500] Batch[4400/12648] complete. train_loss = 42.978588827306574
Epoch [1/500] Batch[4600/12648] complete. train_loss = 42.73171405958093
Epoch [1/500] Batch[4600/12648] complete. train_loss = 42.78026245283044
Epoch [1/500] Batch[4800/12648] complete. train_loss = 42.53482944965363
Epoch [1/500] Batch[4800/12648] complete. train_loss = 42.584960916837055
Epoch [1/500] Batch[5000/12648] complete. train_loss = 42.35868800048828
Epoch [1/500] Batch[5000/12648] complete. train_loss = 42.39792657699585
Epoch [1/500] Batch[5200/12648] complete. train_loss = 42.18279794619634
Epoch [1/500] Batch[5200/12648] complete. train_loss = 42.21835757695712
Epoch [1/500] Batch[5400/12648] complete. train_loss = 42.016900564123084
Epoch [1/500] Batch[5400/12648] complete. train_loss = 42.04808689541287
Epoch [1/500] Batch[5600/12648] complete. train_loss = 41.85066897664751
Epoch [1/500] Batch[5600/12648] complete. train_loss = 41.88476597172873
Epoch [1/500] Batch[5800/12648] complete. train_loss = 41.695464820861815
Epoch [1/500] Batch[5800/12648] complete. train_loss = 41.725663006223485
Epoch [1/500] Batch[6000/12648] complete. train_loss = 41.54489793205261
Epoch [1/500] Batch[6000/12648] complete. train_loss = 41.574137044270834
Epoch [1/500] Batch[6200/12648] complete. train_loss = 41.39589178516019
Epoch [1/500] Batch[6200/12648] complete. train_loss = 41.42446459124165
Epoch [1/500] Batch[6400/12648] complete. train_loss = 41.25650101959705
Epoch [1/500] Batch[6400/12648] complete. train_loss = 41.2810734462738
Epoch [1/500] Batch[6600/12648] complete. train_loss = 41.12156692447084
Epoch [1/500] Batch[6600/12648] complete. train_loss = 41.14241085283684
Epoch [1/500] Batch[6800/12648] complete. train_loss = 40.990994089911965
Epoch [1/500] Batch[6800/12648] complete. train_loss = 41.00689029132619
Epoch [1/500] Batch[7000/12648] complete. train_loss = 40.86602894973755
Epoch [1/500] Batch[7000/12648] complete. train_loss = 40.877320543561666
Epoch [1/500] Batch[7200/12648] complete. train_loss = 40.74064989778731
Epoch [1/500] Batch[7200/12648] complete. train_loss = 40.7510896619161
Epoch [1/500] Batch[7400/12648] complete. train_loss = 40.61825076799135
Epoch [1/500] Batch[7400/12648] complete. train_loss = 40.62884733303173
Epoch [1/500] Batch[7600/12648] complete. train_loss = 40.49750010490418
Epoch [1/500] Batch[7600/12648] complete. train_loss = 40.50674998383773
Epoch [1/500] Batch[7800/12648] complete. train_loss = 40.37868262511033
Epoch [1/500] Batch[7800/12648] complete. train_loss = 40.390438250517235
Epoch [1/500] Batch[8000/12648] complete. train_loss = 40.26481475448608
Epoch [1/500] Batch[8000/12648] complete. train_loss = 40.2772307305336
Epoch [1/500] Batch[8200/12648] complete. train_loss = 40.153269850102866
Epoch [1/500] Batch[8200/12648] complete. train_loss = 40.16702772280065
Epoch [1/500] Batch[8400/12648] complete. train_loss = 40.048656326021465
Epoch [1/500] Batch[8400/12648] complete. train_loss = 40.055519078572594
Epoch [1/500] Batch[8600/12648] complete. train_loss = 39.946826892675354
Epoch [1/500] Batch[8600/12648] complete. train_loss = 39.9453664127616
Epoch [1/500] Batch[8800/12648] complete. train_loss = 39.847476148605345
Epoch [1/500] Batch[8800/12648] complete. train_loss = 39.83742899092761
Epoch [1/500] Batch[9000/12648] complete. train_loss = 39.75047354846531
Epoch [1/500] Batch[9000/12648] complete. train_loss = 39.73421331511604
Epoch [1/500] Batch[9200/12648] complete. train_loss = 39.649719116376794
Epoch [1/500] Batch[9200/12648] complete. train_loss = 39.63511014129804
Epoch [1/500] Batch[9400/12648] complete. train_loss = 39.55411998200924
Epoch [1/500] Batch[9400/12648] complete. train_loss = 39.535138411014636
Epoch [1/500] Batch[9600/12648] complete. train_loss = 39.45704672058423
Epoch [1/500] Batch[9600/12648] complete. train_loss = 39.43406611204147
Epoch [1/500] Batch[9800/12648] complete. train_loss = 39.36556457266516
Epoch [1/500] Batch[9800/12648] complete. train_loss = 39.33743976009136
Epoch [1/500] Batch[10000/12648] complete. train_loss = 39.27309657058716
Epoch [1/500] Batch[10000/12648] complete. train_loss = 39.242223443222045
Epoch [1/500] Batch[10200/12648] complete. train_loss = 39.183133079678406
Epoch [1/500] Batch[10200/12648] complete. train_loss = 39.15045395271451
Epoch [1/500] Batch[10400/12648] complete. train_loss = 39.09562299508315
Epoch [1/500] Batch[10400/12648] complete. train_loss = 39.0580012011528
Epoch [1/500] Batch[10600/12648] complete. train_loss = 39.006816632792635
Epoch [1/500] Batch[10600/12648] complete. train_loss = 38.968195777749116
Epoch [1/500] Batch[10800/12648] complete. train_loss = 38.91887965467241
Epoch [1/500] Batch[10800/12648] complete. train_loss = 38.878542005397655
Epoch [1/500] Batch[11000/12648] complete. train_loss = 38.832773862491955
Epoch [1/500] Batch[11000/12648] complete. train_loss = 38.79245879103921
Epoch [1/500] Batch[11200/12648] complete. train_loss = 38.74606887902532
Epoch [1/500] Batch[11200/12648] complete. train_loss = 38.70606773853302
Epoch [1/500] Batch[11400/12648] complete. train_loss = 38.66198051954571
Epoch [1/500] Batch[11400/12648] complete. train_loss = 38.62041466629296
Epoch [1/500] Batch[11600/12648] complete. train_loss = 38.57844528642194
Epoch [1/500] Batch[11600/12648] complete. train_loss = 38.53438611803384
Epoch [1/500] Batch[11800/12648] complete. train_loss = 38.495714298183636
Epoch [1/500] Batch[11800/12648] complete. train_loss = 38.44897281258793
Epoch [1/500] Batch[12000/12648] complete. train_loss = 38.417793127536775
Epoch [1/500] Batch[12000/12648] complete. train_loss = 38.364931816736856
Epoch [1/500] Batch[12200/12648] complete. train_loss = 38.337825291586704
Epoch [1/500] Batch[12200/12648] complete. train_loss = 38.282324749211796
Epoch [1/500] Batch[12400/12648] complete. train_loss = 38.259132910697694
Epoch [1/500] Batch[12400/12648] complete. train_loss = 38.20200252717541
Epoch [1/500] Batch[12600/12648] complete. train_loss = 38.182641798352435
Epoch [1/500] Batch[12648/12648] complete. valid_loss = 29.624268531799316
best models saved
Best Valid Loss = 29.624268531799316 (Epoch: 1)


Epoch [1/500] Batch[12600/12648] complete. train_loss = 38.1220030607496
Epoch [1/500] Batch[12648/12648] complete. valid_loss = 29.337624073028564
best models saved
Best Valid Loss = 29.337624073028564 (Epoch: 1)


Epoch [2/500] Batch[200/12648] complete. train_loss = 33.096609363555906
Epoch [2/500] Batch[200/12648] complete. train_loss = 32.72390132904053
Epoch [2/500] Batch[400/12648] complete. train_loss = 33.019317965507504
Epoch [2/500] Batch[400/12648] complete. train_loss = 32.70836414337158
Epoch [2/500] Batch[600/12648] complete. train_loss = 32.9432772954305
Epoch [2/500] Batch[600/12648] complete. train_loss = 32.700278278986616
Epoch [2/500] Batch[800/12648] complete. train_loss = 32.94961344003677
Epoch [2/500] Batch[800/12648] complete. train_loss = 32.67068682670593
Epoch [2/500] Batch[1000/12648] complete. train_loss = 32.63089005088806
Epoch [2/500] Batch[1200/12648] complete. train_loss = 32.590421112378436
Epoch [2/500] Batch[1400/12648] complete. train_loss = 32.55776116779872
Epoch [2/500] Batch[1600/12648] complete. train_loss = 32.52928861856461
Epoch [2/500] Batch[1800/12648] complete. train_loss = 32.486172432369656
Epoch [2/500] Batch[2000/12648] complete. train_loss = 32.43767168140411
Epoch [2/500] Batch[2200/12648] complete. train_loss = 32.40664930950511
Epoch [2/500] Batch[2400/12648] complete. train_loss = 32.36825614531835
Epoch [2/500] Batch[2600/12648] complete. train_loss = 32.324211104466364
Epoch [2/500] Batch[2800/12648] complete. train_loss = 32.27337616239275
Epoch [2/500] Batch[3000/12648] complete. train_loss = 32.236742031097414
Epoch [2/500] Batch[3200/12648] complete. train_loss = 32.19176737964153
Epoch [2/500] Batch[3400/12648] complete. train_loss = 32.152791144427134
Epoch [2/500] Batch[3600/12648] complete. train_loss = 32.11430472797818
Epoch [2/500] Batch[3800/12648] complete. train_loss = 32.0779938742989
Epoch [2/500] Batch[4000/12648] complete. train_loss = 32.0350257139206
Epoch [2/500] Batch[4200/12648] complete. train_loss = 31.995981380825953
Epoch [2/500] Batch[4400/12648] complete. train_loss = 31.959475988474757
Epoch [2/500] Batch[4600/12648] complete. train_loss = 31.920819565731545
Epoch [2/500] Batch[4800/12648] complete. train_loss = 31.887002071142195
Epoch [2/500] Batch[5000/12648] complete. train_loss = 31.851072386932373
Epoch [2/500] Batch[5200/12648] complete. train_loss = 31.814063958754907
Epoch [2/500] Batch[5400/12648] complete. train_loss = 31.777290017163313
Epoch [2/500] Batch[5600/12648] complete. train_loss = 31.743863357475824
Epoch [2/500] Batch[5800/12648] complete. train_loss = 31.709386526633953
Epoch [2/500] Batch[6000/12648] complete. train_loss = 31.67336669445038
Epoch [2/500] Batch[6200/12648] complete. train_loss = 31.639359655687887
Epoch [2/500] Batch[6400/12648] complete. train_loss = 31.602328239381315
Epoch [2/500] Batch[6600/12648] complete. train_loss = 31.563824608831695
Epoch [2/500] Batch[6800/12648] complete. train_loss = 31.5263458366955
Epoch [2/500] Batch[7000/12648] complete. train_loss = 31.495471101488384
Epoch [2/500] Batch[7200/12648] complete. train_loss = 31.46169934193293
Epoch [2/500] Batch[7400/12648] complete. train_loss = 31.426962658134666
Epoch [2/500] Batch[7600/12648] complete. train_loss = 31.38966634273529
Epoch [2/500] Batch[7800/12648] complete. train_loss = 31.354335886148306
Epoch [2/500] Batch[8000/12648] complete. train_loss = 31.319705312252044
Epoch [2/500] Batch[8200/12648] complete. train_loss = 31.28503981846135
Epoch [2/500] Batch[8400/12648] complete. train_loss = 31.251806179682415
Epoch [2/500] Batch[8600/12648] complete. train_loss = 31.221102896180263
Epoch [2/500] Batch[8800/12648] complete. train_loss = 31.187052884968843
Epoch [2/500] Batch[9000/12648] complete. train_loss = 31.155063790215387
Epoch [2/500] Batch[9200/12648] complete. train_loss = 31.12129250319108
Epoch [2/500] Batch[9400/12648] complete. train_loss = 31.09014060629175
Epoch [2/500] Batch[9600/12648] complete. train_loss = 31.05863275607427
Epoch [2/500] Batch[9800/12648] complete. train_loss = 31.025132534649906
Epoch [2/500] Batch[10000/12648] complete. train_loss = 30.994238504600524
Epoch [2/500] Batch[10200/12648] complete. train_loss = 30.96114010923049
Epoch [2/500] Batch[10400/12648] complete. train_loss = 30.93017235315763
Epoch [2/500] Batch[10600/12648] complete. train_loss = 30.89978674618703
Epoch [2/500] Batch[10800/12648] complete. train_loss = 30.871087410538284
Epoch [2/500] Batch[11000/12648] complete. train_loss = 30.840183998974886
Epoch [2/500] Batch[11200/12648] complete. train_loss = 30.806634516545703
Epoch [2/500] Batch[11400/12648] complete. train_loss = 30.775697886483712
Epoch [2/500] Batch[11600/12648] complete. train_loss = 30.74582916095339
Epoch [2/500] Batch[11800/12648] complete. train_loss = 30.713149965738847
Epoch [2/500] Batch[12000/12648] complete. train_loss = 30.684987071355184
Epoch [2/500] Batch[12200/12648] complete. train_loss = 30.656522196159987
Epoch [2/500] Batch[12400/12648] complete. train_loss = 30.62451560189647
Epoch [2/500] Batch[12600/12648] complete. train_loss = 30.596355404778134
Epoch [2/500] Batch[12648/12648] complete. valid_loss = 25.334222555160522
best models saved
Best Valid Loss = 25.334222555160522 (Epoch: 2)


Epoch [3/500] Batch[200/12648] complete. train_loss = 28.370559825897217
Epoch [3/500] Batch[400/12648] complete. train_loss = 28.378134360313414
Epoch [3/500] Batch[600/12648] complete. train_loss = 28.32972954750061
Epoch [3/500] Batch[800/12648] complete. train_loss = 28.354123306274413
Epoch [3/500] Batch[1000/12648] complete. train_loss = 28.3145726146698
Epoch [3/500] Batch[1200/12648] complete. train_loss = 28.31190457344055
Epoch [3/500] Batch[1400/12648] complete. train_loss = 28.270765980311804
Epoch [3/500] Batch[1600/12648] complete. train_loss = 28.254245166778563
Epoch [3/500] Batch[1800/12648] complete. train_loss = 28.22870922512478
Epoch [3/500] Batch[2000/12648] complete. train_loss = 28.2154997215271
Epoch [3/500] Batch[2200/12648] complete. train_loss = 28.19105507590554
Epoch [3/500] Batch[2400/12648] complete. train_loss = 28.178588705062865
Epoch [3/500] Batch[2600/12648] complete. train_loss = 28.1539290868319
Epoch [3/500] Batch[2800/12648] complete. train_loss = 28.133621756008694
Epoch [3/500] Batch[3000/12648] complete. train_loss = 28.109091192245483
Epoch [3/500] Batch[3200/12648] complete. train_loss = 28.08867495775223
Epoch [3/500] Batch[3400/12648] complete. train_loss = 28.076277520796832
Epoch [3/500] Batch[3600/12648] complete. train_loss = 28.062277869648405
Epoch [3/500] Batch[3800/12648] complete. train_loss = 28.042691495293067
Epoch [3/500] Batch[4000/12648] complete. train_loss = 28.0258096909523
Epoch [3/500] Batch[4200/12648] complete. train_loss = 28.007459129605973
Epoch [3/500] Batch[4400/12648] complete. train_loss = 27.994255782040682
Epoch [3/500] Batch[4600/12648] complete. train_loss = 27.981940143833988
Epoch [3/500] Batch[4800/12648] complete. train_loss = 27.96823007384936
Epoch [3/500] Batch[5000/12648] complete. train_loss = 27.953523711013794
Epoch [3/500] Batch[5200/12648] complete. train_loss = 27.936446028489332
Epoch [3/500] Batch[5400/12648] complete. train_loss = 27.922505634449145
Epoch [3/500] Batch[5600/12648] complete. train_loss = 27.903670461177825
Epoch [3/500] Batch[5800/12648] complete. train_loss = 27.887747630086437
Epoch [3/500] Batch[6000/12648] complete. train_loss = 27.86971264743805
Epoch [3/500] Batch[6200/12648] complete. train_loss = 27.851172114956764
Epoch [3/500] Batch[6400/12648] complete. train_loss = 27.83436443299055
Epoch [3/500] Batch[6600/12648] complete. train_loss = 27.817703363245183
Epoch [3/500] Batch[6800/12648] complete. train_loss = 27.801774261699002
Epoch [3/500] Batch[7000/12648] complete. train_loss = 27.789274230412076
Epoch [3/500] Batch[7200/12648] complete. train_loss = 27.77516503545973
Epoch [3/500] Batch[7400/12648] complete. train_loss = 27.757694929483776
Epoch [3/500] Batch[7600/12648] complete. train_loss = 27.743405900754425
Epoch [3/500] Batch[7800/12648] complete. train_loss = 27.726043047049107
Epoch [3/500] Batch[8000/12648] complete. train_loss = 27.710365782022475
Epoch [3/500] Batch[8200/12648] complete. train_loss = 27.69730142477082
Epoch [3/500] Batch[8400/12648] complete. train_loss = 27.68413940066383
Epoch [3/500] Batch[8600/12648] complete. train_loss = 27.67072452966557
Epoch [3/500] Batch[8800/12648] complete. train_loss = 27.65577027385885
Epoch [3/500] Batch[9000/12648] complete. train_loss = 27.639760648727417
Epoch [3/500] Batch[9200/12648] complete. train_loss = 27.624207997529403
Epoch [3/500] Batch[9400/12648] complete. train_loss = 27.610084136394743
Epoch [3/500] Batch[9600/12648] complete. train_loss = 27.596754650672278
Epoch [3/500] Batch[9800/12648] complete. train_loss = 27.5820955274543
Epoch [3/500] Batch[10000/12648] complete. train_loss = 27.56832967147827
Epoch [3/500] Batch[10200/12648] complete. train_loss = 27.55287571925743
Epoch [3/500] Batch[10400/12648] complete. train_loss = 27.537396429868846
Epoch [3/500] Batch[10600/12648] complete. train_loss = 27.522019726375365
Epoch [3/500] Batch[10800/12648] complete. train_loss = 27.506925580236647
Epoch [3/500] Batch[11000/12648] complete. train_loss = 27.493805256236683
Epoch [3/500] Batch[11200/12648] complete. train_loss = 27.480421999863214
Epoch [3/500] Batch[11400/12648] complete. train_loss = 27.46659817227146
Epoch [3/500] Batch[11600/12648] complete. train_loss = 27.449414378199084
Epoch [3/500] Batch[11800/12648] complete. train_loss = 27.43596720000445
Epoch [3/500] Batch[12000/12648] complete. train_loss = 27.420517645835876
Epoch [3/500] Batch[12200/12648] complete. train_loss = 27.40772864404272
Epoch [3/500] Batch[12400/12648] complete. train_loss = 27.39296303395302
Epoch [3/500] Batch[12600/12648] complete. train_loss = 27.37939750262669
Epoch [3/500] Batch[12648/12648] complete. valid_loss = 23.51085066795349
best models saved
Best Valid Loss = 23.51085066795349 (Epoch: 3)


Epoch [4/500] Batch[200/12648] complete. train_loss = 26.131697635650635
Epoch [4/500] Batch[400/12648] complete. train_loss = 26.03284815788269
Epoch [4/500] Batch[600/12648] complete. train_loss = 25.97146352450053
Epoch [4/500] Batch[800/12648] complete. train_loss = 25.97108617067337
Epoch [4/500] Batch[1000/12648] complete. train_loss = 25.97076256942749
Epoch [4/500] Batch[1200/12648] complete. train_loss = 25.981627616882324
Epoch [4/500] Batch[1400/12648] complete. train_loss = 25.987143718174526
Epoch [4/500] Batch[1600/12648] complete. train_loss = 25.98944755077362
Epoch [4/500] Batch[1800/12648] complete. train_loss = 25.99253640598721
Epoch [4/500] Batch[2000/12648] complete. train_loss = 25.969824962615967
Epoch [4/500] Batch[2200/12648] complete. train_loss = 25.95916643229398
Epoch [4/500] Batch[2400/12648] complete. train_loss = 25.949344235261282
Epoch [4/500] Batch[2600/12648] complete. train_loss = 25.938001001064595
Epoch [4/500] Batch[2800/12648] complete. train_loss = 25.927746139935085
Epoch [4/500] Batch[3000/12648] complete. train_loss = 25.920574274698893
Epoch [4/500] Batch[3200/12648] complete. train_loss = 25.9228465116024
Epoch [4/500] Batch[3400/12648] complete. train_loss = 25.910666545419133
Epoch [4/500] Batch[3600/12648] complete. train_loss = 25.90132973247104
Epoch [4/500] Batch[3800/12648] complete. train_loss = 25.891821754857112
Epoch [4/500] Batch[4000/12648] complete. train_loss = 25.884349240779876
Epoch [4/500] Batch[4200/12648] complete. train_loss = 25.875683668227424
Epoch [4/500] Batch[4400/12648] complete. train_loss = 25.87036009831862
Epoch [4/500] Batch[4600/12648] complete. train_loss = 25.86450105998827
Epoch [4/500] Batch[4800/12648] complete. train_loss = 25.857976202170054
Epoch [4/500] Batch[5000/12648] complete. train_loss = 25.847754075622557
Epoch [4/500] Batch[5200/12648] complete. train_loss = 25.835462323335502
Epoch [4/500] Batch[5400/12648] complete. train_loss = 25.83115884321707
Epoch [4/500] Batch[5600/12648] complete. train_loss = 25.826072177205766
Epoch [4/500] Batch[5800/12648] complete. train_loss = 25.816226476143147
Epoch [4/500] Batch[6000/12648] complete. train_loss = 25.809614890734355
Epoch [4/500] Batch[6200/12648] complete. train_loss = 25.798998948989375
Epoch [4/500] Batch[6400/12648] complete. train_loss = 25.792537196576596
Epoch [4/500] Batch[6600/12648] complete. train_loss = 25.787434164683024
Epoch [4/500] Batch[6800/12648] complete. train_loss = 25.78121425151825
Epoch [4/500] Batch[7000/12648] complete. train_loss = 25.771770782743182
Epoch [4/500] Batch[7200/12648] complete. train_loss = 25.767488957511056
Epoch [4/500] Batch[7400/12648] complete. train_loss = 25.7618850481188
Epoch [4/500] Batch[7600/12648] complete. train_loss = 25.753159259494982
Epoch [4/500] Batch[7800/12648] complete. train_loss = 25.74437629650801
Epoch [4/500] Batch[8000/12648] complete. train_loss = 25.73401834845543
Epoch [4/500] Batch[8200/12648] complete. train_loss = 25.72941430696627
Epoch [4/500] Batch[8400/12648] complete. train_loss = 25.71747039068313
Epoch [4/500] Batch[8600/12648] complete. train_loss = 25.710933356174202
Epoch [4/500] Batch[8800/12648] complete. train_loss = 25.70441216360439
Epoch [4/500] Batch[9000/12648] complete. train_loss = 25.69635468143887
Epoch [4/500] Batch[9200/12648] complete. train_loss = 25.688646248941836
Epoch [4/500] Batch[9400/12648] complete. train_loss = 25.68125773693653
Epoch [4/500] Batch[9600/12648] complete. train_loss = 25.67227490365505
Epoch [4/500] Batch[9800/12648] complete. train_loss = 25.666104123057153
Epoch [4/500] Batch[10000/12648] complete. train_loss = 25.65731196422577
Epoch [4/500] Batch[10200/12648] complete. train_loss = 25.64874017565858
Epoch [4/500] Batch[10400/12648] complete. train_loss = 25.64144756445518
Epoch [4/500] Batch[10600/12648] complete. train_loss = 25.630749790623504
Epoch [4/500] Batch[10800/12648] complete. train_loss = 25.62204055786133
Epoch [4/500] Batch[11000/12648] complete. train_loss = 25.614672400908038
Epoch [4/500] Batch[11200/12648] complete. train_loss = 25.605529119798117
Epoch [4/500] Batch[11400/12648] complete. train_loss = 25.597671286599677
Epoch [4/500] Batch[11600/12648] complete. train_loss = 25.589403572740228
Epoch [4/500] Batch[11800/12648] complete. train_loss = 25.580509758157245
Epoch [4/500] Batch[12000/12648] complete. train_loss = 25.57419658454259
Epoch [4/500] Batch[12200/12648] complete. train_loss = 25.56636435727604
Epoch [4/500] Batch[12400/12648] complete. train_loss = 25.558277587736807
Epoch [4/500] Batch[12600/12648] complete. train_loss = 25.54930187361581
Epoch [4/500] Batch[12648/12648] complete. valid_loss = 22.49578857421875
best models saved
Best Valid Loss = 22.49578857421875 (Epoch: 4)


Epoch [5/500] Batch[200/12648] complete. train_loss = 24.487842302322388
Epoch [5/500] Batch[400/12648] complete. train_loss = 24.527822794914247
Epoch [5/500] Batch[600/12648] complete. train_loss = 24.516692406336468
Epoch [5/500] Batch[800/12648] complete. train_loss = 24.49119428396225
Epoch [5/500] Batch[1000/12648] complete. train_loss = 24.502670227050782
Epoch [5/500] Batch[1200/12648] complete. train_loss = 24.49152707417806
Epoch [5/500] Batch[1400/12648] complete. train_loss = 24.494714473996844
Epoch [5/500] Batch[1600/12648] complete. train_loss = 24.498433347940445
Epoch [5/500] Batch[1800/12648] complete. train_loss = 24.494948943456013
Epoch [5/500] Batch[2000/12648] complete. train_loss = 24.49411465740204
Epoch [5/500] Batch[2200/12648] complete. train_loss = 24.49590815630826
Epoch [5/500] Batch[2400/12648] complete. train_loss = 24.490817447503407
Epoch [5/500] Batch[2600/12648] complete. train_loss = 24.49594807771536
Epoch [5/500] Batch[2800/12648] complete. train_loss = 24.50005806854793
Epoch [5/500] Batch[3000/12648] complete. train_loss = 24.49466817029317
Epoch [5/500] Batch[3200/12648] complete. train_loss = 24.495346915125847
Epoch [5/500] Batch[3400/12648] complete. train_loss = 24.49939499237958
Epoch [5/500] Batch[3600/12648] complete. train_loss = 24.495816695955064
Epoch [5/500] Batch[3800/12648] complete. train_loss = 24.500828554755763
Epoch [5/500] Batch[4000/12648] complete. train_loss = 24.50065709733963
Epoch [5/500] Batch[4200/12648] complete. train_loss = 24.497778918856667
Epoch [5/500] Batch[4400/12648] complete. train_loss = 24.493165270631962
Epoch [5/500] Batch[4600/12648] complete. train_loss = 24.494715189311815
Epoch [5/500] Batch[4800/12648] complete. train_loss = 24.49624282558759
Epoch [5/500] Batch[5000/12648] complete. train_loss = 24.491585807418822
Epoch [5/500] Batch[5200/12648] complete. train_loss = 24.483752121925352
Epoch [5/500] Batch[5400/12648] complete. train_loss = 24.479303360338566
Epoch [5/500] Batch[5600/12648] complete. train_loss = 24.47559250150408
Epoch [5/500] Batch[5800/12648] complete. train_loss = 24.47062301339774
Epoch [5/500] Batch[6000/12648] complete. train_loss = 24.471560188293456
Epoch [5/500] Batch[6200/12648] complete. train_loss = 24.46914149468945
Epoch [5/500] Batch[6400/12648] complete. train_loss = 24.46620395541191
Epoch [5/500] Batch[6600/12648] complete. train_loss = 24.462312050154715
Epoch [5/500] Batch[6800/12648] complete. train_loss = 24.458113282147576
Epoch [5/500] Batch[7000/12648] complete. train_loss = 24.45527951703753
Epoch [5/500] Batch[7200/12648] complete. train_loss = 24.449008331828647
Epoch [5/500] Batch[7400/12648] complete. train_loss = 24.44387049262588
Epoch [5/500] Batch[7600/12648] complete. train_loss = 24.43997759869224
Epoch [5/500] Batch[7800/12648] complete. train_loss = 24.432941769086398
Epoch [5/500] Batch[8000/12648] complete. train_loss = 24.42920001554489
Epoch [5/500] Batch[8200/12648] complete. train_loss = 24.42697954363939
Epoch [5/500] Batch[8400/12648] complete. train_loss = 24.42254720460801
Epoch [5/500] Batch[8600/12648] complete. train_loss = 24.417104819098185
Epoch [5/500] Batch[8800/12648] complete. train_loss = 24.41328033729033
Epoch [5/500] Batch[9000/12648] complete. train_loss = 24.409789525561862
Epoch [5/500] Batch[9200/12648] complete. train_loss = 24.406219613655754
Epoch [5/500] Batch[9400/12648] complete. train_loss = 24.402096587039054
Epoch [5/500] Batch[9600/12648] complete. train_loss = 24.39590260108312
Epoch [5/500] Batch[9800/12648] complete. train_loss = 24.389675925507838
Epoch [5/500] Batch[10000/12648] complete. train_loss = 24.384168727874755
Epoch [5/500] Batch[10200/12648] complete. train_loss = 24.38058897411122
Epoch [5/500] Batch[10400/12648] complete. train_loss = 24.37654862990746
Epoch [5/500] Batch[10600/12648] complete. train_loss = 24.37183288790145
Epoch [5/500] Batch[10800/12648] complete. train_loss = 24.369547735850016
Epoch [5/500] Batch[11000/12648] complete. train_loss = 24.36591770189459
Epoch [5/500] Batch[11200/12648] complete. train_loss = 24.361931219271252
Epoch [5/500] Batch[11400/12648] complete. train_loss = 24.35727830384907
Epoch [5/500] Batch[11600/12648] complete. train_loss = 24.352964744732297
Epoch [5/500] Batch[11800/12648] complete. train_loss = 24.349082805180952
Epoch [5/500] Batch[12000/12648] complete. train_loss = 24.34328247753779
Epoch [5/500] Batch[12200/12648] complete. train_loss = 24.34006860248378
Epoch [5/500] Batch[12400/12648] complete. train_loss = 24.33678861633424
Epoch [5/500] Batch[12600/12648] complete. train_loss = 24.33179509011526
Epoch [5/500] Batch[12648/12648] complete. valid_loss = 21.994905948638916
best models saved
Best Valid Loss = 21.994905948638916 (Epoch: 5)


Epoch [6/500] Batch[200/12648] complete. train_loss = 23.451724195480345
Epoch [6/500] Batch[400/12648] complete. train_loss = 23.45247972011566
Epoch [6/500] Batch[600/12648] complete. train_loss = 23.426013736724855
Epoch [6/500] Batch[800/12648] complete. train_loss = 23.456242349147796
Epoch [6/500] Batch[1000/12648] complete. train_loss = 23.463664121627808
Epoch [6/500] Batch[1200/12648] complete. train_loss = 23.4798063993454
Epoch [6/500] Batch[1400/12648] complete. train_loss = 23.511835062844412
Epoch [6/500] Batch[1600/12648] complete. train_loss = 23.518119815587998
Epoch [6/500] Batch[1800/12648] complete. train_loss = 23.516794249216716
Epoch [6/500] Batch[2000/12648] complete. train_loss = 23.532412490844727
Epoch [6/500] Batch[2200/12648] complete. train_loss = 23.53390360485424
Epoch [6/500] Batch[2400/12648] complete. train_loss = 23.52858324130376
Epoch [6/500] Batch[2600/12648] complete. train_loss = 23.534468494562002
Epoch [6/500] Batch[2800/12648] complete. train_loss = 23.53944432394845
Epoch [6/500] Batch[3000/12648] complete. train_loss = 23.539227262496947
Epoch [6/500] Batch[3200/12648] complete. train_loss = 23.54321319758892
Epoch [6/500] Batch[3400/12648] complete. train_loss = 23.548347852931304
Epoch [6/500] Batch[3600/12648] complete. train_loss = 23.544965795411002
Epoch [6/500] Batch[3800/12648] complete. train_loss = 23.54417046797903
Epoch [6/500] Batch[4000/12648] complete. train_loss = 23.54136344909668
Epoch [6/500] Batch[4200/12648] complete. train_loss = 23.53974681945074
Epoch [6/500] Batch[4400/12648] complete. train_loss = 23.542005052566527
Epoch [6/500] Batch[4600/12648] complete. train_loss = 23.54013775949893
Epoch [6/500] Batch[4800/12648] complete. train_loss = 23.538998588323594
Epoch [6/500] Batch[5000/12648] complete. train_loss = 23.539683938598632
Epoch [6/500] Batch[5200/12648] complete. train_loss = 23.53805196762085
Epoch [6/500] Batch[5400/12648] complete. train_loss = 23.534686866336397
Epoch [6/500] Batch[5600/12648] complete. train_loss = 23.532004512718746
Epoch [6/500] Batch[5800/12648] complete. train_loss = 23.532091871787763
Epoch [6/500] Batch[6000/12648] complete. train_loss = 23.532151713371277
Epoch [6/500] Batch[6200/12648] complete. train_loss = 23.53359975968638
Epoch [6/500] Batch[6400/12648] complete. train_loss = 23.531461622714996
Epoch [6/500] Batch[6600/12648] complete. train_loss = 23.52825913776051
Epoch [6/500] Batch[6800/12648] complete. train_loss = 23.527205130633185
Epoch [6/500] Batch[7000/12648] complete. train_loss = 23.525167873927526
Epoch [6/500] Batch[7200/12648] complete. train_loss = 23.524650478363036
Epoch [6/500] Batch[7400/12648] complete. train_loss = 23.521096452764564
Epoch [6/500] Batch[7600/12648] complete. train_loss = 23.517592381427164
Epoch [6/500] Batch[7800/12648] complete. train_loss = 23.515619708819266
Epoch [6/500] Batch[8000/12648] complete. train_loss = 23.51378955602646
Epoch [6/500] Batch[8200/12648] complete. train_loss = 23.510968713760377
Epoch [6/500] Batch[8400/12648] complete. train_loss = 23.50966260342371
Epoch [6/500] Batch[8600/12648] complete. train_loss = 23.50531508822774
Epoch [6/500] Batch[8800/12648] complete. train_loss = 23.50326885548505
Epoch [6/500] Batch[9000/12648] complete. train_loss = 23.499422662734986
Epoch [6/500] Batch[9200/12648] complete. train_loss = 23.496121829903643
Epoch [6/500] Batch[9400/12648] complete. train_loss = 23.49413375489255
Epoch [6/500] Batch[9600/12648] complete. train_loss = 23.491977579991023
Epoch [6/500] Batch[9800/12648] complete. train_loss = 23.491308317184448
Epoch [6/500] Batch[10000/12648] complete. train_loss = 23.489669149589538
Epoch [6/500] Batch[10200/12648] complete. train_loss = 23.486950216293334
Epoch [6/500] Batch[10400/12648] complete. train_loss = 23.485063464274774
Epoch [6/500] Batch[10600/12648] complete. train_loss = 23.481983830254034
Epoch [6/500] Batch[10800/12648] complete. train_loss = 23.480457829192833
Epoch [6/500] Batch[11000/12648] complete. train_loss = 23.477525733774357
Epoch [6/500] Batch[11200/12648] complete. train_loss = 23.474144238233567
Epoch [6/500] Batch[11400/12648] complete. train_loss = 23.47174097010964
Epoch [6/500] Batch[11600/12648] complete. train_loss = 23.471014963840616
Epoch [6/500] Batch[11800/12648] complete. train_loss = 23.466713326017736
Epoch [6/500] Batch[12000/12648] complete. train_loss = 23.463022387186687
Epoch [6/500] Batch[12200/12648] complete. train_loss = 23.46038217982308
Epoch [6/500] Batch[12400/12648] complete. train_loss = 23.457915535896056
Epoch [6/500] Batch[12600/12648] complete. train_loss = 23.45412532821534
Epoch [6/500] Batch[12648/12648] complete. valid_loss = 21.389601469039917
best models saved
Best Valid Loss = 21.389601469039917 (Epoch: 6)


Epoch [7/500] Batch[200/12648] complete. train_loss = 22.770304832458496
Epoch [7/500] Batch[400/12648] complete. train_loss = 22.759730229377748
Epoch [7/500] Batch[600/12648] complete. train_loss = 22.754880673090618
Epoch [7/500] Batch[800/12648] complete. train_loss = 22.76172166109085
Epoch [7/500] Batch[1000/12648] complete. train_loss = 22.769381900787355
Epoch [7/500] Batch[1200/12648] complete. train_loss = 22.77442136446635
Epoch [7/500] Batch[1400/12648] complete. train_loss = 22.762171619960238
Epoch [7/500] Batch[1600/12648] complete. train_loss = 22.78112537622452
Epoch [7/500] Batch[1800/12648] complete. train_loss = 22.790083323584664
Epoch [7/500] Batch[2000/12648] complete. train_loss = 22.78412979888916
Epoch [7/500] Batch[2200/12648] complete. train_loss = 22.790716550133446
Epoch [7/500] Batch[2400/12648] complete. train_loss = 22.789670334657032
Epoch [7/500] Batch[2600/12648] complete. train_loss = 22.784259221003605
Epoch [7/500] Batch[2800/12648] complete. train_loss = 22.783904836518424
Epoch [7/500] Batch[3000/12648] complete. train_loss = 22.783297207514444
Epoch [7/500] Batch[3200/12648] complete. train_loss = 22.784741844534874
Epoch [7/500] Batch[3400/12648] complete. train_loss = 22.785544523912318
Epoch [7/500] Batch[3600/12648] complete. train_loss = 22.790206376181708
Epoch [7/500] Batch[3800/12648] complete. train_loss = 22.793288907502827
Epoch [7/500] Batch[4000/12648] complete. train_loss = 22.798031069278718
Epoch [7/500] Batch[4200/12648] complete. train_loss = 22.797134823117936
Epoch [7/500] Batch[4400/12648] complete. train_loss = 22.796923252019017
Epoch [7/500] Batch[4600/12648] complete. train_loss = 22.799353975627735
Epoch [7/500] Batch[4800/12648] complete. train_loss = 22.7978959830602
Epoch [7/500] Batch[5000/12648] complete. train_loss = 22.79699634666443
Epoch [7/500] Batch[5200/12648] complete. train_loss = 22.79792861204881
Epoch [7/500] Batch[5400/12648] complete. train_loss = 22.796692110344214
Epoch [7/500] Batch[5600/12648] complete. train_loss = 22.797247211592538
Epoch [7/500] Batch[5800/12648] complete. train_loss = 22.796537805754564
Epoch [7/500] Batch[6000/12648] complete. train_loss = 22.797398189226787
Epoch [7/500] Batch[6200/12648] complete. train_loss = 22.799374033097298
Epoch [7/500] Batch[6400/12648] complete. train_loss = 22.799373781979085
Epoch [7/500] Batch[6600/12648] complete. train_loss = 22.801390919251876
Epoch [7/500] Batch[6800/12648] complete. train_loss = 22.803415682736563
Epoch [7/500] Batch[7000/12648] complete. train_loss = 22.8045726310185
Epoch [7/500] Batch[7200/12648] complete. train_loss = 22.80244274881151
Epoch [7/500] Batch[7400/12648] complete. train_loss = 22.80223457955025
Epoch [7/500] Batch[7600/12648] complete. train_loss = 22.800359064403334
Epoch [7/500] Batch[7800/12648] complete. train_loss = 22.79951992768508
Epoch [7/500] Batch[8000/12648] complete. train_loss = 22.800822057008745
Epoch [7/500] Batch[8200/12648] complete. train_loss = 22.800505672547875
Epoch [7/500] Batch[8400/12648] complete. train_loss = 22.797256037394206
Epoch [7/500] Batch[8600/12648] complete. train_loss = 22.79604385486869
Epoch [7/500] Batch[8800/12648] complete. train_loss = 22.796613629081033
Epoch [7/500] Batch[9000/12648] complete. train_loss = 22.795922264522975
Epoch [7/500] Batch[9200/12648] complete. train_loss = 22.795808186116425
Epoch [7/500] Batch[9400/12648] complete. train_loss = 22.796529125660022
Epoch [7/500] Batch[9600/12648] complete. train_loss = 22.795966306328772
Epoch [7/500] Batch[9800/12648] complete. train_loss = 22.793986939410775
Epoch [7/500] Batch[10000/12648] complete. train_loss = 22.793323697662352
Epoch [7/500] Batch[10200/12648] complete. train_loss = 22.793553060269822
Epoch [7/500] Batch[10400/12648] complete. train_loss = 22.791637225334462
Epoch [7/500] Batch[10600/12648] complete. train_loss = 22.793201832141516
Epoch [7/500] Batch[10800/12648] complete. train_loss = 22.7926996284061
Epoch [7/500] Batch[11000/12648] complete. train_loss = 22.79148141860962
Epoch [7/500] Batch[11200/12648] complete. train_loss = 22.791070775134223
Epoch [7/500] Batch[11400/12648] complete. train_loss = 22.791713756929365
Epoch [7/500] Batch[11600/12648] complete. train_loss = 22.792284170512495
Epoch [7/500] Batch[11800/12648] complete. train_loss = 22.790351040727
Epoch [7/500] Batch[12000/12648] complete. train_loss = 22.788087363878887
Epoch [7/500] Batch[12200/12648] complete. train_loss = 22.786790834802098
Epoch [7/500] Batch[12400/12648] complete. train_loss = 22.786378579754984
Epoch [7/500] Batch[12600/12648] complete. train_loss = 22.785637592890907
Epoch [7/500] Batch[12648/12648] complete. valid_loss = 21.03409171104431
best models saved
Best Valid Loss = 21.03409171104431 (Epoch: 7)


Epoch [8/500] Batch[200/12648] complete. train_loss = 22.18936122894287
Epoch [8/500] Batch[400/12648] complete. train_loss = 22.154706764221192
Epoch [8/500] Batch[600/12648] complete. train_loss = 22.201174144744872
Epoch [8/500] Batch[800/12648] complete. train_loss = 22.199674940109254
Epoch [8/500] Batch[1000/12648] complete. train_loss = 22.19231266593933
Epoch [8/500] Batch[1200/12648] complete. train_loss = 22.18767175356547
Epoch [8/500] Batch[1400/12648] complete. train_loss = 22.18829295022147
Epoch [8/500] Batch[1600/12648] complete. train_loss = 22.201673500537872
Epoch [8/500] Batch[1800/12648] complete. train_loss = 22.20424827363756
Epoch [8/500] Batch[2000/12648] complete. train_loss = 22.206568024635313
Epoch [8/500] Batch[2200/12648] complete. train_loss = 22.208144889311356
Epoch [8/500] Batch[2400/12648] complete. train_loss = 22.213101491133372
Epoch [8/500] Batch[2600/12648] complete. train_loss = 22.22038910132188
Epoch [8/500] Batch[2800/12648] complete. train_loss = 22.219358422415596
Epoch [8/500] Batch[3000/12648] complete. train_loss = 22.225110237121584
Epoch [8/500] Batch[3200/12648] complete. train_loss = 22.227637655735016
Epoch [8/500] Batch[3400/12648] complete. train_loss = 22.230334736880135
Epoch [8/500] Batch[3600/12648] complete. train_loss = 22.23273596021864
Epoch [8/500] Batch[3800/12648] complete. train_loss = 22.231570525420338
Epoch [8/500] Batch[4000/12648] complete. train_loss = 22.23308299303055
Epoch [8/500] Batch[4200/12648] complete. train_loss = 22.23152077129909
Epoch [8/500] Batch[4400/12648] complete. train_loss = 22.235381828654898
Epoch [8/500] Batch[4600/12648] complete. train_loss = 22.22934770003609
Epoch [8/500] Batch[4800/12648] complete. train_loss = 22.235454441706338
Epoch [8/500] Batch[5000/12648] complete. train_loss = 22.238991771316527
Epoch [8/500] Batch[5200/12648] complete. train_loss = 22.240925724689777
Epoch [8/500] Batch[5400/12648] complete. train_loss = 22.24461346661603
Epoch [8/500] Batch[5600/12648] complete. train_loss = 22.247945260320392
Epoch [8/500] Batch[5800/12648] complete. train_loss = 22.249414763943903
Epoch [8/500] Batch[6000/12648] complete. train_loss = 22.25009743754069
Epoch [8/500] Batch[6200/12648] complete. train_loss = 22.25005956280616
Epoch [8/500] Batch[6400/12648] complete. train_loss = 22.25097726136446
Epoch [8/500] Batch[6600/12648] complete. train_loss = 22.25172882051179
Epoch [8/500] Batch[6800/12648] complete. train_loss = 22.25279897998361
Epoch [8/500] Batch[7000/12648] complete. train_loss = 22.250960488183157
Epoch [8/500] Batch[7200/12648] complete. train_loss = 22.25246485763126
Epoch [8/500] Batch[7400/12648] complete. train_loss = 22.25093258883502
Epoch [8/500] Batch[7600/12648] complete. train_loss = 22.251503559162742
Epoch [8/500] Batch[7800/12648] complete. train_loss = 22.25227165222168
Epoch [8/500] Batch[8000/12648] complete. train_loss = 22.253465148448946
Epoch [8/500] Batch[8200/12648] complete. train_loss = 22.25589521059176
Epoch [8/500] Batch[8400/12648] complete. train_loss = 22.25805805978321
Epoch [8/500] Batch[8600/12648] complete. train_loss = 22.258097938271455
Epoch [8/500] Batch[8800/12648] complete. train_loss = 22.260761049444024
Epoch [8/500] Batch[9000/12648] complete. train_loss = 22.257933504740397
Epoch [8/500] Batch[9200/12648] complete. train_loss = 22.257602838225985
Epoch [8/500] Batch[9400/12648] complete. train_loss = 22.25705362441692
Epoch [8/500] Batch[9600/12648] complete. train_loss = 22.25630949775378
Epoch [8/500] Batch[9800/12648] complete. train_loss = 22.255681637744516
Epoch [8/500] Batch[10000/12648] complete. train_loss = 22.254924486732484
Epoch [8/500] Batch[10200/12648] complete. train_loss = 22.254593654146383
Epoch [8/500] Batch[10400/12648] complete. train_loss = 22.254156640126155
Epoch [8/500] Batch[10600/12648] complete. train_loss = 22.254256875919847
Epoch [8/500] Batch[10800/12648] complete. train_loss = 22.25395915578913
Epoch [8/500] Batch[11000/12648] complete. train_loss = 22.25465949613398
Epoch [8/500] Batch[11200/12648] complete. train_loss = 22.25530829497746
Epoch [8/500] Batch[11400/12648] complete. train_loss = 22.253506573459557
Epoch [8/500] Batch[11600/12648] complete. train_loss = 22.252650022506714
Epoch [8/500] Batch[11800/12648] complete. train_loss = 22.252090530557147
Epoch [8/500] Batch[12000/12648] complete. train_loss = 22.251609665711722
Epoch [8/500] Batch[12200/12648] complete. train_loss = 22.251028507889295
Epoch [8/500] Batch[12400/12648] complete. train_loss = 22.249463217181543
Epoch [8/500] Batch[12600/12648] complete. train_loss = 22.249006193705966
Epoch [8/500] Batch[12648/12648] complete. valid_loss = 20.73674440383911
best models saved
Best Valid Loss = 20.73674440383911 (Epoch: 8)


Epoch [9/500] Batch[200/12648] complete. train_loss = 21.62669331550598
Epoch [9/500] Batch[400/12648] complete. train_loss = 21.610602955818177
Epoch [9/500] Batch[600/12648] complete. train_loss = 21.66834453900655
Epoch [9/500] Batch[800/12648] complete. train_loss = 21.6665371465683
Epoch [9/500] Batch[1000/12648] complete. train_loss = 21.675186685562135
Epoch [9/500] Batch[1200/12648] complete. train_loss = 21.676651496887207
Epoch [9/500] Batch[1400/12648] complete. train_loss = 21.687638634272982
Epoch [9/500] Batch[1600/12648] complete. train_loss = 21.69743079543114
Epoch [9/500] Batch[1800/12648] complete. train_loss = 21.691867738299898
Epoch [9/500] Batch[2000/12648] complete. train_loss = 21.69121997356415
Epoch [9/500] Batch[2200/12648] complete. train_loss = 21.699924858266655
Epoch [9/500] Batch[2400/12648] complete. train_loss = 21.698790730635324
Epoch [9/500] Batch[2600/12648] complete. train_loss = 21.70225204907931
Epoch [9/500] Batch[2800/12648] complete. train_loss = 21.710100878306797
Epoch [9/500] Batch[3000/12648] complete. train_loss = 21.71411282157898
Epoch [9/500] Batch[3200/12648] complete. train_loss = 21.712711404561997
Epoch [9/500] Batch[3400/12648] complete. train_loss = 21.713818704941694
Epoch [9/500] Batch[3600/12648] complete. train_loss = 21.72018462287055
Epoch [9/500] Batch[3800/12648] complete. train_loss = 21.724593048095702
Epoch [9/500] Batch[4000/12648] complete. train_loss = 21.72637470245361
Epoch [9/500] Batch[4200/12648] complete. train_loss = 21.729621992565338
Epoch [9/500] Batch[4400/12648] complete. train_loss = 21.72829976645383
Epoch [9/500] Batch[4600/12648] complete. train_loss = 21.736383933191714
Epoch [9/500] Batch[4800/12648] complete. train_loss = 21.74259526173274
Epoch [9/500] Batch[5000/12648] complete. train_loss = 21.74197211341858
Epoch [9/500] Batch[5200/12648] complete. train_loss = 21.745233044624328
Epoch [9/500] Batch[5400/12648] complete. train_loss = 21.75369239701165
Epoch [9/500] Batch[5600/12648] complete. train_loss = 21.756473976543973
Epoch [9/500] Batch[5800/12648] complete. train_loss = 21.759751258718556
Epoch [9/500] Batch[6000/12648] complete. train_loss = 21.76244840749105
Epoch [9/500] Batch[6200/12648] complete. train_loss = 21.767299410297024
Epoch [9/500] Batch[6400/12648] complete. train_loss = 21.7661681419611
Epoch [9/500] Batch[6600/12648] complete. train_loss = 21.767042928753476
Epoch [9/500] Batch[6800/12648] complete. train_loss = 21.76862477386699
Epoch [9/500] Batch[7000/12648] complete. train_loss = 21.770858956473216
Epoch [9/500] Batch[7200/12648] complete. train_loss = 21.771146208710142
Epoch [9/500] Batch[7400/12648] complete. train_loss = 21.773500456165625
Epoch [9/500] Batch[7600/12648] complete. train_loss = 21.774825722794784
Epoch [9/500] Batch[7800/12648] complete. train_loss = 21.774287045063115
Epoch [9/500] Batch[8000/12648] complete. train_loss = 21.77625110864639
Epoch [9/500] Batch[8200/12648] complete. train_loss = 21.778910107263705
Epoch [9/500] Batch[8400/12648] complete. train_loss = 21.77948582944416
Epoch [9/500] Batch[8600/12648] complete. train_loss = 21.782218707106836
Epoch [9/500] Batch[8800/12648] complete. train_loss = 21.783176164627076
Epoch [9/500] Batch[9000/12648] complete. train_loss = 21.785143610636393
Epoch [9/500] Batch[9200/12648] complete. train_loss = 21.788737081030142
Epoch [9/500] Batch[9400/12648] complete. train_loss = 21.791977655532513
Epoch [9/500] Batch[9600/12648] complete. train_loss = 21.793656410177547
Epoch [9/500] Batch[9800/12648] complete. train_loss = 21.79381028681385
Epoch [9/500] Batch[10000/12648] complete. train_loss = 21.795237456893922
Epoch [9/500] Batch[10200/12648] complete. train_loss = 21.79528517741783
Epoch [9/500] Batch[10400/12648] complete. train_loss = 21.797619583973518
Epoch [9/500] Batch[10600/12648] complete. train_loss = 21.79696162979558
Epoch [9/500] Batch[10800/12648] complete. train_loss = 21.797399491380762
Epoch [9/500] Batch[11000/12648] complete. train_loss = 21.797130302082408
Epoch [9/500] Batch[11200/12648] complete. train_loss = 21.801156603949412
Epoch [9/500] Batch[11400/12648] complete. train_loss = 21.801998331839577
Epoch [9/500] Batch[11600/12648] complete. train_loss = 21.802111752279874
Epoch [9/500] Batch[11800/12648] complete. train_loss = 21.801780053639817
Epoch [9/500] Batch[12000/12648] complete. train_loss = 21.80465279944738
Epoch [9/500] Batch[12200/12648] complete. train_loss = 21.804028688806003
Epoch [9/500] Batch[12400/12648] complete. train_loss = 21.80377928595389
Epoch [9/500] Batch[12600/12648] complete. train_loss = 21.80650783902123
Epoch [9/500] Batch[12648/12648] complete. valid_loss = 20.556344270706177
best models saved
Best Valid Loss = 20.556344270706177 (Epoch: 9)


Epoch [10/500] Batch[200/12648] complete. train_loss = 21.186809482574464
Epoch [10/500] Batch[400/12648] complete. train_loss = 21.16554190158844
Epoch [10/500] Batch[600/12648] complete. train_loss = 21.208998206456503
Epoch [10/500] Batch[800/12648] complete. train_loss = 21.21638778448105
Epoch [10/500] Batch[1000/12648] complete. train_loss = 21.221670597076415
Epoch [10/500] Batch[1200/12648] complete. train_loss = 21.232694045702615
Epoch [10/500] Batch[1400/12648] complete. train_loss = 21.245348646981377
Epoch [10/500] Batch[1600/12648] complete. train_loss = 21.25783040523529
Epoch [10/500] Batch[1800/12648] complete. train_loss = 21.27033167309231
Epoch [10/500] Batch[2000/12648] complete. train_loss = 21.27370516586304
Epoch [10/500] Batch[2200/12648] complete. train_loss = 21.294351884668522
Epoch [10/500] Batch[2400/12648] complete. train_loss = 21.29308797597885
Epoch [10/500] Batch[2600/12648] complete. train_loss = 21.301138406166665
Epoch [10/500] Batch[2800/12648] complete. train_loss = 21.30431834629604
Epoch [10/500] Batch[3000/12648] complete. train_loss = 21.308102078119912
Epoch [10/500] Batch[3200/12648] complete. train_loss = 21.31583014726639
Epoch [10/500] Batch[3400/12648] complete. train_loss = 21.32184610198526
Epoch [10/500] Batch[3600/12648] complete. train_loss = 21.321022214359708
Epoch [10/500] Batch[3800/12648] complete. train_loss = 21.33196760378386
Epoch [10/500] Batch[4000/12648] complete. train_loss = 21.335515518188476
Epoch [10/500] Batch[4200/12648] complete. train_loss = 21.336260160718645
Epoch [10/500] Batch[4400/12648] complete. train_loss = 21.338286116773432
Epoch [10/500] Batch[4600/12648] complete. train_loss = 21.343302249493806
Epoch [10/500] Batch[4800/12648] complete. train_loss = 21.34567449013392
Epoch [10/500] Batch[5000/12648] complete. train_loss = 21.350887368011474
Epoch [10/500] Batch[5200/12648] complete. train_loss = 21.349224972358115
Epoch [10/500] Batch[5400/12648] complete. train_loss = 21.351822474444354
Epoch [10/500] Batch[5600/12648] complete. train_loss = 21.354122047764914
Epoch [10/500] Batch[5800/12648] complete. train_loss = 21.355681940933753
Epoch [10/500] Batch[6000/12648] complete. train_loss = 21.3582943871816
Epoch [10/500] Batch[6200/12648] complete. train_loss = 21.359988608514108
Epoch [10/500] Batch[6400/12648] complete. train_loss = 21.36259687811136
Epoch [10/500] Batch[6600/12648] complete. train_loss = 21.364298817894674
Epoch [10/500] Batch[6800/12648] complete. train_loss = 21.368063265576083
Epoch [10/500] Batch[7000/12648] complete. train_loss = 21.372019193104336
Epoch [10/500] Batch[7200/12648] complete. train_loss = 21.375583583778806
Epoch [10/500] Batch[7400/12648] complete. train_loss = 21.37837999446972
Epoch [10/500] Batch[7600/12648] complete. train_loss = 21.383839790695593
Epoch [10/500] Batch[7800/12648] complete. train_loss = 21.385399545767367
Epoch [10/500] Batch[8000/12648] complete. train_loss = 21.389177844524383
Epoch [10/500] Batch[8200/12648] complete. train_loss = 21.391698531406682
Epoch [10/500] Batch[8400/12648] complete. train_loss = 21.395181539172217
Epoch [10/500] Batch[8600/12648] complete. train_loss = 21.396559381928554
Epoch [10/500] Batch[8800/12648] complete. train_loss = 21.398211035728455
Epoch [10/500] Batch[9000/12648] complete. train_loss = 21.400207547717624
Epoch [10/500] Batch[9200/12648] complete. train_loss = 21.402676021534464
Epoch [10/500] Batch[9400/12648] complete. train_loss = 21.40685393394308
Epoch [10/500] Batch[9600/12648] complete. train_loss = 21.40880368411541
Epoch [10/500] Batch[9800/12648] complete. train_loss = 21.41136209040272
Epoch [10/500] Batch[10000/12648] complete. train_loss = 21.413712322998048
Epoch [10/500] Batch[10200/12648] complete. train_loss = 21.415321222380097
Epoch [10/500] Batch[10400/12648] complete. train_loss = 21.41931128556912
Epoch [10/500] Batch[10600/12648] complete. train_loss = 21.421401244469408
Epoch [10/500] Batch[10800/12648] complete. train_loss = 21.42337546154305
Epoch [10/500] Batch[11000/12648] complete. train_loss = 21.42492292473533
Epoch [10/500] Batch[11200/12648] complete. train_loss = 21.426085673230034
Epoch [10/500] Batch[11400/12648] complete. train_loss = 21.428572502805476
Epoch [10/500] Batch[11600/12648] complete. train_loss = 21.431206822395325
Epoch [10/500] Batch[11800/12648] complete. train_loss = 21.43170359142756
Epoch [10/500] Batch[12000/12648] complete. train_loss = 21.432721423467
Epoch [10/500] Batch[12200/12648] complete. train_loss = 21.433542895707927
Epoch [10/500] Batch[12400/12648] complete. train_loss = 21.436524263505014
Epoch [10/500] Batch[12600/12648] complete. train_loss = 21.437257450345964
Epoch [10/500] Batch[12648/12648] complete. valid_loss = 20.368171453475952
best models saved
Best Valid Loss = 20.368171453475952 (Epoch: 10)


Epoch [11/500] Batch[200/12648] complete. train_loss = 20.929466743469238
Epoch [11/500] Batch[400/12648] complete. train_loss = 20.86296322822571
Epoch [11/500] Batch[600/12648] complete. train_loss = 20.85955061276754
Epoch [11/500] Batch[800/12648] complete. train_loss = 20.890294034481048
Epoch [11/500] Batch[1000/12648] complete. train_loss = 20.911665393829345
Epoch [11/500] Batch[1200/12648] complete. train_loss = 20.91163901646932
Epoch [11/500] Batch[1400/12648] complete. train_loss = 20.91560714312962
Epoch [11/500] Batch[1600/12648] complete. train_loss = 20.924571669101717
Epoch [11/500] Batch[1800/12648] complete. train_loss = 20.918839388953316
Epoch [11/500] Batch[2000/12648] complete. train_loss = 20.930042149543763
Epoch [11/500] Batch[2200/12648] complete. train_loss = 20.934021460793236
Epoch [11/500] Batch[2400/12648] complete. train_loss = 20.929816143512724
Epoch [11/500] Batch[2600/12648] complete. train_loss = 20.942213103221015
Epoch [11/500] Batch[2800/12648] complete. train_loss = 20.944255259377616
Epoch [11/500] Batch[3000/12648] complete. train_loss = 20.952624914805096
Epoch [11/500] Batch[3200/12648] complete. train_loss = 20.960710886120797
Epoch [11/500] Batch[3400/12648] complete. train_loss = 20.970730576234704
Epoch [11/500] Batch[3600/12648] complete. train_loss = 20.98050280994839
Epoch [11/500] Batch[3800/12648] complete. train_loss = 20.99134601643211
Epoch [11/500] Batch[4000/12648] complete. train_loss = 20.9972369351387
Epoch [11/500] Batch[4200/12648] complete. train_loss = 20.998526407877605
Epoch [11/500] Batch[4400/12648] complete. train_loss = 21.00289569594643
Epoch [11/500] Batch[4600/12648] complete. train_loss = 21.00652046493862
Epoch [11/500] Batch[4800/12648] complete. train_loss = 21.01131579120954
Epoch [11/500] Batch[5000/12648] complete. train_loss = 21.01370489463806
Epoch [11/500] Batch[5200/12648] complete. train_loss = 21.019406045766978
Epoch [11/500] Batch[5400/12648] complete. train_loss = 21.02502387435348
Epoch [11/500] Batch[5600/12648] complete. train_loss = 21.027729866504668
Epoch [11/500] Batch[5800/12648] complete. train_loss = 21.028792356293778
Epoch [11/500] Batch[6000/12648] complete. train_loss = 21.03232184537252
Epoch [11/500] Batch[6200/12648] complete. train_loss = 21.036460432237195
Epoch [11/500] Batch[6400/12648] complete. train_loss = 21.03647190839052
Epoch [11/500] Batch[6600/12648] complete. train_loss = 21.040480946338537
Epoch [11/500] Batch[6800/12648] complete. train_loss = 21.04284015599419
Epoch [11/500] Batch[7000/12648] complete. train_loss = 21.046338329042708
Epoch [11/500] Batch[7200/12648] complete. train_loss = 21.04932052956687
Epoch [11/500] Batch[7400/12648] complete. train_loss = 21.05281875197952
Epoch [11/500] Batch[7600/12648] complete. train_loss = 21.054637301595587
Epoch [11/500] Batch[7800/12648] complete. train_loss = 21.059114072995307
Epoch [11/500] Batch[8000/12648] complete. train_loss = 21.062545442581175
Epoch [11/500] Batch[8200/12648] complete. train_loss = 21.066619473434077
Epoch [11/500] Batch[8400/12648] complete. train_loss = 21.06770611354283
Epoch [11/500] Batch[8600/12648] complete. train_loss = 21.071136415836424
Epoch [11/500] Batch[8800/12648] complete. train_loss = 21.073826708576895
Epoch [11/500] Batch[9000/12648] complete. train_loss = 21.0745977651808
Epoch [11/500] Batch[9200/12648] complete. train_loss = 21.07648614137069
Epoch [11/500] Batch[9400/12648] complete. train_loss = 21.079084541239638
Epoch [11/500] Batch[9600/12648] complete. train_loss = 21.080553907553355
Epoch [11/500] Batch[9800/12648] complete. train_loss = 21.082621737694254
Epoch [11/500] Batch[10000/12648] complete. train_loss = 21.08452495136261
Epoch [11/500] Batch[10200/12648] complete. train_loss = 21.087597128737208
Epoch [11/500] Batch[10400/12648] complete. train_loss = 21.08909547494008
Epoch [11/500] Batch[10600/12648] complete. train_loss = 21.09275559569305
Epoch [11/500] Batch[10800/12648] complete. train_loss = 21.095992610896076
Epoch [11/500] Batch[11000/12648] complete. train_loss = 21.099434639497236
Epoch [11/500] Batch[11200/12648] complete. train_loss = 21.10356179203306
Epoch [11/500] Batch[11400/12648] complete. train_loss = 21.10553722666021
Epoch [11/500] Batch[11600/12648] complete. train_loss = 21.10714600908345
Epoch [11/500] Batch[11800/12648] complete. train_loss = 21.108990696890878
Epoch [11/500] Batch[12000/12648] complete. train_loss = 21.112035997072855
Epoch [11/500] Batch[12200/12648] complete. train_loss = 21.113483835751893
Epoch [11/500] Batch[12400/12648] complete. train_loss = 21.11562421737179
Epoch [11/500] Batch[12600/12648] complete. train_loss = 21.117298324373035
Epoch [11/500] Batch[12648/12648] complete. valid_loss = 20.209299087524414
best models saved
Best Valid Loss = 20.209299087524414 (Epoch: 11)


Epoch [12/500] Batch[200/12648] complete. train_loss = 20.6738537979126
Epoch [12/500] Batch[400/12648] complete. train_loss = 20.621819167137147
Epoch [12/500] Batch[600/12648] complete. train_loss = 20.645720596313478
Epoch [12/500] Batch[800/12648] complete. train_loss = 20.636892018318175
Epoch [12/500] Batch[1000/12648] complete. train_loss = 20.635059072494506
Epoch [12/500] Batch[1200/12648] complete. train_loss = 20.632446497281393
Epoch [12/500] Batch[1400/12648] complete. train_loss = 20.64439586230687
Epoch [12/500] Batch[1600/12648] complete. train_loss = 20.631410007476806
Epoch [12/500] Batch[1800/12648] complete. train_loss = 20.63757819387648
Epoch [12/500] Batch[2000/12648] complete. train_loss = 20.647212447166442
Epoch [12/500] Batch[2200/12648] complete. train_loss = 20.653324759223246
Epoch [12/500] Batch[2400/12648] complete. train_loss = 20.66082891702652
Epoch [12/500] Batch[2600/12648] complete. train_loss = 20.659333852621224
Epoch [12/500] Batch[2800/12648] complete. train_loss = 20.668049307550703
Epoch [12/500] Batch[3000/12648] complete. train_loss = 20.678035588582357
Epoch [12/500] Batch[3200/12648] complete. train_loss = 20.682792368531228
Epoch [12/500] Batch[3400/12648] complete. train_loss = 20.688528964659746
Epoch [12/500] Batch[3600/12648] complete. train_loss = 20.693474340968663
Epoch [12/500] Batch[3800/12648] complete. train_loss = 20.695545227151168
Epoch [12/500] Batch[4000/12648] complete. train_loss = 20.698982511997222
Epoch [12/500] Batch[4200/12648] complete. train_loss = 20.705483552387783
Epoch [12/500] Batch[4400/12648] complete. train_loss = 20.714788935401224
Epoch [12/500] Batch[4600/12648] complete. train_loss = 20.722038235042405
Epoch [12/500] Batch[4800/12648] complete. train_loss = 20.726777535676955
Epoch [12/500] Batch[5000/12648] complete. train_loss = 20.72959556427002
Epoch [12/500] Batch[5200/12648] complete. train_loss = 20.734518208870522
Epoch [12/500] Batch[5400/12648] complete. train_loss = 20.74085937252751
Epoch [12/500] Batch[5600/12648] complete. train_loss = 20.743971650600432
Epoch [12/500] Batch[5800/12648] complete. train_loss = 20.746851276529245
Epoch [12/500] Batch[6000/12648] complete. train_loss = 20.750567584037782
Epoch [12/500] Batch[6200/12648] complete. train_loss = 20.755446466938142
Epoch [12/500] Batch[6400/12648] complete. train_loss = 20.757526817023756
Epoch [12/500] Batch[6600/12648] complete. train_loss = 20.761528769406404
Epoch [12/500] Batch[6800/12648] complete. train_loss = 20.765881674710442
Epoch [12/500] Batch[7000/12648] complete. train_loss = 20.77084821537563
Epoch [12/500] Batch[7200/12648] complete. train_loss = 20.773999455240038
Epoch [12/500] Batch[7400/12648] complete. train_loss = 20.775374053491127
Epoch [12/500] Batch[7600/12648] complete. train_loss = 20.776934985863534
Epoch [12/500] Batch[7800/12648] complete. train_loss = 20.780768935863787
Epoch [12/500] Batch[8000/12648] complete. train_loss = 20.783867556810378
Epoch [12/500] Batch[8200/12648] complete. train_loss = 20.787927679899262
Epoch [12/500] Batch[8400/12648] complete. train_loss = 20.790857426098416
Epoch [12/500] Batch[8600/12648] complete. train_loss = 20.79400657432024
Epoch [12/500] Batch[8800/12648] complete. train_loss = 20.79742833289233
Epoch [12/500] Batch[9000/12648] complete. train_loss = 20.799665684170193
Epoch [12/500] Batch[9200/12648] complete. train_loss = 20.80064506157585
Epoch [12/500] Batch[9400/12648] complete. train_loss = 20.805030605437906
Epoch [12/500] Batch[9600/12648] complete. train_loss = 20.806656662623087
Epoch [12/500] Batch[9800/12648] complete. train_loss = 20.809155666974124
Epoch [12/500] Batch[10000/12648] complete. train_loss = 20.81055115737915
Epoch [12/500] Batch[10200/12648] complete. train_loss = 20.813167290968053
Epoch [12/500] Batch[10400/12648] complete. train_loss = 20.81479582621501
Epoch [12/500] Batch[10600/12648] complete. train_loss = 20.817751573346698
Epoch [12/500] Batch[10800/12648] complete. train_loss = 20.819849940052737
Epoch [12/500] Batch[11000/12648] complete. train_loss = 20.82156387970664
Epoch [12/500] Batch[11200/12648] complete. train_loss = 20.823009926080704
Epoch [12/500] Batch[11400/12648] complete. train_loss = 20.826572893376937
Epoch [12/500] Batch[11600/12648] complete. train_loss = 20.830145192475154
Epoch [12/500] Batch[11800/12648] complete. train_loss = 20.830319594367076
Epoch [12/500] Batch[12000/12648] complete. train_loss = 20.83268728876114
Epoch [12/500] Batch[12200/12648] complete. train_loss = 20.834468301866874
Epoch [12/500] Batch[12400/12648] complete. train_loss = 20.836179486243957
Epoch [12/500] Batch[12600/12648] complete. train_loss = 20.83753529064239
Epoch [12/500] Batch[12648/12648] complete. valid_loss = 20.14050602912903
best models saved
Best Valid Loss = 20.14050602912903 (Epoch: 12)


Epoch [13/500] Batch[200/12648] complete. train_loss = 20.246855974197388
Epoch [13/500] Batch[400/12648] complete. train_loss = 20.318155727386475
Epoch [13/500] Batch[600/12648] complete. train_loss = 20.340274457931518
Epoch [13/500] Batch[800/12648] complete. train_loss = 20.349583365917205
Epoch [13/500] Batch[1000/12648] complete. train_loss = 20.350429777145386
Epoch [13/500] Batch[1200/12648] complete. train_loss = 20.356469292640686
Epoch [13/500] Batch[1400/12648] complete. train_loss = 20.36244510786874
Epoch [13/500] Batch[1600/12648] complete. train_loss = 20.37091203212738
Epoch [13/500] Batch[1800/12648] complete. train_loss = 20.377783121532865
Epoch [13/500] Batch[2000/12648] complete. train_loss = 20.378796288490296
Epoch [13/500] Batch[2200/12648] complete. train_loss = 20.38512510993264
Epoch [13/500] Batch[2400/12648] complete. train_loss = 20.393789152304333
Epoch [13/500] Batch[2600/12648] complete. train_loss = 20.39641621222863
Epoch [13/500] Batch[2800/12648] complete. train_loss = 20.40116524423872
Epoch [13/500] Batch[3000/12648] complete. train_loss = 20.412722359339398
Epoch [13/500] Batch[3200/12648] complete. train_loss = 20.419488612413407
Epoch [13/500] Batch[3400/12648] complete. train_loss = 20.42345891896416
Epoch [13/500] Batch[3600/12648] complete. train_loss = 20.436322980456882
Epoch [13/500] Batch[3800/12648] complete. train_loss = 20.445749749133462
Epoch [13/500] Batch[4000/12648] complete. train_loss = 20.445325781822206
Epoch [13/500] Batch[4200/12648] complete. train_loss = 20.44872949100676
Epoch [13/500] Batch[4400/12648] complete. train_loss = 20.450230882818047
Epoch [13/500] Batch[4600/12648] complete. train_loss = 20.450343734077784
Epoch [13/500] Batch[4800/12648] complete. train_loss = 20.456280363400776
Epoch [13/500] Batch[5000/12648] complete. train_loss = 20.462878580856323
Epoch [13/500] Batch[5200/12648] complete. train_loss = 20.469421483553372
Epoch [13/500] Batch[5400/12648] complete. train_loss = 20.47279885503981
Epoch [13/500] Batch[5600/12648] complete. train_loss = 20.47669173853738
Epoch [13/500] Batch[5800/12648] complete. train_loss = 20.48321741728947
Epoch [13/500] Batch[6000/12648] complete. train_loss = 20.487325923919677
Epoch [13/500] Batch[6200/12648] complete. train_loss = 20.492614553513064
Epoch [13/500] Batch[6400/12648] complete. train_loss = 20.49751102656126
Epoch [13/500] Batch[6600/12648] complete. train_loss = 20.498431264414933
Epoch [13/500] Batch[6800/12648] complete. train_loss = 20.504136617323933
Epoch [13/500] Batch[7000/12648] complete. train_loss = 20.51105850819179
Epoch [13/500] Batch[7200/12648] complete. train_loss = 20.511672398514218
Epoch [13/500] Batch[7400/12648] complete. train_loss = 20.51615791295026
Epoch [13/500] Batch[7600/12648] complete. train_loss = 20.51756325797031
Epoch [13/500] Batch[7800/12648] complete. train_loss = 20.52051952410967
Epoch [13/500] Batch[8000/12648] complete. train_loss = 20.52605566453934
Epoch [13/500] Batch[8200/12648] complete. train_loss = 20.52980435836606
Epoch [13/500] Batch[8400/12648] complete. train_loss = 20.532532055945623
Epoch [13/500] Batch[8600/12648] complete. train_loss = 20.535423988519714
Epoch [13/500] Batch[8800/12648] complete. train_loss = 20.53758010495793
Epoch [13/500] Batch[9000/12648] complete. train_loss = 20.540272117614744
Epoch [13/500] Batch[9200/12648] complete. train_loss = 20.54176461758821
Epoch [13/500] Batch[9400/12648] complete. train_loss = 20.54496569613193
Epoch [13/500] Batch[9600/12648] complete. train_loss = 20.54778067668279
Epoch [13/500] Batch[9800/12648] complete. train_loss = 20.55167438273527
Epoch [13/500] Batch[10000/12648] complete. train_loss = 20.55443817882538
Epoch [13/500] Batch[10200/12648] complete. train_loss = 20.556993209053488
Epoch [13/500] Batch[10400/12648] complete. train_loss = 20.56036429460232
Epoch [13/500] Batch[10600/12648] complete. train_loss = 20.563525455942695
Epoch [13/500] Batch[10800/12648] complete. train_loss = 20.56498289655756
Epoch [13/500] Batch[11000/12648] complete. train_loss = 20.56826651798595
Epoch [13/500] Batch[11200/12648] complete. train_loss = 20.56926386816161
Epoch [13/500] Batch[11400/12648] complete. train_loss = 20.572768863711442
Epoch [13/500] Batch[11600/12648] complete. train_loss = 20.575589734603618
Epoch [13/500] Batch[11800/12648] complete. train_loss = 20.5775503800279
Epoch [13/500] Batch[12000/12648] complete. train_loss = 20.58043843348821
Epoch [13/500] Batch[12200/12648] complete. train_loss = 20.58239046112436
Epoch [13/500] Batch[12400/12648] complete. train_loss = 20.585811959697356
Epoch [13/500] Batch[12600/12648] complete. train_loss = 20.588354333998666
Epoch [13/500] Batch[12648/12648] complete. valid_loss = 20.042213678359985
best models saved
Best Valid Loss = 20.042213678359985 (Epoch: 13)


Epoch [14/500] Batch[200/12648] complete. train_loss = 20.11804461479187
Epoch [14/500] Batch[400/12648] complete. train_loss = 20.088229660987853
Epoch [14/500] Batch[600/12648] complete. train_loss = 20.114896987279256
Epoch [14/500] Batch[800/12648] complete. train_loss = 20.126749289035796
Epoch [14/500] Batch[1000/12648] complete. train_loss = 20.130829320907594
Epoch [14/500] Batch[1200/12648] complete. train_loss = 20.142702085177103
Epoch [14/500] Batch[1400/12648] complete. train_loss = 20.15189505985805
Epoch [14/500] Batch[1600/12648] complete. train_loss = 20.159730851650238
Epoch [14/500] Batch[1800/12648] complete. train_loss = 20.15443506558736
Epoch [14/500] Batch[2000/12648] complete. train_loss = 20.16050054550171
Epoch [14/500] Batch[2200/12648] complete. train_loss = 20.16118720141324
Epoch [14/500] Batch[2400/12648] complete. train_loss = 20.170946536064147
Epoch [14/500] Batch[2600/12648] complete. train_loss = 20.174395399827223
Epoch [14/500] Batch[2800/12648] complete. train_loss = 20.18328734942845
Epoch [14/500] Batch[3000/12648] complete. train_loss = 20.1870093015035
Epoch [14/500] Batch[3200/12648] complete. train_loss = 20.19024164021015
Epoch [14/500] Batch[3400/12648] complete. train_loss = 20.191216759401208
Epoch [14/500] Batch[3600/12648] complete. train_loss = 20.195381518999735
Epoch [14/500] Batch[3800/12648] complete. train_loss = 20.19897576834026
Epoch [14/500] Batch[4000/12648] complete. train_loss = 20.204526996135712
Epoch [14/500] Batch[4200/12648] complete. train_loss = 20.208053082057408
Epoch [14/500] Batch[4400/12648] complete. train_loss = 20.213987708091736
Epoch [14/500] Batch[4600/12648] complete. train_loss = 20.215219062722248
Epoch [14/500] Batch[4800/12648] complete. train_loss = 20.22395149588585
Epoch [14/500] Batch[5000/12648] complete. train_loss = 20.2276016582489
Epoch [14/500] Batch[5200/12648] complete. train_loss = 20.231102742782006
Epoch [14/500] Batch[5400/12648] complete. train_loss = 20.234849079273364
Epoch [14/500] Batch[5600/12648] complete. train_loss = 20.244002679075514
Epoch [14/500] Batch[5800/12648] complete. train_loss = 20.250736802857496
Epoch [14/500] Batch[6000/12648] complete. train_loss = 20.25908502737681
Epoch [14/500] Batch[6200/12648] complete. train_loss = 20.261779514743434
Epoch [14/500] Batch[6400/12648] complete. train_loss = 20.266138369739057
Epoch [14/500] Batch[6600/12648] complete. train_loss = 20.268056612881747
Epoch [14/500] Batch[6800/12648] complete. train_loss = 20.272692524124594
Epoch [14/500] Batch[7000/12648] complete. train_loss = 20.279890697751725
Epoch [14/500] Batch[7200/12648] complete. train_loss = 20.283887072139315
Epoch [14/500] Batch[7400/12648] complete. train_loss = 20.288469285191717
Epoch [14/500] Batch[7600/12648] complete. train_loss = 20.290915752963016
Epoch [14/500] Batch[7800/12648] complete. train_loss = 20.293578689770822
Epoch [14/500] Batch[8000/12648] complete. train_loss = 20.295888179779052
Epoch [14/500] Batch[8200/12648] complete. train_loss = 20.300259112613958
Epoch [14/500] Batch[8400/12648] complete. train_loss = 20.30233193102337
Epoch [14/500] Batch[8600/12648] complete. train_loss = 20.304574469189312
Epoch [14/500] Batch[8800/12648] complete. train_loss = 20.307250827009028
Epoch [14/500] Batch[9000/12648] complete. train_loss = 20.30868228615655
Epoch [14/500] Batch[9200/12648] complete. train_loss = 20.314622165223827
Epoch [14/500] Batch[9400/12648] complete. train_loss = 20.316230452923065
Epoch [14/500] Batch[9600/12648] complete. train_loss = 20.3182059297959
Epoch [14/500] Batch[9800/12648] complete. train_loss = 20.32206560777158
Epoch [14/500] Batch[10000/12648] complete. train_loss = 20.324878453826905
Epoch [14/500] Batch[10200/12648] complete. train_loss = 20.328992523305555
Epoch [14/500] Batch[10400/12648] complete. train_loss = 20.33170489329558
Epoch [14/500] Batch[10600/12648] complete. train_loss = 20.33488237309006
Epoch [14/500] Batch[10800/12648] complete. train_loss = 20.33922681366956
Epoch [14/500] Batch[11000/12648] complete. train_loss = 20.341583448410034
Epoch [14/500] Batch[11200/12648] complete. train_loss = 20.345366040638513
Epoch [14/500] Batch[11400/12648] complete. train_loss = 20.347998284624335
Epoch [14/500] Batch[11600/12648] complete. train_loss = 20.351628865537972
Epoch [14/500] Batch[11800/12648] complete. train_loss = 20.35347856246819
Epoch [14/500] Batch[12000/12648] complete. train_loss = 20.35664961798986
Epoch [14/500] Batch[12200/12648] complete. train_loss = 20.3600472589399
Epoch [14/500] Batch[12400/12648] complete. train_loss = 20.362952592603623
Epoch [14/500] Batch[12600/12648] complete. train_loss = 20.365744653429303
Epoch [14/500] Batch[12648/12648] complete. valid_loss = 19.918834924697876
best models saved
Best Valid Loss = 19.918834924697876 (Epoch: 14)


Epoch [15/500] Batch[200/12648] complete. train_loss = 19.787373123168944
Epoch [15/500] Batch[400/12648] complete. train_loss = 19.85825876235962
Epoch [15/500] Batch[600/12648] complete. train_loss = 19.870415134429933
Epoch [15/500] Batch[800/12648] complete. train_loss = 19.884604742527006
Epoch [15/500] Batch[1000/12648] complete. train_loss = 19.898432006835936
Epoch [15/500] Batch[1200/12648] complete. train_loss = 19.90417261282603
Epoch [15/500] Batch[1400/12648] complete. train_loss = 19.908414591380527
Epoch [15/500] Batch[1600/12648] complete. train_loss = 19.9141885137558
Epoch [15/500] Batch[1800/12648] complete. train_loss = 19.92408062087165
Epoch [15/500] Batch[2000/12648] complete. train_loss = 19.929790406227113
Epoch [15/500] Batch[2200/12648] complete. train_loss = 19.93865337198431
Epoch [15/500] Batch[2400/12648] complete. train_loss = 19.949505296548207
Epoch [15/500] Batch[2600/12648] complete. train_loss = 19.956922877385065
Epoch [15/500] Batch[2800/12648] complete. train_loss = 19.963060658318657
Epoch [15/500] Batch[3000/12648] complete. train_loss = 19.966040225346884
Epoch [15/500] Batch[3200/12648] complete. train_loss = 19.971314908266066
Epoch [15/500] Batch[3400/12648] complete. train_loss = 19.9768085418028
Epoch [15/500] Batch[3600/12648] complete. train_loss = 19.98256270090739
Epoch [15/500] Batch[3800/12648] complete. train_loss = 19.997169565401578
Epoch [15/500] Batch[4000/12648] complete. train_loss = 20.000938686847686
Epoch [15/500] Batch[4200/12648] complete. train_loss = 20.003613443828765
Epoch [15/500] Batch[4400/12648] complete. train_loss = 20.00364740675146
Epoch [15/500] Batch[4600/12648] complete. train_loss = 20.00645149189493
Epoch [15/500] Batch[4800/12648] complete. train_loss = 20.011863888104756
Epoch [15/500] Batch[5000/12648] complete. train_loss = 20.016295960235595
Epoch [15/500] Batch[5200/12648] complete. train_loss = 20.021623101234436
Epoch [15/500] Batch[5400/12648] complete. train_loss = 20.031736433594315
Epoch [15/500] Batch[5600/12648] complete. train_loss = 20.036258972031728
Epoch [15/500] Batch[5800/12648] complete. train_loss = 20.037126149802372
Epoch [15/500] Batch[6000/12648] complete. train_loss = 20.04393979549408
Epoch [15/500] Batch[6200/12648] complete. train_loss = 20.046619615247174
Epoch [15/500] Batch[6400/12648] complete. train_loss = 20.05219211369753
Epoch [15/500] Batch[6600/12648] complete. train_loss = 20.055899767442185
Epoch [15/500] Batch[6800/12648] complete. train_loss = 20.060698237699622
Epoch [15/500] Batch[7000/12648] complete. train_loss = 20.063443704332624
Epoch [15/500] Batch[7200/12648] complete. train_loss = 20.071777041223314
Epoch [15/500] Batch[7400/12648] complete. train_loss = 20.07592385807553
Epoch [15/500] Batch[7600/12648] complete. train_loss = 20.081177040652225
Epoch [15/500] Batch[7800/12648] complete. train_loss = 20.085759340432976
Epoch [15/500] Batch[8000/12648] complete. train_loss = 20.08626883816719
Epoch [15/500] Batch[8200/12648] complete. train_loss = 20.090513115627008
Epoch [15/500] Batch[8400/12648] complete. train_loss = 20.09665544646127
Epoch [15/500] Batch[8600/12648] complete. train_loss = 20.100520043262215
Epoch [15/500] Batch[8800/12648] complete. train_loss = 20.103376163569365
Epoch [15/500] Batch[9000/12648] complete. train_loss = 20.10802405251397
Epoch [15/500] Batch[9200/12648] complete. train_loss = 20.115105801250625
Epoch [15/500] Batch[9400/12648] complete. train_loss = 20.11749953067049
Epoch [15/500] Batch[9600/12648] complete. train_loss = 20.120339112480483
Epoch [15/500] Batch[9800/12648] complete. train_loss = 20.125238513168025
Epoch [15/500] Batch[10000/12648] complete. train_loss = 20.128851995658874
Epoch [15/500] Batch[10200/12648] complete. train_loss = 20.13240416769888
Epoch [15/500] Batch[10400/12648] complete. train_loss = 20.133789383998284
Epoch [15/500] Batch[10600/12648] complete. train_loss = 20.138151389247966
Epoch [15/500] Batch[10800/12648] complete. train_loss = 20.142380296212657
Epoch [15/500] Batch[11000/12648] complete. train_loss = 20.14435752660578
Epoch [15/500] Batch[11200/12648] complete. train_loss = 20.147712826388222
Epoch [15/500] Batch[11400/12648] complete. train_loss = 20.150003163019814
Epoch [15/500] Batch[11600/12648] complete. train_loss = 20.152012706460624
Epoch [15/500] Batch[11800/12648] complete. train_loss = 20.154077649520616
Epoch [15/500] Batch[12000/12648] complete. train_loss = 20.15560273504257
Epoch [15/500] Batch[12200/12648] complete. train_loss = 20.159459045910445
Epoch [15/500] Batch[12400/12648] complete. train_loss = 20.160015718552373
Epoch [15/500] Batch[12600/12648] complete. train_loss = 20.164741034734817
Epoch [15/500] Batch[12648/12648] complete. valid_loss = 19.843815326690674
best models saved
Best Valid Loss = 19.843815326690674 (Epoch: 15)


Epoch [16/500] Batch[200/12648] complete. train_loss = 19.69502010345459
Epoch [16/500] Batch[400/12648] complete. train_loss = 19.666090502738953
Epoch [16/500] Batch[600/12648] complete. train_loss = 19.696900164286294
Epoch [16/500] Batch[800/12648] complete. train_loss = 19.688198778629303
Epoch [16/500] Batch[1000/12648] complete. train_loss = 19.71472485923767
Epoch [16/500] Batch[1200/12648] complete. train_loss = 19.717720410029095
Epoch [16/500] Batch[1400/12648] complete. train_loss = 19.71878358568464
Epoch [16/500] Batch[1600/12648] complete. train_loss = 19.7260675740242
Epoch [16/500] Batch[1800/12648] complete. train_loss = 19.730744140413073
Epoch [16/500] Batch[2000/12648] complete. train_loss = 19.734858289718627
Epoch [16/500] Batch[2200/12648] complete. train_loss = 19.74032338662581
Epoch [16/500] Batch[2400/12648] complete. train_loss = 19.742957243919374
Epoch [16/500] Batch[2600/12648] complete. train_loss = 19.751090211868288
Epoch [16/500] Batch[2800/12648] complete. train_loss = 19.760513412611825
Epoch [16/500] Batch[3000/12648] complete. train_loss = 19.767797557195028
Epoch [16/500] Batch[3200/12648] complete. train_loss = 19.773297815322877
Epoch [16/500] Batch[3400/12648] complete. train_loss = 19.785506706237793
Epoch [16/500] Batch[3600/12648] complete. train_loss = 19.796068007151288
Epoch [16/500] Batch[3800/12648] complete. train_loss = 19.8039545310171
Epoch [16/500] Batch[4000/12648] complete. train_loss = 19.813019886016846
Epoch [16/500] Batch[4200/12648] complete. train_loss = 19.816733867100307
Epoch [16/500] Batch[4400/12648] complete. train_loss = 19.819591580737722
Epoch [16/500] Batch[4600/12648] complete. train_loss = 19.824677353734554
Epoch [16/500] Batch[4800/12648] complete. train_loss = 19.83133325854937
Epoch [16/500] Batch[5000/12648] complete. train_loss = 19.838337827301025
Epoch [16/500] Batch[5200/12648] complete. train_loss = 19.84742802986732
Epoch [16/500] Batch[5400/12648] complete. train_loss = 19.852447809643216
Epoch [16/500] Batch[5600/12648] complete. train_loss = 19.858929725033896
Epoch [16/500] Batch[5800/12648] complete. train_loss = 19.86479444799752
Epoch [16/500] Batch[6000/12648] complete. train_loss = 19.87504522514343
Epoch [16/500] Batch[6200/12648] complete. train_loss = 19.878258487024613
Epoch [16/500] Batch[6400/12648] complete. train_loss = 19.87987994134426
Epoch [16/500] Batch[6600/12648] complete. train_loss = 19.881796814311635
Epoch [16/500] Batch[6800/12648] complete. train_loss = 19.884992333860957
Epoch [16/500] Batch[7000/12648] complete. train_loss = 19.8875925012316
Epoch [16/500] Batch[7200/12648] complete. train_loss = 19.889097095595467
Epoch [16/500] Batch[7400/12648] complete. train_loss = 19.88909146257349
Epoch [16/500] Batch[7600/12648] complete. train_loss = 19.892724569973193
Epoch [16/500] Batch[7800/12648] complete. train_loss = 19.89798823038737
Epoch [16/500] Batch[8000/12648] complete. train_loss = 19.90319057226181
Epoch [16/500] Batch[8200/12648] complete. train_loss = 19.905894012683774
Epoch [16/500] Batch[8400/12648] complete. train_loss = 19.909299882480077
Epoch [16/500] Batch[8600/12648] complete. train_loss = 19.917092044963393
Epoch [16/500] Batch[8800/12648] complete. train_loss = 19.923207367550244
Epoch [16/500] Batch[9000/12648] complete. train_loss = 19.92969412231445
Epoch [16/500] Batch[9200/12648] complete. train_loss = 19.932145005516382
Epoch [16/500] Batch[9400/12648] complete. train_loss = 19.935047773807607
Epoch [16/500] Batch[9600/12648] complete. train_loss = 19.93791181822618
Epoch [16/500] Batch[9800/12648] complete. train_loss = 19.940514061013047
Epoch [16/500] Batch[10000/12648] complete. train_loss = 19.942864977645876
Epoch [16/500] Batch[10200/12648] complete. train_loss = 19.945461257859773
Epoch [16/500] Batch[10400/12648] complete. train_loss = 19.948860631355874
Epoch [16/500] Batch[10600/12648] complete. train_loss = 19.951680211840934
Epoch [16/500] Batch[10800/12648] complete. train_loss = 19.95498075803121
Epoch [16/500] Batch[11000/12648] complete. train_loss = 19.957617809989234
Epoch [16/500] Batch[11200/12648] complete. train_loss = 19.96100518294743
Epoch [16/500] Batch[11400/12648] complete. train_loss = 19.963926947075024
Epoch [16/500] Batch[11600/12648] complete. train_loss = 19.96767419650637
Epoch [16/500] Batch[11800/12648] complete. train_loss = 19.97140537213471
Epoch [16/500] Batch[12000/12648] complete. train_loss = 19.973169997533162
Epoch [16/500] Batch[12200/12648] complete. train_loss = 19.976862787965867
Epoch [16/500] Batch[12400/12648] complete. train_loss = 19.98014482713515
Epoch [16/500] Batch[12600/12648] complete. train_loss = 19.983660153888522
Epoch [16/500] Batch[12648/12648] complete. valid_loss = 19.82003140449524
best models saved
Best Valid Loss = 19.82003140449524 (Epoch: 16)


Epoch [17/500] Batch[200/12648] complete. train_loss = 19.421994981765746
Epoch [17/500] Batch[400/12648] complete. train_loss = 19.43919945716858
Epoch [17/500] Batch[600/12648] complete. train_loss = 19.45284040768941
Epoch [17/500] Batch[800/12648] complete. train_loss = 19.46131677865982
Epoch [17/500] Batch[1000/12648] complete. train_loss = 19.483872539520263
Epoch [17/500] Batch[1200/12648] complete. train_loss = 19.504683753649395
Epoch [17/500] Batch[1400/12648] complete. train_loss = 19.522757674625943
Epoch [17/500] Batch[1600/12648] complete. train_loss = 19.528066487312316
Epoch [17/500] Batch[1800/12648] complete. train_loss = 19.537157198588055
Epoch [17/500] Batch[2000/12648] complete. train_loss = 19.552513030052186
Epoch [17/500] Batch[2200/12648] complete. train_loss = 19.559173643805764
Epoch [17/500] Batch[2400/12648] complete. train_loss = 19.577539417743683
Epoch [17/500] Batch[2600/12648] complete. train_loss = 19.581805684749895
Epoch [17/500] Batch[2800/12648] complete. train_loss = 19.584266287258693
Epoch [17/500] Batch[3000/12648] complete. train_loss = 19.588898178100585
Epoch [17/500] Batch[3200/12648] complete. train_loss = 19.59683403134346
Epoch [17/500] Batch[3400/12648] complete. train_loss = 19.60958479039809
Epoch [17/500] Batch[3600/12648] complete. train_loss = 19.61677947998047
Epoch [17/500] Batch[3800/12648] complete. train_loss = 19.624580760253103
Epoch [17/500] Batch[4000/12648] complete. train_loss = 19.63446682548523
Epoch [17/500] Batch[4200/12648] complete. train_loss = 19.643214731216432
Epoch [17/500] Batch[4400/12648] complete. train_loss = 19.651308198408646
Epoch [17/500] Batch[4600/12648] complete. train_loss = 19.656369099409684
Epoch [17/500] Batch[4800/12648] complete. train_loss = 19.66209578871727
Epoch [17/500] Batch[5000/12648] complete. train_loss = 19.66948615951538
Epoch [17/500] Batch[5200/12648] complete. train_loss = 19.67502413859734
Epoch [17/500] Batch[5400/12648] complete. train_loss = 19.679272543589274
Epoch [17/500] Batch[5600/12648] complete. train_loss = 19.685139910834177
Epoch [17/500] Batch[5800/12648] complete. train_loss = 19.6897057822655
Epoch [17/500] Batch[6000/12648] complete. train_loss = 19.69578966617584
Epoch [17/500] Batch[6200/12648] complete. train_loss = 19.703560097602107
Epoch [17/500] Batch[6400/12648] complete. train_loss = 19.711726856827735
Epoch [17/500] Batch[6600/12648] complete. train_loss = 19.715452943859678
Epoch [17/500] Batch[6800/12648] complete. train_loss = 19.719133325464586
Epoch [17/500] Batch[7000/12648] complete. train_loss = 19.72262735939026
Epoch [17/500] Batch[7200/12648] complete. train_loss = 19.726033407317267
Epoch [17/500] Batch[7400/12648] complete. train_loss = 19.731083724047686
Epoch [17/500] Batch[7600/12648] complete. train_loss = 19.734722048859847
Epoch [17/500] Batch[7800/12648] complete. train_loss = 19.736982606252035
Epoch [17/500] Batch[8000/12648] complete. train_loss = 19.741633341550827
Epoch [17/500] Batch[8200/12648] complete. train_loss = 19.74462233403834
Epoch [17/500] Batch[8400/12648] complete. train_loss = 19.74800984586988
Epoch [17/500] Batch[8600/12648] complete. train_loss = 19.75005321569221
Epoch [17/500] Batch[8800/12648] complete. train_loss = 19.752441352280705
Epoch [17/500] Batch[9000/12648] complete. train_loss = 19.7593659163581
Epoch [17/500] Batch[9200/12648] complete. train_loss = 19.762976866805037
Epoch [17/500] Batch[9400/12648] complete. train_loss = 19.765699608173776
Epoch [17/500] Batch[9600/12648] complete. train_loss = 19.767806836366653
Epoch [17/500] Batch[9800/12648] complete. train_loss = 19.76991154476088
Epoch [17/500] Batch[10000/12648] complete. train_loss = 19.772884761810303
Epoch [17/500] Batch[10200/12648] complete. train_loss = 19.776303583032945
Epoch [17/500] Batch[10400/12648] complete. train_loss = 19.780987134713392
Epoch [17/500] Batch[10600/12648] complete. train_loss = 19.78359136689384
Epoch [17/500] Batch[10800/12648] complete. train_loss = 19.784262049639665
Epoch [17/500] Batch[11000/12648] complete. train_loss = 19.788869597521696
Epoch [17/500] Batch[11200/12648] complete. train_loss = 19.790335561037065
Epoch [17/500] Batch[11400/12648] complete. train_loss = 19.7946407744759
Epoch [17/500] Batch[11600/12648] complete. train_loss = 19.798090039450546
Epoch [17/500] Batch[11800/12648] complete. train_loss = 19.801985359353534
Epoch [17/500] Batch[12000/12648] complete. train_loss = 19.805225327650707
Epoch [17/500] Batch[12200/12648] complete. train_loss = 19.8088450647573
Epoch [17/500] Batch[12400/12648] complete. train_loss = 19.811844888964007
Epoch [17/500] Batch[12600/12648] complete. train_loss = 19.814521953037808
Epoch [17/500] Batch[12648/12648] complete. valid_loss = 19.7096905708313
best models saved
Best Valid Loss = 19.7096905708313 (Epoch: 17)


Epoch [18/500] Batch[200/12648] complete. train_loss = 19.17700598716736
Epoch [18/500] Batch[400/12648] complete. train_loss = 19.227126126289367
Epoch [18/500] Batch[600/12648] complete. train_loss = 19.27536807060242
Epoch [18/500] Batch[800/12648] complete. train_loss = 19.286565630435945
Epoch [18/500] Batch[1000/12648] complete. train_loss = 19.305125734329224
Epoch [18/500] Batch[1200/12648] complete. train_loss = 19.32484819253286
Epoch [18/500] Batch[1400/12648] complete. train_loss = 19.346826324462892
Epoch [18/500] Batch[1600/12648] complete. train_loss = 19.357890325784684
Epoch [18/500] Batch[1800/12648] complete. train_loss = 19.370175428390503
Epoch [18/500] Batch[2000/12648] complete. train_loss = 19.373325294494627
Epoch [18/500] Batch[2200/12648] complete. train_loss = 19.379666793996638
Epoch [18/500] Batch[2400/12648] complete. train_loss = 19.391535894870756
Epoch [18/500] Batch[2600/12648] complete. train_loss = 19.399397274897648
Epoch [18/500] Batch[2800/12648] complete. train_loss = 19.40813386508397
Epoch [18/500] Batch[3000/12648] complete. train_loss = 19.414015172322593
Epoch [18/500] Batch[3200/12648] complete. train_loss = 19.42312534749508
Epoch [18/500] Batch[3400/12648] complete. train_loss = 19.429773589863498
Epoch [18/500] Batch[3600/12648] complete. train_loss = 19.43294235335456
Epoch [18/500] Batch[3800/12648] complete. train_loss = 19.440419842067516
Epoch [18/500] Batch[4000/12648] complete. train_loss = 19.450222397327423
Epoch [18/500] Batch[4200/12648] complete. train_loss = 19.457278770265127
Epoch [18/500] Batch[4400/12648] complete. train_loss = 19.4639447480982
Epoch [18/500] Batch[4600/12648] complete. train_loss = 19.468988069866015
Epoch [18/500] Batch[4800/12648] complete. train_loss = 19.479460328817368
Epoch [18/500] Batch[5000/12648] complete. train_loss = 19.489671098327637
Epoch [18/500] Batch[5200/12648] complete. train_loss = 19.492511421350333
Epoch [18/500] Batch[5400/12648] complete. train_loss = 19.497873800065783
Epoch [18/500] Batch[5600/12648] complete. train_loss = 19.506401029314315
Epoch [18/500] Batch[5800/12648] complete. train_loss = 19.51294003453748
Epoch [18/500] Batch[6000/12648] complete. train_loss = 19.52037351989746
Epoch [18/500] Batch[6200/12648] complete. train_loss = 19.522863282542076
Epoch [18/500] Batch[6400/12648] complete. train_loss = 19.533500773608683
Epoch [18/500] Batch[6600/12648] complete. train_loss = 19.536628435308284
Epoch [18/500] Batch[6800/12648] complete. train_loss = 19.541491925856647
Epoch [18/500] Batch[7000/12648] complete. train_loss = 19.545218882969447
Epoch [18/500] Batch[7200/12648] complete. train_loss = 19.5495611582862
Epoch [18/500] Batch[7400/12648] complete. train_loss = 19.55387432820088
Epoch [18/500] Batch[7600/12648] complete. train_loss = 19.559565295420196
Epoch [18/500] Batch[7800/12648] complete. train_loss = 19.56546752587343
Epoch [18/500] Batch[8000/12648] complete. train_loss = 19.570252891540527
Epoch [18/500] Batch[8200/12648] complete. train_loss = 19.573836130979583
Epoch [18/500] Batch[8400/12648] complete. train_loss = 19.578545848074413
Epoch [18/500] Batch[8600/12648] complete. train_loss = 19.58177616452062
Epoch [18/500] Batch[8800/12648] complete. train_loss = 19.586200943643398
Epoch [18/500] Batch[9000/12648] complete. train_loss = 19.58924694167243
Epoch [18/500] Batch[9200/12648] complete. train_loss = 19.59548479764358
Epoch [18/500] Batch[9400/12648] complete. train_loss = 19.598527316032573
Epoch [18/500] Batch[9600/12648] complete. train_loss = 19.602675602436065
Epoch [18/500] Batch[9800/12648] complete. train_loss = 19.605316301073348
Epoch [18/500] Batch[10000/12648] complete. train_loss = 19.60918171272278
Epoch [18/500] Batch[10200/12648] complete. train_loss = 19.613641808266735
Epoch [18/500] Batch[10400/12648] complete. train_loss = 19.61725036767813
Epoch [18/500] Batch[10600/12648] complete. train_loss = 19.621235996462264
Epoch [18/500] Batch[10800/12648] complete. train_loss = 19.6254883118029
Epoch [18/500] Batch[11000/12648] complete. train_loss = 19.628078177538786
Epoch [18/500] Batch[11200/12648] complete. train_loss = 19.629411230427877
Epoch [18/500] Batch[11400/12648] complete. train_loss = 19.631466765989337
Epoch [18/500] Batch[11600/12648] complete. train_loss = 19.635795913729176
Epoch [18/500] Batch[11800/12648] complete. train_loss = 19.639160511534094
Epoch [18/500] Batch[12000/12648] complete. train_loss = 19.64515509668986
Epoch [18/500] Batch[12200/12648] complete. train_loss = 19.649806216818387
Epoch [18/500] Batch[12400/12648] complete. train_loss = 19.654103148368097
Epoch [18/500] Batch[12600/12648] complete. train_loss = 19.65726244865902
Epoch [18/500] Batch[12648/12648] complete. valid_loss = 19.724538326263428
Epoch [19/500] Batch[200/12648] complete. train_loss = 19.21630867958069
Epoch [19/500] Batch[400/12648] complete. train_loss = 19.15405716896057
Epoch [19/500] Batch[600/12648] complete. train_loss = 19.155136359532673
Epoch [19/500] Batch[800/12648] complete. train_loss = 19.144854180812835
Epoch [19/500] Batch[1000/12648] complete. train_loss = 19.169668712615966
Epoch [19/500] Batch[1200/12648] complete. train_loss = 19.176241273880006
Epoch [19/500] Batch[1400/12648] complete. train_loss = 19.182007687432424
Epoch [19/500] Batch[1600/12648] complete. train_loss = 19.198534013032912
Epoch [19/500] Batch[1800/12648] complete. train_loss = 19.202008395724825
Epoch [19/500] Batch[2000/12648] complete. train_loss = 19.221521324157713
Epoch [19/500] Batch[2200/12648] complete. train_loss = 19.232924695448443
Epoch [19/500] Batch[2400/12648] complete. train_loss = 19.237633095582325
Epoch [19/500] Batch[2600/12648] complete. train_loss = 19.246638650894166
Epoch [19/500] Batch[2800/12648] complete. train_loss = 19.251783185686385
Epoch [19/500] Batch[3000/12648] complete. train_loss = 19.257333374659222
Epoch [19/500] Batch[3200/12648] complete. train_loss = 19.263757743239402
Epoch [19/500] Batch[3400/12648] complete. train_loss = 19.277036499135633
Epoch [19/500] Batch[3600/12648] complete. train_loss = 19.28562570254008
Epoch [19/500] Batch[3800/12648] complete. train_loss = 19.293556214884706
Epoch [19/500] Batch[4000/12648] complete. train_loss = 19.298060461997984
Epoch [19/500] Batch[4200/12648] complete. train_loss = 19.307773061479843
Epoch [19/500] Batch[4400/12648] complete. train_loss = 19.318296823935075
Epoch [19/500] Batch[4600/12648] complete. train_loss = 19.326619435600612
Epoch [19/500] Batch[4800/12648] complete. train_loss = 19.334279070297878
Epoch [19/500] Batch[5000/12648] complete. train_loss = 19.33799970664978
Epoch [19/500] Batch[5200/12648] complete. train_loss = 19.3420131617326
Epoch [19/500] Batch[5400/12648] complete. train_loss = 19.348259073540017
Epoch [19/500] Batch[5600/12648] complete. train_loss = 19.355702832426342
Epoch [19/500] Batch[5800/12648] complete. train_loss = 19.35885574505247
Epoch [19/500] Batch[6000/12648] complete. train_loss = 19.366676315625508
Epoch [19/500] Batch[6200/12648] complete. train_loss = 19.37243201194271
Epoch [19/500] Batch[6400/12648] complete. train_loss = 19.378086412847043
Epoch [19/500] Batch[6600/12648] complete. train_loss = 19.382218871550126
Epoch [19/500] Batch[6800/12648] complete. train_loss = 19.385175276083103
Epoch [19/500] Batch[7000/12648] complete. train_loss = 19.391015108925956
Epoch [19/500] Batch[7200/12648] complete. train_loss = 19.396337225966985
Epoch [19/500] Batch[7400/12648] complete. train_loss = 19.401126867242763
Epoch [19/500] Batch[7600/12648] complete. train_loss = 19.407868197340715
Epoch [19/500] Batch[7800/12648] complete. train_loss = 19.41161947861696
Epoch [19/500] Batch[8000/12648] complete. train_loss = 19.414715670585633
Epoch [19/500] Batch[8200/12648] complete. train_loss = 19.421217830704478
Epoch [19/500] Batch[8400/12648] complete. train_loss = 19.426398005031405
Epoch [19/500] Batch[8600/12648] complete. train_loss = 19.431574435344963
Epoch [19/500] Batch[8800/12648] complete. train_loss = 19.438389154564252
Epoch [19/500] Batch[9000/12648] complete. train_loss = 19.44312076250712
Epoch [19/500] Batch[9200/12648] complete. train_loss = 19.445883156320324
Epoch [19/500] Batch[9400/12648] complete. train_loss = 19.44947332808312
Epoch [19/500] Batch[9600/12648] complete. train_loss = 19.453196189204853
Epoch [19/500] Batch[9800/12648] complete. train_loss = 19.45761041135204
Epoch [19/500] Batch[10000/12648] complete. train_loss = 19.463335293006896
Epoch [19/500] Batch[10200/12648] complete. train_loss = 19.466675546870512
Epoch [19/500] Batch[10400/12648] complete. train_loss = 19.47042526318477
Epoch [19/500] Batch[10600/12648] complete. train_loss = 19.47489018872099
Epoch [19/500] Batch[10800/12648] complete. train_loss = 19.478829994025055
Epoch [19/500] Batch[11000/12648] complete. train_loss = 19.48315208903226
Epoch [19/500] Batch[11200/12648] complete. train_loss = 19.488929256881985
Epoch [19/500] Batch[11400/12648] complete. train_loss = 19.49331233242102
Epoch [19/500] Batch[11600/12648] complete. train_loss = 19.497853481851774
Epoch [19/500] Batch[11800/12648] complete. train_loss = 19.500305083808254
Epoch [19/500] Batch[12000/12648] complete. train_loss = 19.50323200750351
Epoch [19/500] Batch[12200/12648] complete. train_loss = 19.50733569395347
Epoch [19/500] Batch[12400/12648] complete. train_loss = 19.50999234184142
Epoch [19/500] Batch[12600/12648] complete. train_loss = 19.512322851816812
Epoch [19/500] Batch[12648/12648] complete. valid_loss = 19.66894268989563
best models saved
Best Valid Loss = 19.66894268989563 (Epoch: 19)


Epoch [20/500] Batch[200/12648] complete. train_loss = 19.16447301864624
Epoch [20/500] Batch[400/12648] complete. train_loss = 19.098310074806214
Epoch [20/500] Batch[600/12648] complete. train_loss = 19.081870613098143
Epoch [20/500] Batch[800/12648] complete. train_loss = 19.081406733989716
Epoch [20/500] Batch[1000/12648] complete. train_loss = 19.07911386680603
Epoch [20/500] Batch[1200/12648] complete. train_loss = 19.085292421976725
Epoch [20/500] Batch[1400/12648] complete. train_loss = 19.080483098711287
Epoch [20/500] Batch[1600/12648] complete. train_loss = 19.094212428331375
Epoch [20/500] Batch[1800/12648] complete. train_loss = 19.098564222123887
Epoch [20/500] Batch[2000/12648] complete. train_loss = 19.099905354499818
Epoch [20/500] Batch[2200/12648] complete. train_loss = 19.112142198736016
Epoch [20/500] Batch[2400/12648] complete. train_loss = 19.12686155160268
Epoch [20/500] Batch[2600/12648] complete. train_loss = 19.1303377525623
Epoch [20/500] Batch[2800/12648] complete. train_loss = 19.14262841973986
Epoch [20/500] Batch[3000/12648] complete. train_loss = 19.15013194402059
Epoch [20/500] Batch[3200/12648] complete. train_loss = 19.15572611272335
Epoch [20/500] Batch[3400/12648] complete. train_loss = 19.163214614531572
Epoch [20/500] Batch[3600/12648] complete. train_loss = 19.167923251258003
Epoch [20/500] Batch[3800/12648] complete. train_loss = 19.174066589255084
Epoch [20/500] Batch[4000/12648] complete. train_loss = 19.178185411930084
Epoch [20/500] Batch[4200/12648] complete. train_loss = 19.18947835104806
Epoch [20/500] Batch[4400/12648] complete. train_loss = 19.191314109888943
Epoch [20/500] Batch[4600/12648] complete. train_loss = 19.19766198075336
Epoch [20/500] Batch[4800/12648] complete. train_loss = 19.205967630942663
Epoch [20/500] Batch[5000/12648] complete. train_loss = 19.214813151931764
Epoch [20/500] Batch[5200/12648] complete. train_loss = 19.218964171409606
Epoch [20/500] Batch[5400/12648] complete. train_loss = 19.224809645193595
Epoch [20/500] Batch[5600/12648] complete. train_loss = 19.23007898909705
Epoch [20/500] Batch[5800/12648] complete. train_loss = 19.237838747748015
Epoch [20/500] Batch[6000/12648] complete. train_loss = 19.240220017115274
Epoch [20/500] Batch[6200/12648] complete. train_loss = 19.2452820134932
Epoch [20/500] Batch[6400/12648] complete. train_loss = 19.249026848077776
Epoch [20/500] Batch[6600/12648] complete. train_loss = 19.257090044021606
Epoch [20/500] Batch[6800/12648] complete. train_loss = 19.259543402335222
Epoch [20/500] Batch[7000/12648] complete. train_loss = 19.264264359337943
Epoch [20/500] Batch[7200/12648] complete. train_loss = 19.26720144616233
Epoch [20/500] Batch[7400/12648] complete. train_loss = 19.275039650427328
Epoch [20/500] Batch[7600/12648] complete. train_loss = 19.279997783209147
Epoch [20/500] Batch[7800/12648] complete. train_loss = 19.28854575866308
Epoch [20/500] Batch[8000/12648] complete. train_loss = 19.293351118564605
Epoch [20/500] Batch[8200/12648] complete. train_loss = 19.295782508152286
Epoch [20/500] Batch[8400/12648] complete. train_loss = 19.30021611418043
Epoch [20/500] Batch[8600/12648] complete. train_loss = 19.304844567498495
Epoch [20/500] Batch[8800/12648] complete. train_loss = 19.308849915591153
Epoch [20/500] Batch[9000/12648] complete. train_loss = 19.31607759306166
Epoch [20/500] Batch[9200/12648] complete. train_loss = 19.32021546073582
Epoch [20/500] Batch[9400/12648] complete. train_loss = 19.323748568271068
Epoch [20/500] Batch[9600/12648] complete. train_loss = 19.327852330207826
Epoch [20/500] Batch[9800/12648] complete. train_loss = 19.33179576387211
Epoch [20/500] Batch[10000/12648] complete. train_loss = 19.333607288742066
Epoch [20/500] Batch[10200/12648] complete. train_loss = 19.33648263164595
Epoch [20/500] Batch[10400/12648] complete. train_loss = 19.338937849815075
Epoch [20/500] Batch[10600/12648] complete. train_loss = 19.34350364990954
Epoch [20/500] Batch[10800/12648] complete. train_loss = 19.346792475029275
Epoch [20/500] Batch[11000/12648] complete. train_loss = 19.35111167647622
Epoch [20/500] Batch[11200/12648] complete. train_loss = 19.356067853825433
Epoch [20/500] Batch[11400/12648] complete. train_loss = 19.35898608140778
Epoch [20/500] Batch[11600/12648] complete. train_loss = 19.362999042149248
Epoch [20/500] Batch[11800/12648] complete. train_loss = 19.36716298345792
Epoch [20/500] Batch[12000/12648] complete. train_loss = 19.37022252400716
Epoch [20/500] Batch[12200/12648] complete. train_loss = 19.372570787179665
Epoch [20/500] Batch[12400/12648] complete. train_loss = 19.375478657907056
Epoch [20/500] Batch[12600/12648] complete. train_loss = 19.37919349095178
Epoch [20/500] Batch[12648/12648] complete. valid_loss = 19.61464810371399
best models saved
Best Valid Loss = 19.61464810371399 (Epoch: 20)


Epoch [21/500] Batch[200/12648] complete. train_loss = 18.865685987472535
Epoch [21/500] Batch[400/12648] complete. train_loss = 18.856562314033507
Epoch [21/500] Batch[600/12648] complete. train_loss = 18.88268507639567
Epoch [21/500] Batch[800/12648] complete. train_loss = 18.886136133670806
Epoch [21/500] Batch[1000/12648] complete. train_loss = 18.880563402175902
Epoch [21/500] Batch[1200/12648] complete. train_loss = 18.905379344622293
Epoch [21/500] Batch[1400/12648] complete. train_loss = 18.911870208467757
Epoch [21/500] Batch[1600/12648] complete. train_loss = 18.931640572547913
Epoch [21/500] Batch[1800/12648] complete. train_loss = 18.93791124343872
Epoch [21/500] Batch[2000/12648] complete. train_loss = 18.943058767318725
Epoch [21/500] Batch[2200/12648] complete. train_loss = 18.949362838918514
Epoch [21/500] Batch[2400/12648] complete. train_loss = 18.960907950401307
Epoch [21/500] Batch[2600/12648] complete. train_loss = 18.97274882389949
Epoch [21/500] Batch[2800/12648] complete. train_loss = 18.98273985522134
Epoch [21/500] Batch[3000/12648] complete. train_loss = 18.993850290934244
Epoch [21/500] Batch[3200/12648] complete. train_loss = 18.999904484152793
Epoch [21/500] Batch[3400/12648] complete. train_loss = 19.008984933179967
Epoch [21/500] Batch[3600/12648] complete. train_loss = 19.017038569450378
Epoch [21/500] Batch[3800/12648] complete. train_loss = 19.023741055036847
Epoch [21/500] Batch[4000/12648] complete. train_loss = 19.02970768880844
Epoch [21/500] Batch[4200/12648] complete. train_loss = 19.036217258090065
Epoch [21/500] Batch[4400/12648] complete. train_loss = 19.04304676879536
Epoch [21/500] Batch[4600/12648] complete. train_loss = 19.05403245801511
Epoch [21/500] Batch[4800/12648] complete. train_loss = 19.062607618172965
Epoch [21/500] Batch[5000/12648] complete. train_loss = 19.069792181396483
Epoch [21/500] Batch[5200/12648] complete. train_loss = 19.07506370691153
Epoch [21/500] Batch[5400/12648] complete. train_loss = 19.080651996753833
Epoch [21/500] Batch[5600/12648] complete. train_loss = 19.087138167449407
Epoch [21/500] Batch[5800/12648] complete. train_loss = 19.094891088091092
Epoch [21/500] Batch[6000/12648] complete. train_loss = 19.10203572781881
Epoch [21/500] Batch[6200/12648] complete. train_loss = 19.109794363821706
Epoch [21/500] Batch[6400/12648] complete. train_loss = 19.11625631660223
Epoch [21/500] Batch[6600/12648] complete. train_loss = 19.12070689721541
Epoch [21/500] Batch[6800/12648] complete. train_loss = 19.122503673329074
Epoch [21/500] Batch[7000/12648] complete. train_loss = 19.128958571842738
Epoch [21/500] Batch[7200/12648] complete. train_loss = 19.131343931357065
Epoch [21/500] Batch[7400/12648] complete. train_loss = 19.13651879052858
Epoch [21/500] Batch[7600/12648] complete. train_loss = 19.143198308693734
Epoch [21/500] Batch[7800/12648] complete. train_loss = 19.148650661615225
Epoch [21/500] Batch[8000/12648] complete. train_loss = 19.15464621543884
Epoch [21/500] Batch[8200/12648] complete. train_loss = 19.1592185436807
Epoch [21/500] Batch[8400/12648] complete. train_loss = 19.164792475700377
Epoch [21/500] Batch[8600/12648] complete. train_loss = 19.169023626017015
Epoch [21/500] Batch[8800/12648] complete. train_loss = 19.17414061047814
Epoch [21/500] Batch[9000/12648] complete. train_loss = 19.178666637208728
Epoch [21/500] Batch[9200/12648] complete. train_loss = 19.18281572424847
Epoch [21/500] Batch[9400/12648] complete. train_loss = 19.186062958291238
Epoch [21/500] Batch[9600/12648] complete. train_loss = 19.19157176832358
Epoch [21/500] Batch[9800/12648] complete. train_loss = 19.19423681045065
Epoch [21/500] Batch[10000/12648] complete. train_loss = 19.19573418273926
Epoch [21/500] Batch[10200/12648] complete. train_loss = 19.20087592648525
Epoch [21/500] Batch[10400/12648] complete. train_loss = 19.20555262693992
Epoch [21/500] Batch[10600/12648] complete. train_loss = 19.209121104366375
Epoch [21/500] Batch[10800/12648] complete. train_loss = 19.214376453117087
Epoch [21/500] Batch[11000/12648] complete. train_loss = 19.21971399636702
Epoch [21/500] Batch[11200/12648] complete. train_loss = 19.224281868594034
Epoch [21/500] Batch[11400/12648] complete. train_loss = 19.228084756784273
Epoch [21/500] Batch[11600/12648] complete. train_loss = 19.23206051629165
Epoch [21/500] Batch[11800/12648] complete. train_loss = 19.236269087872262
Epoch [21/500] Batch[12000/12648] complete. train_loss = 19.24009575510025
Epoch [21/500] Batch[12200/12648] complete. train_loss = 19.24402717512162
Epoch [21/500] Batch[12400/12648] complete. train_loss = 19.24728392524104
Epoch [21/500] Batch[12600/12648] complete. train_loss = 19.252634041952707
Epoch [21/500] Batch[12648/12648] complete. valid_loss = 19.596354484558105
best models saved
Best Valid Loss = 19.596354484558105 (Epoch: 21)


Epoch [22/500] Batch[200/12648] complete. train_loss = 18.733279399871826
Epoch [22/500] Batch[400/12648] complete. train_loss = 18.720123357772827
Epoch [22/500] Batch[600/12648] complete. train_loss = 18.743755111694338
Epoch [22/500] Batch[800/12648] complete. train_loss = 18.786755547523498
Epoch [22/500] Batch[1000/12648] complete. train_loss = 18.79108250427246
Epoch [22/500] Batch[1200/12648] complete. train_loss = 18.803674203554788
Epoch [22/500] Batch[1400/12648] complete. train_loss = 18.831098533357892
Epoch [22/500] Batch[1600/12648] complete. train_loss = 18.837073318958282
Epoch [22/500] Batch[1800/12648] complete. train_loss = 18.84790087170071
Epoch [22/500] Batch[2000/12648] complete. train_loss = 18.864581007957458
Epoch [22/500] Batch[2200/12648] complete. train_loss = 18.863135922171853
Epoch [22/500] Batch[2400/12648] complete. train_loss = 18.863215227921803
Epoch [22/500] Batch[2600/12648] complete. train_loss = 18.87630493750939
Epoch [22/500] Batch[2800/12648] complete. train_loss = 18.8812295797893
Epoch [22/500] Batch[3000/12648] complete. train_loss = 18.890675051371257
Epoch [22/500] Batch[3200/12648] complete. train_loss = 18.901011786460877
Epoch [22/500] Batch[3400/12648] complete. train_loss = 18.902379806181965
Epoch [22/500] Batch[3600/12648] complete. train_loss = 18.906285926500956
Epoch [22/500] Batch[3800/12648] complete. train_loss = 18.913810230054352
Epoch [22/500] Batch[4000/12648] complete. train_loss = 18.924754693984987
Epoch [22/500] Batch[4200/12648] complete. train_loss = 18.93008362406776
Epoch [22/500] Batch[4400/12648] complete. train_loss = 18.93704943266782
Epoch [22/500] Batch[4600/12648] complete. train_loss = 18.94471237431402
Epoch [22/500] Batch[4800/12648] complete. train_loss = 18.9538092704614
Epoch [22/500] Batch[5000/12648] complete. train_loss = 18.963243023681642
Epoch [22/500] Batch[5200/12648] complete. train_loss = 18.97243223997263
Epoch [22/500] Batch[5400/12648] complete. train_loss = 18.975812417136297
Epoch [22/500] Batch[5600/12648] complete. train_loss = 18.979204156058174
Epoch [22/500] Batch[5800/12648] complete. train_loss = 18.984807177905378
Epoch [22/500] Batch[6000/12648] complete. train_loss = 18.990538496017457
Epoch [22/500] Batch[6200/12648] complete. train_loss = 18.99363362896827
Epoch [22/500] Batch[6400/12648] complete. train_loss = 18.998306942284106
Epoch [22/500] Batch[6600/12648] complete. train_loss = 19.002472146352133
Epoch [22/500] Batch[6800/12648] complete. train_loss = 19.0101612887663
Epoch [22/500] Batch[7000/12648] complete. train_loss = 19.01726050240653
Epoch [22/500] Batch[7200/12648] complete. train_loss = 19.021980407502916
Epoch [22/500] Batch[7400/12648] complete. train_loss = 19.028100119152583
Epoch [22/500] Batch[7600/12648] complete. train_loss = 19.032909794857627
Epoch [22/500] Batch[7800/12648] complete. train_loss = 19.038262544289612
Epoch [22/500] Batch[8000/12648] complete. train_loss = 19.042049713373185
Epoch [22/500] Batch[8200/12648] complete. train_loss = 19.045212774509338
Epoch [22/500] Batch[8400/12648] complete. train_loss = 19.05132988861629
Epoch [22/500] Batch[8600/12648] complete. train_loss = 19.055998410956803
Epoch [22/500] Batch[8800/12648] complete. train_loss = 19.06006161776456
Epoch [22/500] Batch[9000/12648] complete. train_loss = 19.06372477298313
Epoch [22/500] Batch[9200/12648] complete. train_loss = 19.068515292665232
Epoch [22/500] Batch[9400/12648] complete. train_loss = 19.073750751373616
Epoch [22/500] Batch[9600/12648] complete. train_loss = 19.076640554269154
Epoch [22/500] Batch[9800/12648] complete. train_loss = 19.081107516191445
Epoch [22/500] Batch[10000/12648] complete. train_loss = 19.085080068397524
Epoch [22/500] Batch[10200/12648] complete. train_loss = 19.09078384511611
Epoch [22/500] Batch[10400/12648] complete. train_loss = 19.094719314758596
Epoch [22/500] Batch[10600/12648] complete. train_loss = 19.097471963594543
Epoch [22/500] Batch[10800/12648] complete. train_loss = 19.0995764181349
Epoch [22/500] Batch[11000/12648] complete. train_loss = 19.105318152861162
Epoch [22/500] Batch[11200/12648] complete. train_loss = 19.108604031120027
Epoch [22/500] Batch[11400/12648] complete. train_loss = 19.11282718206707
Epoch [22/500] Batch[11600/12648] complete. train_loss = 19.117089383684355
Epoch [22/500] Batch[11800/12648] complete. train_loss = 19.121129649049145
Epoch [22/500] Batch[12000/12648] complete. train_loss = 19.125425383885702
Epoch [22/500] Batch[12200/12648] complete. train_loss = 19.12776168494928
Epoch [22/500] Batch[12400/12648] complete. train_loss = 19.13215559713302
Epoch [22/500] Batch[12600/12648] complete. train_loss = 19.135558466835626
Epoch [22/500] Batch[12648/12648] complete. valid_loss = 19.583417654037476
best models saved
Best Valid Loss = 19.583417654037476 (Epoch: 22)


Epoch [23/500] Batch[200/12648] complete. train_loss = 18.676166048049925
Epoch [23/500] Batch[400/12648] complete. train_loss = 18.647131752967834
Epoch [23/500] Batch[600/12648] complete. train_loss = 18.649771302541097
Epoch [23/500] Batch[800/12648] complete. train_loss = 18.646023247241974
Epoch [23/500] Batch[1000/12648] complete. train_loss = 18.676652687072753
Epoch [23/500] Batch[1200/12648] complete. train_loss = 18.682174463272094
Epoch [23/500] Batch[1400/12648] complete. train_loss = 18.702940484455652
Epoch [23/500] Batch[1600/12648] complete. train_loss = 18.711679507493972
Epoch [23/500] Batch[1800/12648] complete. train_loss = 18.717034633424547
Epoch [23/500] Batch[2000/12648] complete. train_loss = 18.729359053611756
Epoch [23/500] Batch[2200/12648] complete. train_loss = 18.73987787246704
Epoch [23/500] Batch[2400/12648] complete. train_loss = 18.74232625404994
Epoch [23/500] Batch[2600/12648] complete. train_loss = 18.74873180976281
Epoch [23/500] Batch[2800/12648] complete. train_loss = 18.7564720255988
Epoch [23/500] Batch[3000/12648] complete. train_loss = 18.765461453119915
Epoch [23/500] Batch[3200/12648] complete. train_loss = 18.773750783801077
Epoch [23/500] Batch[3400/12648] complete. train_loss = 18.789665159898647
Epoch [23/500] Batch[3600/12648] complete. train_loss = 18.79772973696391
Epoch [23/500] Batch[3800/12648] complete. train_loss = 18.80041787147522
Epoch [23/500] Batch[4000/12648] complete. train_loss = 18.80806816148758
Epoch [23/500] Batch[4200/12648] complete. train_loss = 18.81770286151341
Epoch [23/500] Batch[4400/12648] complete. train_loss = 18.824591144648466
Epoch [23/500] Batch[4600/12648] complete. train_loss = 18.82862981506016
Epoch [23/500] Batch[4800/12648] complete. train_loss = 18.8363121453921
Epoch [23/500] Batch[5000/12648] complete. train_loss = 18.84362541923523
Epoch [23/500] Batch[5200/12648] complete. train_loss = 18.851372087551997
Epoch [23/500] Batch[5400/12648] complete. train_loss = 18.8593360431106
Epoch [23/500] Batch[5600/12648] complete. train_loss = 18.866155356679645
Epoch [23/500] Batch[5800/12648] complete. train_loss = 18.870714546400926
Epoch [23/500] Batch[6000/12648] complete. train_loss = 18.87724085013072
Epoch [23/500] Batch[6200/12648] complete. train_loss = 18.88348518986856
Epoch [23/500] Batch[6400/12648] complete. train_loss = 18.890421049296855
Epoch [23/500] Batch[6600/12648] complete. train_loss = 18.895266677105067
Epoch [23/500] Batch[6800/12648] complete. train_loss = 18.900947163245256
Epoch [23/500] Batch[7000/12648] complete. train_loss = 18.905649461746215
Epoch [23/500] Batch[7200/12648] complete. train_loss = 18.911123384369745
Epoch [23/500] Batch[7400/12648] complete. train_loss = 18.915947916958782
Epoch [23/500] Batch[7600/12648] complete. train_loss = 18.922876596701773
Epoch [23/500] Batch[7800/12648] complete. train_loss = 18.92797958056132
Epoch [23/500] Batch[8000/12648] complete. train_loss = 18.93347409939766
Epoch [23/500] Batch[8200/12648] complete. train_loss = 18.940231882886188
Epoch [23/500] Batch[8400/12648] complete. train_loss = 18.9416724611464
Epoch [23/500] Batch[8600/12648] complete. train_loss = 18.94642256714577
Epoch [23/500] Batch[8800/12648] complete. train_loss = 18.950212799419056
Epoch [23/500] Batch[9000/12648] complete. train_loss = 18.954306751463147
Epoch [23/500] Batch[9200/12648] complete. train_loss = 18.95870413261911
Epoch [23/500] Batch[9400/12648] complete. train_loss = 18.963029403889433
Epoch [23/500] Batch[9600/12648] complete. train_loss = 18.964960128068924
Epoch [23/500] Batch[9800/12648] complete. train_loss = 18.969636809679926
Epoch [23/500] Batch[10000/12648] complete. train_loss = 18.975661689186097
Epoch [23/500] Batch[10200/12648] complete. train_loss = 18.98004002832899
Epoch [23/500] Batch[10400/12648] complete. train_loss = 18.985743410220515
Epoch [23/500] Batch[10600/12648] complete. train_loss = 18.98899235941329
Epoch [23/500] Batch[10800/12648] complete. train_loss = 18.99213730653127
Epoch [23/500] Batch[11000/12648] complete. train_loss = 18.99624304407293
Epoch [23/500] Batch[11200/12648] complete. train_loss = 18.999025441408158
Epoch [23/500] Batch[11400/12648] complete. train_loss = 19.000395645007753
Epoch [23/500] Batch[11600/12648] complete. train_loss = 19.004518093733953
Epoch [23/500] Batch[11800/12648] complete. train_loss = 19.010781381898006
Epoch [23/500] Batch[12000/12648] complete. train_loss = 19.013941199620565
Epoch [23/500] Batch[12200/12648] complete. train_loss = 19.018272581413143
Epoch [23/500] Batch[12400/12648] complete. train_loss = 19.02155442730073
Epoch [23/500] Batch[12600/12648] complete. train_loss = 19.02512695948283
Epoch [23/500] Batch[12648/12648] complete. valid_loss = 19.57560169696808
best models saved
Best Valid Loss = 19.57560169696808 (Epoch: 23)


Epoch [24/500] Batch[200/12648] complete. train_loss = 18.382345247268677
Epoch [24/500] Batch[400/12648] complete. train_loss = 18.448145198822022
Epoch [24/500] Batch[600/12648] complete. train_loss = 18.489561093648273
Epoch [24/500] Batch[800/12648] complete. train_loss = 18.514189474582672
Epoch [24/500] Batch[1000/12648] complete. train_loss = 18.51463742828369
Epoch [24/500] Batch[1200/12648] complete. train_loss = 18.529625447591147
Epoch [24/500] Batch[1400/12648] complete. train_loss = 18.54497835976737
Epoch [24/500] Batch[1600/12648] complete. train_loss = 18.562290172576905
Epoch [24/500] Batch[1800/12648] complete. train_loss = 18.57539403915405
Epoch [24/500] Batch[2000/12648] complete. train_loss = 18.59087229824066
Epoch [24/500] Batch[2200/12648] complete. train_loss = 18.602464053414085
Epoch [24/500] Batch[2400/12648] complete. train_loss = 18.607714087963103
Epoch [24/500] Batch[2600/12648] complete. train_loss = 18.6165234543727
Epoch [24/500] Batch[2800/12648] complete. train_loss = 18.62469663619995
Epoch [24/500] Batch[3000/12648] complete. train_loss = 18.63225617980957
Epoch [24/500] Batch[3200/12648] complete. train_loss = 18.641146387457848
Epoch [24/500] Batch[3400/12648] complete. train_loss = 18.654881565430586
Epoch [24/500] Batch[3600/12648] complete. train_loss = 18.663269751336838
Epoch [24/500] Batch[3800/12648] complete. train_loss = 18.669744044354086
Epoch [24/500] Batch[4000/12648] complete. train_loss = 18.682225317955016
Epoch [24/500] Batch[4200/12648] complete. train_loss = 18.68959101676941
Epoch [24/500] Batch[4400/12648] complete. train_loss = 18.699750635840676
Epoch [24/500] Batch[4600/12648] complete. train_loss = 18.707802749302076
Epoch [24/500] Batch[4800/12648] complete. train_loss = 18.71492524544398
Epoch [24/500] Batch[5000/12648] complete. train_loss = 18.72246262626648
Epoch [24/500] Batch[5200/12648] complete. train_loss = 18.730336199907157
Epoch [24/500] Batch[5400/12648] complete. train_loss = 18.737924827293114
Epoch [24/500] Batch[5600/12648] complete. train_loss = 18.74393610204969
Epoch [24/500] Batch[5800/12648] complete. train_loss = 18.751530700880906
Epoch [24/500] Batch[6000/12648] complete. train_loss = 18.760921266237894
Epoch [24/500] Batch[6200/12648] complete. train_loss = 18.766764870305217
Epoch [24/500] Batch[6400/12648] complete. train_loss = 18.775169294178486
Epoch [24/500] Batch[6600/12648] complete. train_loss = 18.778793301726832
Epoch [24/500] Batch[6800/12648] complete. train_loss = 18.787007602803847
Epoch [24/500] Batch[7000/12648] complete. train_loss = 18.79458737836565
Epoch [24/500] Batch[7200/12648] complete. train_loss = 18.801181086699167
Epoch [24/500] Batch[7400/12648] complete. train_loss = 18.807642667873484
Epoch [24/500] Batch[7600/12648] complete. train_loss = 18.813121318064237
Epoch [24/500] Batch[7800/12648] complete. train_loss = 18.818066452711058
Epoch [24/500] Batch[8000/12648] complete. train_loss = 18.823024557352067
Epoch [24/500] Batch[8200/12648] complete. train_loss = 18.82794741002525
Epoch [24/500] Batch[8400/12648] complete. train_loss = 18.83284064179375
Epoch [24/500] Batch[8600/12648] complete. train_loss = 18.836046934349593
Epoch [24/500] Batch[8800/12648] complete. train_loss = 18.840250054922972
Epoch [24/500] Batch[9000/12648] complete. train_loss = 18.844859155866835
Epoch [24/500] Batch[9200/12648] complete. train_loss = 18.848092531535936
Epoch [24/500] Batch[9400/12648] complete. train_loss = 18.853802974985
Epoch [24/500] Batch[9600/12648] complete. train_loss = 18.85977360765139
Epoch [24/500] Batch[9800/12648] complete. train_loss = 18.864712624257926
Epoch [24/500] Batch[10000/12648] complete. train_loss = 18.869602917289733
Epoch [24/500] Batch[10200/12648] complete. train_loss = 18.874693023831238
Epoch [24/500] Batch[10400/12648] complete. train_loss = 18.879081039978907
Epoch [24/500] Batch[10600/12648] complete. train_loss = 18.882212403495355
Epoch [24/500] Batch[10800/12648] complete. train_loss = 18.886458569632637
Epoch [24/500] Batch[11000/12648] complete. train_loss = 18.890739212729713
Epoch [24/500] Batch[11200/12648] complete. train_loss = 18.894652435098376
Epoch [24/500] Batch[11400/12648] complete. train_loss = 18.898996816099736
Epoch [24/500] Batch[11600/12648] complete. train_loss = 18.902629857885426
Epoch [24/500] Batch[11800/12648] complete. train_loss = 18.907358814013207
Epoch [24/500] Batch[12000/12648] complete. train_loss = 18.911633540312447
Epoch [24/500] Batch[12200/12648] complete. train_loss = 18.91448550083598
Epoch [24/500] Batch[12400/12648] complete. train_loss = 18.918440519302123
Epoch [24/500] Batch[12600/12648] complete. train_loss = 18.92290163085574
Epoch [24/500] Batch[12648/12648] complete. valid_loss = 19.538809299468994
best models saved
Best Valid Loss = 19.538809299468994 (Epoch: 24)


Epoch [25/500] Batch[200/12648] complete. train_loss = 18.4512100982666
Epoch [25/500] Batch[400/12648] complete. train_loss = 18.40820281982422
Epoch [25/500] Batch[600/12648] complete. train_loss = 18.41003983179728
Epoch [25/500] Batch[800/12648] complete. train_loss = 18.41641941547394
Epoch [25/500] Batch[1000/12648] complete. train_loss = 18.436015439987184
Epoch [25/500] Batch[1200/12648] complete. train_loss = 18.46673194805781
Epoch [25/500] Batch[1400/12648] complete. train_loss = 18.490561958721706
Epoch [25/500] Batch[1600/12648] complete. train_loss = 18.50045201122761
Epoch [25/500] Batch[1800/12648] complete. train_loss = 18.505480536884733
Epoch [25/500] Batch[2000/12648] complete. train_loss = 18.51370465326309
Epoch [25/500] Batch[2200/12648] complete. train_loss = 18.52151625849984
Epoch [25/500] Batch[2400/12648] complete. train_loss = 18.53306039214134
Epoch [25/500] Batch[2600/12648] complete. train_loss = 18.54136448750129
Epoch [25/500] Batch[2800/12648] complete. train_loss = 18.547174753120967
Epoch [25/500] Batch[3000/12648] complete. train_loss = 18.560215096473694
Epoch [25/500] Batch[3200/12648] complete. train_loss = 18.56835058480501
Epoch [25/500] Batch[3400/12648] complete. train_loss = 18.580811973740072
Epoch [25/500] Batch[3600/12648] complete. train_loss = 18.58656364361445
Epoch [25/500] Batch[3800/12648] complete. train_loss = 18.5959000529741
Epoch [25/500] Batch[4000/12648] complete. train_loss = 18.605366797208784
Epoch [25/500] Batch[4200/12648] complete. train_loss = 18.616292075883774
Epoch [25/500] Batch[4400/12648] complete. train_loss = 18.624967925548553
Epoch [25/500] Batch[4600/12648] complete. train_loss = 18.626789500402367
Epoch [25/500] Batch[4800/12648] complete. train_loss = 18.630090651313463
Epoch [25/500] Batch[5000/12648] complete. train_loss = 18.63919790172577
Epoch [25/500] Batch[5200/12648] complete. train_loss = 18.643301011415627
Epoch [25/500] Batch[5400/12648] complete. train_loss = 18.650762308791833
Epoch [25/500] Batch[5600/12648] complete. train_loss = 18.65689869080271
Epoch [25/500] Batch[5800/12648] complete. train_loss = 18.662892768629668
Epoch [25/500] Batch[6000/12648] complete. train_loss = 18.668937424500783
Epoch [25/500] Batch[6200/12648] complete. train_loss = 18.677507343753692
Epoch [25/500] Batch[6400/12648] complete. train_loss = 18.683283536285163
Epoch [25/500] Batch[6600/12648] complete. train_loss = 18.687654137322397
Epoch [25/500] Batch[6800/12648] complete. train_loss = 18.693528755272137
Epoch [25/500] Batch[7000/12648] complete. train_loss = 18.697972580364773
Epoch [25/500] Batch[7200/12648] complete. train_loss = 18.704593038691414
Epoch [25/500] Batch[7400/12648] complete. train_loss = 18.71075712294192
Epoch [25/500] Batch[7600/12648] complete. train_loss = 18.71607083333166
Epoch [25/500] Batch[7800/12648] complete. train_loss = 18.721013954969553
Epoch [25/500] Batch[8000/12648] complete. train_loss = 18.72440482532978
Epoch [25/500] Batch[8200/12648] complete. train_loss = 18.729449947985206
Epoch [25/500] Batch[8400/12648] complete. train_loss = 18.73713052965346
Epoch [25/500] Batch[8600/12648] complete. train_loss = 18.743238867271778
Epoch [25/500] Batch[8800/12648] complete. train_loss = 18.746630778421054
Epoch [25/500] Batch[9000/12648] complete. train_loss = 18.75189649889204
Epoch [25/500] Batch[9200/12648] complete. train_loss = 18.75724668637566
Epoch [25/500] Batch[9400/12648] complete. train_loss = 18.760081283995447
Epoch [25/500] Batch[9600/12648] complete. train_loss = 18.764308290382225
Epoch [25/500] Batch[9800/12648] complete. train_loss = 18.76925977249535
Epoch [25/500] Batch[10000/12648] complete. train_loss = 18.77364518060684
Epoch [25/500] Batch[10200/12648] complete. train_loss = 18.77773232431973
Epoch [25/500] Batch[10400/12648] complete. train_loss = 18.782519923631963
Epoch [25/500] Batch[10600/12648] complete. train_loss = 18.786901695773288
Epoch [25/500] Batch[10800/12648] complete. train_loss = 18.791565444292846
Epoch [25/500] Batch[11000/12648] complete. train_loss = 18.794175600311974
Epoch [25/500] Batch[11200/12648] complete. train_loss = 18.798150537099158
Epoch [25/500] Batch[11400/12648] complete. train_loss = 18.80331897074716
Epoch [25/500] Batch[11600/12648] complete. train_loss = 18.80846896804612
Epoch [25/500] Batch[11800/12648] complete. train_loss = 18.81383765972267
Epoch [25/500] Batch[12000/12648] complete. train_loss = 18.817295365571976
Epoch [25/500] Batch[12200/12648] complete. train_loss = 18.822918059943152
Epoch [25/500] Batch[12400/12648] complete. train_loss = 18.825502785636534
Epoch [25/500] Batch[12600/12648] complete. train_loss = 18.8303021242505
Epoch [25/500] Batch[12648/12648] complete. valid_loss = 19.560300588607788
Epoch [26/500] Batch[200/12648] complete. train_loss = 18.272145252227784
Epoch [26/500] Batch[400/12648] complete. train_loss = 18.289968724250794
Epoch [26/500] Batch[600/12648] complete. train_loss = 18.306375443140666
Epoch [26/500] Batch[800/12648] complete. train_loss = 18.338749811649322
Epoch [26/500] Batch[1000/12648] complete. train_loss = 18.331336851119996
Epoch [26/500] Batch[1200/12648] complete. train_loss = 18.353295296033224
Epoch [26/500] Batch[1400/12648] complete. train_loss = 18.360592049189975
Epoch [26/500] Batch[1600/12648] complete. train_loss = 18.380822039842606
Epoch [26/500] Batch[1800/12648] complete. train_loss = 18.398062077628243
Epoch [26/500] Batch[2000/12648] complete. train_loss = 18.39850875377655
Epoch [26/500] Batch[2200/12648] complete. train_loss = 18.411251595237037
Epoch [26/500] Batch[2400/12648] complete. train_loss = 18.42387408574422
Epoch [26/500] Batch[2600/12648] complete. train_loss = 18.437441348295945
Epoch [26/500] Batch[2800/12648] complete. train_loss = 18.44261312825339
Epoch [26/500] Batch[3000/12648] complete. train_loss = 18.45262837791443
Epoch [26/500] Batch[3200/12648] complete. train_loss = 18.471686212420465
Epoch [26/500] Batch[3400/12648] complete. train_loss = 18.48713535084444
Epoch [26/500] Batch[3600/12648] complete. train_loss = 18.4966392660141
Epoch [26/500] Batch[3800/12648] complete. train_loss = 18.50503159723784
Epoch [26/500] Batch[4000/12648] complete. train_loss = 18.51401208639145
Epoch [26/500] Batch[4200/12648] complete. train_loss = 18.52023222151257
Epoch [26/500] Batch[4400/12648] complete. train_loss = 18.526598704944956
Epoch [26/500] Batch[4600/12648] complete. train_loss = 18.531817856664244
Epoch [26/500] Batch[4800/12648] complete. train_loss = 18.540593229929605
Epoch [26/500] Batch[5000/12648] complete. train_loss = 18.547770009613036
Epoch [26/500] Batch[5200/12648] complete. train_loss = 18.556698219959554
Epoch [26/500] Batch[5400/12648] complete. train_loss = 18.563039208518134
Epoch [26/500] Batch[5600/12648] complete. train_loss = 18.570104584012714
Epoch [26/500] Batch[5800/12648] complete. train_loss = 18.5754188879605
Epoch [26/500] Batch[6000/12648] complete. train_loss = 18.583204770406088
Epoch [26/500] Batch[6200/12648] complete. train_loss = 18.586802211884528
Epoch [26/500] Batch[6400/12648] complete. train_loss = 18.591984245181084
Epoch [26/500] Batch[6600/12648] complete. train_loss = 18.59887184634353
Epoch [26/500] Batch[6800/12648] complete. train_loss = 18.603405354163225
Epoch [26/500] Batch[7000/12648] complete. train_loss = 18.61043704359872
Epoch [26/500] Batch[7200/12648] complete. train_loss = 18.615391875108084
Epoch [26/500] Batch[7400/12648] complete. train_loss = 18.6203367055429
Epoch [26/500] Batch[7600/12648] complete. train_loss = 18.62311826981996
Epoch [26/500] Batch[7800/12648] complete. train_loss = 18.62770409779671
Epoch [26/500] Batch[8000/12648] complete. train_loss = 18.633595436573028
Epoch [26/500] Batch[8200/12648] complete. train_loss = 18.641165618896483
Epoch [26/500] Batch[8400/12648] complete. train_loss = 18.64704342751276
Epoch [26/500] Batch[8600/12648] complete. train_loss = 18.65282675610032
Epoch [26/500] Batch[8800/12648] complete. train_loss = 18.65676260362972
Epoch [26/500] Batch[9000/12648] complete. train_loss = 18.66242459932963
Epoch [26/500] Batch[9200/12648] complete. train_loss = 18.665656839868298
Epoch [26/500] Batch[9400/12648] complete. train_loss = 18.671788337991593
Epoch [26/500] Batch[9600/12648] complete. train_loss = 18.675123565594355
Epoch [26/500] Batch[9800/12648] complete. train_loss = 18.679557979739442
Epoch [26/500] Batch[10000/12648] complete. train_loss = 18.681711190223695
Epoch [26/500] Batch[10200/12648] complete. train_loss = 18.686329264734304
Epoch [26/500] Batch[10400/12648] complete. train_loss = 18.69301347915943
Epoch [26/500] Batch[10600/12648] complete. train_loss = 18.696869931670854
Epoch [26/500] Batch[10800/12648] complete. train_loss = 18.702953338093227
Epoch [26/500] Batch[11000/12648] complete. train_loss = 18.70660545799949
Epoch [26/500] Batch[11200/12648] complete. train_loss = 18.71071745106152
Epoch [26/500] Batch[11400/12648] complete. train_loss = 18.71525072315283
Epoch [26/500] Batch[11600/12648] complete. train_loss = 18.71871354990992
Epoch [26/500] Batch[11800/12648] complete. train_loss = 18.72277884111566
Epoch [26/500] Batch[12000/12648] complete. train_loss = 18.72640656042099
Epoch [26/500] Batch[12200/12648] complete. train_loss = 18.729992063084588
Epoch [26/500] Batch[12400/12648] complete. train_loss = 18.735018736162495
Epoch [26/500] Batch[12600/12648] complete. train_loss = 18.738713015147617
Epoch [26/500] Batch[12648/12648] complete. valid_loss = 19.531685829162598
best models saved
Best Valid Loss = 19.531685829162598 (Epoch: 26)


Epoch [27/500] Batch[200/12648] complete. train_loss = 18.13765456199646
Epoch [27/500] Batch[400/12648] complete. train_loss = 18.16453950405121
Epoch [27/500] Batch[600/12648] complete. train_loss = 18.233475624720256
Epoch [27/500] Batch[800/12648] complete. train_loss = 18.250050327777863
Epoch [27/500] Batch[1000/12648] complete. train_loss = 18.272485073089598
Epoch [27/500] Batch[1200/12648] complete. train_loss = 18.28532313664754
Epoch [27/500] Batch[1400/12648] complete. train_loss = 18.297385018212456
Epoch [27/500] Batch[1600/12648] complete. train_loss = 18.29856323122978
Epoch [27/500] Batch[1800/12648] complete. train_loss = 18.307115740246243
Epoch [27/500] Batch[2000/12648] complete. train_loss = 18.323478956222534
Epoch [27/500] Batch[2200/12648] complete. train_loss = 18.336815278313377
Epoch [27/500] Batch[2400/12648] complete. train_loss = 18.349667991002402
Epoch [27/500] Batch[2600/12648] complete. train_loss = 18.36011442257808
Epoch [27/500] Batch[2800/12648] complete. train_loss = 18.378528812953405
Epoch [27/500] Batch[3000/12648] complete. train_loss = 18.388038582483926
Epoch [27/500] Batch[3200/12648] complete. train_loss = 18.393013074994087
Epoch [27/500] Batch[3400/12648] complete. train_loss = 18.397052087783813
Epoch [27/500] Batch[3600/12648] complete. train_loss = 18.403438428243
Epoch [27/500] Batch[3800/12648] complete. train_loss = 18.40874872257835
Epoch [27/500] Batch[4000/12648] complete. train_loss = 18.416118649482726
Epoch [27/500] Batch[4200/12648] complete. train_loss = 18.420931489127025
Epoch [27/500] Batch[4400/12648] complete. train_loss = 18.4290843335065
Epoch [27/500] Batch[4600/12648] complete. train_loss = 18.43829307846401
Epoch [27/500] Batch[4800/12648] complete. train_loss = 18.44657960653305
Epoch [27/500] Batch[5000/12648] complete. train_loss = 18.45548751487732
Epoch [27/500] Batch[5200/12648] complete. train_loss = 18.465793071893547
Epoch [27/500] Batch[5400/12648] complete. train_loss = 18.474278187575162
Epoch [27/500] Batch[5600/12648] complete. train_loss = 18.480238753046308
Epoch [27/500] Batch[5800/12648] complete. train_loss = 18.487706438919595
Epoch [27/500] Batch[6000/12648] complete. train_loss = 18.49353174432119
Epoch [27/500] Batch[6200/12648] complete. train_loss = 18.499823765293243
Epoch [27/500] Batch[6400/12648] complete. train_loss = 18.507899574041367
Epoch [27/500] Batch[6600/12648] complete. train_loss = 18.51632099382805
Epoch [27/500] Batch[6800/12648] complete. train_loss = 18.52174520885243
Epoch [27/500] Batch[7000/12648] complete. train_loss = 18.526626522881646
Epoch [27/500] Batch[7200/12648] complete. train_loss = 18.533028718365564
Epoch [27/500] Batch[7400/12648] complete. train_loss = 18.54167331257382
Epoch [27/500] Batch[7600/12648] complete. train_loss = 18.5484826108029
Epoch [27/500] Batch[7800/12648] complete. train_loss = 18.553937683594533
Epoch [27/500] Batch[8000/12648] complete. train_loss = 18.56129398703575
Epoch [27/500] Batch[8200/12648] complete. train_loss = 18.56513595999741
Epoch [27/500] Batch[8400/12648] complete. train_loss = 18.569637166886103
Epoch [27/500] Batch[8600/12648] complete. train_loss = 18.57394768537477
Epoch [27/500] Batch[8800/12648] complete. train_loss = 18.577969703024085
Epoch [27/500] Batch[9000/12648] complete. train_loss = 18.580695581648087
Epoch [27/500] Batch[9200/12648] complete. train_loss = 18.585180221847867
Epoch [27/500] Batch[9400/12648] complete. train_loss = 18.588980687324035
Epoch [27/500] Batch[9600/12648] complete. train_loss = 18.593030860026676
Epoch [27/500] Batch[9800/12648] complete. train_loss = 18.594912747947536
Epoch [27/500] Batch[10000/12648] complete. train_loss = 18.59968658390045
Epoch [27/500] Batch[10200/12648] complete. train_loss = 18.604901569590847
Epoch [27/500] Batch[10400/12648] complete. train_loss = 18.609007280056293
Epoch [27/500] Batch[10600/12648] complete. train_loss = 18.613977242775682
Epoch [27/500] Batch[10800/12648] complete. train_loss = 18.618910961151123
Epoch [27/500] Batch[11000/12648] complete. train_loss = 18.62119016786055
Epoch [27/500] Batch[11200/12648] complete. train_loss = 18.625728283098766
Epoch [27/500] Batch[11400/12648] complete. train_loss = 18.629220116765875
Epoch [27/500] Batch[11600/12648] complete. train_loss = 18.632384769176614
Epoch [27/500] Batch[11800/12648] complete. train_loss = 18.63601921744266
Epoch [27/500] Batch[12000/12648] complete. train_loss = 18.639526428699494
Epoch [27/500] Batch[12200/12648] complete. train_loss = 18.643565064414602
Epoch [27/500] Batch[12400/12648] complete. train_loss = 18.647960557937623
Epoch [27/500] Batch[12600/12648] complete. train_loss = 18.65210920969645
Epoch [27/500] Batch[12648/12648] complete. valid_loss = 19.61611783504486
Epoch [28/500] Batch[200/12648] complete. train_loss = 18.261048135757445
Epoch [28/500] Batch[400/12648] complete. train_loss = 18.198284277915956
Epoch [28/500] Batch[600/12648] complete. train_loss = 18.194623028437295
Epoch [28/500] Batch[800/12648] complete. train_loss = 18.182686898708344
Epoch [28/500] Batch[1000/12648] complete. train_loss = 18.1748704624176
Epoch [28/500] Batch[1200/12648] complete. train_loss = 18.19626262505849
Epoch [28/500] Batch[1400/12648] complete. train_loss = 18.21008873803275
Epoch [28/500] Batch[1600/12648] complete. train_loss = 18.216913677453995
Epoch [28/500] Batch[1800/12648] complete. train_loss = 18.235554760826957
Epoch [28/500] Batch[2000/12648] complete. train_loss = 18.24618727016449
Epoch [28/500] Batch[2200/12648] complete. train_loss = 18.25478705666282
Epoch [28/500] Batch[2400/12648] complete. train_loss = 18.262481690247853
Epoch [28/500] Batch[2600/12648] complete. train_loss = 18.267613532726582
Epoch [28/500] Batch[2800/12648] complete. train_loss = 18.28171699660165
Epoch [28/500] Batch[3000/12648] complete. train_loss = 18.291614546457925
Epoch [28/500] Batch[3200/12648] complete. train_loss = 18.303037077188492
Epoch [28/500] Batch[3400/12648] complete. train_loss = 18.308907335505765
Epoch [28/500] Batch[3600/12648] complete. train_loss = 18.319528406461078
Epoch [28/500] Batch[3800/12648] complete. train_loss = 18.32612780872144
Epoch [28/500] Batch[4000/12648] complete. train_loss = 18.333438637256624
Epoch [28/500] Batch[4200/12648] complete. train_loss = 18.337463223593577
Epoch [28/500] Batch[4400/12648] complete. train_loss = 18.33870806607333
Epoch [28/500] Batch[4600/12648] complete. train_loss = 18.348773966250214
Epoch [28/500] Batch[4800/12648] complete. train_loss = 18.35752731839816
Epoch [28/500] Batch[5000/12648] complete. train_loss = 18.36792294883728
Epoch [28/500] Batch[5200/12648] complete. train_loss = 18.37271383909079
Epoch [28/500] Batch[5400/12648] complete. train_loss = 18.38337463308264
Epoch [28/500] Batch[5600/12648] complete. train_loss = 18.391539683001383
Epoch [28/500] Batch[5800/12648] complete. train_loss = 18.40229300860701
Epoch [28/500] Batch[6000/12648] complete. train_loss = 18.40826478099823
Epoch [28/500] Batch[6200/12648] complete. train_loss = 18.418547602007465
Epoch [28/500] Batch[6400/12648] complete. train_loss = 18.42166310727596
Epoch [28/500] Batch[6600/12648] complete. train_loss = 18.425612026272397
Epoch [28/500] Batch[6800/12648] complete. train_loss = 18.431594163389768
Epoch [28/500] Batch[7000/12648] complete. train_loss = 18.437384284973145
Epoch [28/500] Batch[7200/12648] complete. train_loss = 18.44294093185001
Epoch [28/500] Batch[7400/12648] complete. train_loss = 18.44817821915085
Epoch [28/500] Batch[7600/12648] complete. train_loss = 18.45597145532307
Epoch [28/500] Batch[7800/12648] complete. train_loss = 18.462389604128322
Epoch [28/500] Batch[8000/12648] complete. train_loss = 18.465971160411836
Epoch [28/500] Batch[8200/12648] complete. train_loss = 18.47105001658928
Epoch [28/500] Batch[8400/12648] complete. train_loss = 18.47577158950624
Epoch [28/500] Batch[8600/12648] complete. train_loss = 18.48007018532864
Epoch [28/500] Batch[8800/12648] complete. train_loss = 18.486241504495794
Epoch [28/500] Batch[9000/12648] complete. train_loss = 18.492111410776776
Epoch [28/500] Batch[9200/12648] complete. train_loss = 18.497143272731616
Epoch [28/500] Batch[9400/12648] complete. train_loss = 18.50190493969207
Epoch [28/500] Batch[9600/12648] complete. train_loss = 18.50697343448798
Epoch [28/500] Batch[9800/12648] complete. train_loss = 18.511133865823552
Epoch [28/500] Batch[10000/12648] complete. train_loss = 18.51580830345154
Epoch [28/500] Batch[10200/12648] complete. train_loss = 18.521414703668334
Epoch [28/500] Batch[10400/12648] complete. train_loss = 18.523842545839457
Epoch [28/500] Batch[10600/12648] complete. train_loss = 18.526917170038764
Epoch [28/500] Batch[10800/12648] complete. train_loss = 18.530749064551458
Epoch [28/500] Batch[11000/12648] complete. train_loss = 18.533363934603603
Epoch [28/500] Batch[11200/12648] complete. train_loss = 18.538153305905205
Epoch [28/500] Batch[11400/12648] complete. train_loss = 18.54080825036032
Epoch [28/500] Batch[11600/12648] complete. train_loss = 18.544867102359902
Epoch [28/500] Batch[11800/12648] complete. train_loss = 18.549283493332943
Epoch [28/500] Batch[12000/12648] complete. train_loss = 18.555082222779593
Epoch [28/500] Batch[12200/12648] complete. train_loss = 18.560734384098993
Epoch [28/500] Batch[12400/12648] complete. train_loss = 18.564810980366122
Epoch [28/500] Batch[12600/12648] complete. train_loss = 18.568627488726662
Epoch [28/500] Batch[12648/12648] complete. valid_loss = 19.603468418121338
Epoch [29/500] Batch[200/12648] complete. train_loss = 18.08159939289093
Epoch [29/500] Batch[400/12648] complete. train_loss = 18.096079428195953
Epoch [29/500] Batch[600/12648] complete. train_loss = 18.127657380104065
Epoch [29/500] Batch[800/12648] complete. train_loss = 18.102940479516985
Epoch [29/500] Batch[1000/12648] complete. train_loss = 18.115659863471986
Epoch [29/500] Batch[1200/12648] complete. train_loss = 18.11565945704778
Epoch [29/500] Batch[1400/12648] complete. train_loss = 18.126215573038372
Epoch [29/500] Batch[1600/12648] complete. train_loss = 18.146840765476227
Epoch [29/500] Batch[1800/12648] complete. train_loss = 18.15347486390008
Epoch [29/500] Batch[2000/12648] complete. train_loss = 18.15481284713745
Epoch [29/500] Batch[2200/12648] complete. train_loss = 18.162589713876898
Epoch [29/500] Batch[2400/12648] complete. train_loss = 18.175069576501848
Epoch [29/500] Batch[2600/12648] complete. train_loss = 18.18066836833954
Epoch [29/500] Batch[2800/12648] complete. train_loss = 18.19479410137449
Epoch [29/500] Batch[3000/12648] complete. train_loss = 18.20596054236094
Epoch [29/500] Batch[3200/12648] complete. train_loss = 18.21021099716425
Epoch [29/500] Batch[3400/12648] complete. train_loss = 18.21966488080866
Epoch [29/500] Batch[3600/12648] complete. train_loss = 18.231303027205996
Epoch [29/500] Batch[3800/12648] complete. train_loss = 18.239412967531305
Epoch [29/500] Batch[4000/12648] complete. train_loss = 18.247862849473954
Epoch [29/500] Batch[4200/12648] complete. train_loss = 18.25512864408039
Epoch [29/500] Batch[4400/12648] complete. train_loss = 18.262043133865703
Epoch [29/500] Batch[4600/12648] complete. train_loss = 18.27320970431618
Epoch [29/500] Batch[4800/12648] complete. train_loss = 18.279390744566918
Epoch [29/500] Batch[5000/12648] complete. train_loss = 18.288023574638366
Epoch [29/500] Batch[5200/12648] complete. train_loss = 18.294268419742583
Epoch [29/500] Batch[5400/12648] complete. train_loss = 18.301208293526262
Epoch [29/500] Batch[5600/12648] complete. train_loss = 18.305023110083173
Epoch [29/500] Batch[5800/12648] complete. train_loss = 18.31076558458394
Epoch [29/500] Batch[6000/12648] complete. train_loss = 18.319248616377514
Epoch [29/500] Batch[6200/12648] complete. train_loss = 18.324714425763776
Epoch [29/500] Batch[6400/12648] complete. train_loss = 18.32960907921195
Epoch [29/500] Batch[6600/12648] complete. train_loss = 18.336807844133087
Epoch [29/500] Batch[6800/12648] complete. train_loss = 18.340480079791124
Epoch [29/500] Batch[7000/12648] complete. train_loss = 18.34653087874821
Epoch [29/500] Batch[7200/12648] complete. train_loss = 18.352986485560734
Epoch [29/500] Batch[7400/12648] complete. train_loss = 18.358453056361224
Epoch [29/500] Batch[7600/12648] complete. train_loss = 18.36427791080977
Epoch [29/500] Batch[7800/12648] complete. train_loss = 18.37280223051707
Epoch [29/500] Batch[8000/12648] complete. train_loss = 18.379203477978706
Epoch [29/500] Batch[8200/12648] complete. train_loss = 18.38556290614896
Epoch [29/500] Batch[8400/12648] complete. train_loss = 18.391199525992075
Epoch [29/500] Batch[8600/12648] complete. train_loss = 18.39689410464708
Epoch [29/500] Batch[8800/12648] complete. train_loss = 18.403041304133154
Epoch [29/500] Batch[9000/12648] complete. train_loss = 18.406719879468284
Epoch [29/500] Batch[9200/12648] complete. train_loss = 18.40989091821339
Epoch [29/500] Batch[9400/12648] complete. train_loss = 18.414689258920387
Epoch [29/500] Batch[9600/12648] complete. train_loss = 18.42107861548662
Epoch [29/500] Batch[9800/12648] complete. train_loss = 18.426012150414135
Epoch [29/500] Batch[10000/12648] complete. train_loss = 18.429874642658234
Epoch [29/500] Batch[10200/12648] complete. train_loss = 18.43431160767873
Epoch [29/500] Batch[10400/12648] complete. train_loss = 18.438336206307778
Epoch [29/500] Batch[10600/12648] complete. train_loss = 18.442357011921
Epoch [29/500] Batch[10800/12648] complete. train_loss = 18.447874169791188
Epoch [29/500] Batch[11000/12648] complete. train_loss = 18.4532676449689
Epoch [29/500] Batch[11200/12648] complete. train_loss = 18.457372757792474
Epoch [29/500] Batch[11400/12648] complete. train_loss = 18.461485033286245
Epoch [29/500] Batch[11600/12648] complete. train_loss = 18.46629236558388
Epoch [29/500] Batch[11800/12648] complete. train_loss = 18.471559224128722
Epoch [29/500] Batch[12000/12648] complete. train_loss = 18.475328288634618
Epoch [29/500] Batch[12200/12648] complete. train_loss = 18.48036368643651
Epoch [29/500] Batch[12400/12648] complete. train_loss = 18.487707633126167
Epoch [29/500] Batch[12600/12648] complete. train_loss = 18.491528195199514
Epoch [29/500] Batch[12648/12648] complete. valid_loss = 19.585736513137817
Epoch [30/500] Batch[200/12648] complete. train_loss = 17.9747976064682
Epoch [30/500] Batch[400/12648] complete. train_loss = 17.997293293476105
Epoch [30/500] Batch[600/12648] complete. train_loss = 18.021687534650166
Epoch [30/500] Batch[800/12648] complete. train_loss = 18.046654349565507
Epoch [30/500] Batch[1000/12648] complete. train_loss = 18.039063532829285
Epoch [30/500] Batch[1200/12648] complete. train_loss = 18.05278172572454
Epoch [30/500] Batch[1400/12648] complete. train_loss = 18.062965730258398
Epoch [30/500] Batch[1600/12648] complete. train_loss = 18.073700385689737
Epoch [30/500] Batch[1800/12648] complete. train_loss = 18.086710109180874
Epoch [30/500] Batch[2000/12648] complete. train_loss = 18.101247770786287
Epoch [30/500] Batch[2200/12648] complete. train_loss = 18.110722957524388
Epoch [30/500] Batch[2400/12648] complete. train_loss = 18.122126747369766
Epoch [30/500] Batch[2600/12648] complete. train_loss = 18.127258442732003
Epoch [30/500] Batch[2800/12648] complete. train_loss = 18.134268985135215
Epoch [30/500] Batch[3000/12648] complete. train_loss = 18.152406737645467
Epoch [30/500] Batch[3200/12648] complete. train_loss = 18.155662217140197
Epoch [30/500] Batch[3400/12648] complete. train_loss = 18.1621313235339
Epoch [30/500] Batch[3600/12648] complete. train_loss = 18.17165786213345
Epoch [30/500] Batch[3800/12648] complete. train_loss = 18.180250636150962
Epoch [30/500] Batch[4000/12648] complete. train_loss = 18.190324387550355
Epoch [30/500] Batch[4200/12648] complete. train_loss = 18.19835819380624
Epoch [30/500] Batch[4400/12648] complete. train_loss = 18.20638623757796
Epoch [30/500] Batch[4600/12648] complete. train_loss = 18.210145226354186
Epoch [30/500] Batch[4800/12648] complete. train_loss = 18.216383530696234
Epoch [30/500] Batch[5000/12648] complete. train_loss = 18.225430875778198
Epoch [30/500] Batch[5200/12648] complete. train_loss = 18.233813571929932
Epoch [30/500] Batch[5400/12648] complete. train_loss = 18.240457178751626
Epoch [30/500] Batch[5600/12648] complete. train_loss = 18.24936025585447
Epoch [30/500] Batch[5800/12648] complete. train_loss = 18.25355386240729
Epoch [30/500] Batch[6000/12648] complete. train_loss = 18.260053409576415
Epoch [30/500] Batch[6200/12648] complete. train_loss = 18.264531933107683
Epoch [30/500] Batch[6400/12648] complete. train_loss = 18.269382086247205
Epoch [30/500] Batch[6600/12648] complete. train_loss = 18.272329290707905
Epoch [30/500] Batch[6800/12648] complete. train_loss = 18.27745126541923
Epoch [30/500] Batch[7000/12648] complete. train_loss = 18.28400825895582
Epoch [30/500] Batch[7200/12648] complete. train_loss = 18.290373761786356
Epoch [30/500] Batch[7400/12648] complete. train_loss = 18.29728713048471
Epoch [30/500] Batch[7600/12648] complete. train_loss = 18.301281995898798
Epoch [30/500] Batch[7800/12648] complete. train_loss = 18.305142603531863
Epoch [30/500] Batch[8000/12648] complete. train_loss = 18.31078680741787
Epoch [30/500] Batch[8200/12648] complete. train_loss = 18.316696910276647
Epoch [30/500] Batch[8400/12648] complete. train_loss = 18.324297339689164
Epoch [30/500] Batch[8600/12648] complete. train_loss = 18.330431528867678
Epoch [30/500] Batch[8800/12648] complete. train_loss = 18.332994555234908
Epoch [30/500] Batch[9000/12648] complete. train_loss = 18.33936100165049
Epoch [30/500] Batch[9200/12648] complete. train_loss = 18.344884168894396
Epoch [30/500] Batch[9400/12648] complete. train_loss = 18.348066890290443
Epoch [30/500] Batch[9600/12648] complete. train_loss = 18.352624871631463
Epoch [30/500] Batch[9800/12648] complete. train_loss = 18.358152909084243
Epoch [30/500] Batch[10000/12648] complete. train_loss = 18.362043957805632
Epoch [30/500] Batch[10200/12648] complete. train_loss = 18.3669213105183
Epoch [30/500] Batch[10400/12648] complete. train_loss = 18.372708571232284
Epoch [30/500] Batch[10600/12648] complete. train_loss = 18.377513307265517
Epoch [30/500] Batch[10800/12648] complete. train_loss = 18.381025837527382
Epoch [30/500] Batch[11000/12648] complete. train_loss = 18.38460262289914
Epoch [30/500] Batch[11200/12648] complete. train_loss = 18.388791823301997
Epoch [30/500] Batch[11400/12648] complete. train_loss = 18.393177320497077
Epoch [30/500] Batch[11600/12648] complete. train_loss = 18.399141133653707
Epoch [30/500] Batch[11800/12648] complete. train_loss = 18.40327776044102
Epoch [30/500] Batch[12000/12648] complete. train_loss = 18.409739832162856
Epoch [30/500] Batch[12200/12648] complete. train_loss = 18.41197055042767
Epoch [30/500] Batch[12400/12648] complete. train_loss = 18.415946343868008
Epoch [30/500] Batch[12600/12648] complete. train_loss = 18.422599771363394
Epoch [30/500] Batch[12648/12648] complete. valid_loss = 19.540624737739563
Epoch [31/500] Batch[200/12648] complete. train_loss = 17.881500158309937
Epoch [31/500] Batch[400/12648] complete. train_loss = 17.94701569080353
Epoch [31/500] Batch[600/12648] complete. train_loss = 17.93825744311015
Epoch [31/500] Batch[800/12648] complete. train_loss = 17.940528481006623
Epoch [31/500] Batch[1000/12648] complete. train_loss = 17.959118598937987
Epoch [31/500] Batch[1200/12648] complete. train_loss = 17.983588345050812
Epoch [31/500] Batch[1400/12648] complete. train_loss = 17.979872443335395
Epoch [31/500] Batch[1600/12648] complete. train_loss = 17.98096348762512
Epoch [31/500] Batch[1800/12648] complete. train_loss = 17.986330599255034
Epoch [31/500] Batch[2000/12648] complete. train_loss = 17.997158358573913
Epoch [31/500] Batch[2200/12648] complete. train_loss = 18.015205433585425
Epoch [31/500] Batch[2400/12648] complete. train_loss = 18.01592641711235
Epoch [31/500] Batch[2600/12648] complete. train_loss = 18.024803171524635
Epoch [31/500] Batch[2800/12648] complete. train_loss = 18.036646052428654
Epoch [31/500] Batch[3000/12648] complete. train_loss = 18.041278007825216
Epoch [31/500] Batch[3200/12648] complete. train_loss = 18.05419072240591
Epoch [31/500] Batch[3400/12648] complete. train_loss = 18.06956445048837
Epoch [31/500] Batch[3600/12648] complete. train_loss = 18.080296278794606
Epoch [31/500] Batch[3800/12648] complete. train_loss = 18.089293815964147
Epoch [31/500] Batch[4000/12648] complete. train_loss = 18.100819409132004
Epoch [31/500] Batch[4200/12648] complete. train_loss = 18.108544640086947
Epoch [31/500] Batch[4400/12648] complete. train_loss = 18.1181959011338
Epoch [31/500] Batch[4600/12648] complete. train_loss = 18.12590917939725
Epoch [31/500] Batch[4800/12648] complete. train_loss = 18.13638394097487
Epoch [31/500] Batch[5000/12648] complete. train_loss = 18.14119473133087
Epoch [31/500] Batch[5200/12648] complete. train_loss = 18.146257284787985
Epoch [31/500] Batch[5400/12648] complete. train_loss = 18.155630140127958
Epoch [31/500] Batch[5600/12648] complete. train_loss = 18.160416415929795
Epoch [31/500] Batch[5800/12648] complete. train_loss = 18.165002571467696
Epoch [31/500] Batch[6000/12648] complete. train_loss = 18.176114743073782
Epoch [31/500] Batch[6200/12648] complete. train_loss = 18.181615924373748
Epoch [31/500] Batch[6400/12648] complete. train_loss = 18.189431761950253
Epoch [31/500] Batch[6600/12648] complete. train_loss = 18.194834589380207
Epoch [31/500] Batch[6800/12648] complete. train_loss = 18.200738962538104
Epoch [31/500] Batch[7000/12648] complete. train_loss = 18.20716845716749
Epoch [31/500] Batch[7200/12648] complete. train_loss = 18.214640230735142
Epoch [31/500] Batch[7400/12648] complete. train_loss = 18.220371075063138
Epoch [31/500] Batch[7600/12648] complete. train_loss = 18.22817993000934
Epoch [31/500] Batch[7800/12648] complete. train_loss = 18.233313662088836
Epoch [31/500] Batch[8000/12648] complete. train_loss = 18.23794003069401
Epoch [31/500] Batch[8200/12648] complete. train_loss = 18.244589112095717
Epoch [31/500] Batch[8400/12648] complete. train_loss = 18.252107494558608
Epoch [31/500] Batch[8600/12648] complete. train_loss = 18.25472636522249
Epoch [31/500] Batch[8800/12648] complete. train_loss = 18.261446558887307
Epoch [31/500] Batch[9000/12648] complete. train_loss = 18.267744779692755
Epoch [31/500] Batch[9200/12648] complete. train_loss = 18.273124025697292
Epoch [31/500] Batch[9400/12648] complete. train_loss = 18.278149559244195
Epoch [31/500] Batch[9600/12648] complete. train_loss = 18.282973422308764
Epoch [31/500] Batch[9800/12648] complete. train_loss = 18.287980307267638
Epoch [31/500] Batch[10000/12648] complete. train_loss = 18.289962067508696
Epoch [31/500] Batch[10200/12648] complete. train_loss = 18.294257967799318
Epoch [31/500] Batch[10400/12648] complete. train_loss = 18.29947350181066
Epoch [31/500] Batch[10600/12648] complete. train_loss = 18.304291193170368
Epoch [31/500] Batch[10800/12648] complete. train_loss = 18.309337538701516
Epoch [31/500] Batch[11000/12648] complete. train_loss = 18.313539737614718
Epoch [31/500] Batch[11200/12648] complete. train_loss = 18.31727054519313
Epoch [31/500] Batch[11400/12648] complete. train_loss = 18.32189066401699
Epoch [31/500] Batch[11600/12648] complete. train_loss = 18.325727937961446
Epoch [31/500] Batch[11800/12648] complete. train_loss = 18.330990658776233
Epoch [31/500] Batch[12000/12648] complete. train_loss = 18.334810837745668
Epoch [31/500] Batch[12200/12648] complete. train_loss = 18.337074780229663
Epoch [31/500] Batch[12400/12648] complete. train_loss = 18.341372498850667
Epoch [31/500] Batch[12600/12648] complete. train_loss = 18.346119565358237
Epoch [31/500] Batch[12648/12648] complete. valid_loss = 19.647916078567505
Epoch [32/500] Batch[200/12648] complete. train_loss = 17.824832706451417
Epoch [32/500] Batch[400/12648] complete. train_loss = 17.832139635086058
Epoch [32/500] Batch[600/12648] complete. train_loss = 17.850340957641603
Epoch [32/500] Batch[800/12648] complete. train_loss = 17.851222267150877
Epoch [32/500] Batch[1000/12648] complete. train_loss = 17.87084055519104
Epoch [32/500] Batch[1200/12648] complete. train_loss = 17.88327600399653
Epoch [32/500] Batch[1400/12648] complete. train_loss = 17.905896248817445
Epoch [32/500] Batch[1600/12648] complete. train_loss = 17.923997558951378
Epoch [32/500] Batch[1800/12648] complete. train_loss = 17.94072934203678
Epoch [32/500] Batch[2000/12648] complete. train_loss = 17.956316355228424
Epoch [32/500] Batch[2200/12648] complete. train_loss = 17.961301912394436
Epoch [32/500] Batch[2400/12648] complete. train_loss = 17.96431538462639
Epoch [32/500] Batch[2600/12648] complete. train_loss = 17.978841531093305
Epoch [32/500] Batch[2800/12648] complete. train_loss = 17.993921101093292
Epoch [32/500] Batch[3000/12648] complete. train_loss = 18.00386521180471
Epoch [32/500] Batch[3200/12648] complete. train_loss = 18.01788356631994
Epoch [32/500] Batch[3400/12648] complete. train_loss = 18.02059522937326
Epoch [32/500] Batch[3600/12648] complete. train_loss = 18.029560534424252
Epoch [32/500] Batch[3800/12648] complete. train_loss = 18.03219883015281
Epoch [32/500] Batch[4000/12648] complete. train_loss = 18.038118544101714
Epoch [32/500] Batch[4200/12648] complete. train_loss = 18.049819425855365
Epoch [32/500] Batch[4400/12648] complete. train_loss = 18.055509366555647
Epoch [32/500] Batch[4600/12648] complete. train_loss = 18.063436810037363
Epoch [32/500] Batch[4800/12648] complete. train_loss = 18.07141362229983
Epoch [32/500] Batch[5000/12648] complete. train_loss = 18.077493325805666
Epoch [32/500] Batch[5200/12648] complete. train_loss = 18.084137776814973
Epoch [32/500] Batch[5400/12648] complete. train_loss = 18.092918545758284
Epoch [32/500] Batch[5600/12648] complete. train_loss = 18.100452999387468
Epoch [32/500] Batch[5800/12648] complete. train_loss = 18.108005269478106
Epoch [32/500] Batch[6000/12648] complete. train_loss = 18.11554432137807
Epoch [32/500] Batch[6200/12648] complete. train_loss = 18.123667880027526
Epoch [32/500] Batch[6400/12648] complete. train_loss = 18.131404429078103
Epoch [32/500] Batch[6600/12648] complete. train_loss = 18.139596836494675
Epoch [32/500] Batch[6800/12648] complete. train_loss = 18.145226467917947
Epoch [32/500] Batch[7000/12648] complete. train_loss = 18.15212538065229
Epoch [32/500] Batch[7200/12648] complete. train_loss = 18.15671974791421
Epoch [32/500] Batch[7400/12648] complete. train_loss = 18.16186113434869
Epoch [32/500] Batch[7600/12648] complete. train_loss = 18.17078411102295
Epoch [32/500] Batch[7800/12648] complete. train_loss = 18.17450391329252
Epoch [32/500] Batch[8000/12648] complete. train_loss = 18.180045622825624
Epoch [32/500] Batch[8200/12648] complete. train_loss = 18.18693652013453
Epoch [32/500] Batch[8400/12648] complete. train_loss = 18.191339259147643
Epoch [32/500] Batch[8600/12648] complete. train_loss = 18.195139331374058
Epoch [32/500] Batch[8800/12648] complete. train_loss = 18.199535771066493
Epoch [32/500] Batch[9000/12648] complete. train_loss = 18.204761507034302
Epoch [32/500] Batch[9200/12648] complete. train_loss = 18.210167417940887
Epoch [32/500] Batch[9400/12648] complete. train_loss = 18.216880979335055
Epoch [32/500] Batch[9600/12648] complete. train_loss = 18.222558207511902
Epoch [32/500] Batch[9800/12648] complete. train_loss = 18.22734573052854
Epoch [32/500] Batch[10000/12648] complete. train_loss = 18.23171446762085
Epoch [32/500] Batch[10200/12648] complete. train_loss = 18.236863046720917
Epoch [32/500] Batch[10400/12648] complete. train_loss = 18.241545048677004
Epoch [32/500] Batch[10600/12648] complete. train_loss = 18.245353032777896
Epoch [32/500] Batch[10800/12648] complete. train_loss = 18.24750478673864
Epoch [32/500] Batch[11000/12648] complete. train_loss = 18.251351201144132
Epoch [32/500] Batch[11200/12648] complete. train_loss = 18.25427007113184
Epoch [32/500] Batch[11400/12648] complete. train_loss = 18.25764931394343
Epoch [32/500] Batch[11600/12648] complete. train_loss = 18.261667385430172
Epoch [32/500] Batch[11800/12648] complete. train_loss = 18.26693200111389
Epoch [32/500] Batch[12000/12648] complete. train_loss = 18.270776445865632
Epoch [32/500] Batch[12200/12648] complete. train_loss = 18.274080700483477
Epoch [32/500] Batch[12400/12648] complete. train_loss = 18.278580057390275
Epoch [32/500] Batch[12600/12648] complete. train_loss = 18.28129337795197
Epoch [32/500] Batch[12648/12648] complete. valid_loss = 19.612834215164185
Epoch [33/500] Batch[200/12648] complete. train_loss = 17.85004593849182
Epoch [33/500] Batch[400/12648] complete. train_loss = 17.81577126502991
Epoch [33/500] Batch[600/12648] complete. train_loss = 17.83366022904714
Epoch [33/500] Batch[800/12648] complete. train_loss = 17.861549615859985
Epoch [33/500] Batch[1000/12648] complete. train_loss = 17.860731294631957
Epoch [33/500] Batch[1200/12648] complete. train_loss = 17.874382190704345
Epoch [33/500] Batch[1400/12648] complete. train_loss = 17.87896494592939
Epoch [33/500] Batch[1600/12648] complete. train_loss = 17.87751169681549
Epoch [33/500] Batch[1800/12648] complete. train_loss = 17.889565302530926
Epoch [33/500] Batch[2000/12648] complete. train_loss = 17.898447728157045
Epoch [33/500] Batch[2200/12648] complete. train_loss = 17.909859932119197
Epoch [33/500] Batch[2400/12648] complete. train_loss = 17.914918365478517
Epoch [33/500] Batch[2600/12648] complete. train_loss = 17.921709990134605
Epoch [33/500] Batch[2800/12648] complete. train_loss = 17.925737119742802
Epoch [33/500] Batch[3000/12648] complete. train_loss = 17.9351489572525
Epoch [33/500] Batch[3200/12648] complete. train_loss = 17.945207754671575
Epoch [33/500] Batch[3400/12648] complete. train_loss = 17.94612105622011
Epoch [33/500] Batch[3600/12648] complete. train_loss = 17.95672690709432
Epoch [33/500] Batch[3800/12648] complete. train_loss = 17.966864058343987
Epoch [33/500] Batch[4000/12648] complete. train_loss = 17.975036139965056
Epoch [33/500] Batch[4200/12648] complete. train_loss = 17.984523706209092
Epoch [33/500] Batch[4400/12648] complete. train_loss = 17.990517179532485
Epoch [33/500] Batch[4600/12648] complete. train_loss = 17.996798309450565
Epoch [33/500] Batch[4800/12648] complete. train_loss = 18.005032024582228
Epoch [33/500] Batch[5000/12648] complete. train_loss = 18.012579200553894
Epoch [33/500] Batch[5200/12648] complete. train_loss = 18.022056138515474
Epoch [33/500] Batch[5400/12648] complete. train_loss = 18.028135300565648
Epoch [33/500] Batch[5600/12648] complete. train_loss = 18.033423396348955
Epoch [33/500] Batch[5800/12648] complete. train_loss = 18.040130769959813
Epoch [33/500] Batch[6000/12648] complete. train_loss = 18.04828748877843
Epoch [33/500] Batch[6200/12648] complete. train_loss = 18.055488466293582
Epoch [33/500] Batch[6400/12648] complete. train_loss = 18.06138284429908
Epoch [33/500] Batch[6600/12648] complete. train_loss = 18.067073483756094
Epoch [33/500] Batch[6800/12648] complete. train_loss = 18.073942886941573
Epoch [33/500] Batch[7000/12648] complete. train_loss = 18.079236647060938
Epoch [33/500] Batch[7200/12648] complete. train_loss = 18.082943441470466
Epoch [33/500] Batch[7400/12648] complete. train_loss = 18.09026101434553
Epoch [33/500] Batch[7600/12648] complete. train_loss = 18.09586360843558
Epoch [33/500] Batch[7800/12648] complete. train_loss = 18.0995162828152
Epoch [33/500] Batch[8000/12648] complete. train_loss = 18.106865904211997
Epoch [33/500] Batch[8200/12648] complete. train_loss = 18.111034760940367
Epoch [33/500] Batch[8400/12648] complete. train_loss = 18.11711532944725
Epoch [33/500] Batch[8600/12648] complete. train_loss = 18.122671242758287
Epoch [33/500] Batch[8800/12648] complete. train_loss = 18.12744317499074
Epoch [33/500] Batch[9000/12648] complete. train_loss = 18.132999815517003
Epoch [33/500] Batch[9200/12648] complete. train_loss = 18.13974858087042
Epoch [33/500] Batch[9400/12648] complete. train_loss = 18.145283518750617
Epoch [33/500] Batch[9600/12648] complete. train_loss = 18.149289114574593
Epoch [33/500] Batch[9800/12648] complete. train_loss = 18.15460708822523
Epoch [33/500] Batch[10000/12648] complete. train_loss = 18.160914980220795
Epoch [33/500] Batch[10200/12648] complete. train_loss = 18.166493806745493
Epoch [33/500] Batch[10400/12648] complete. train_loss = 18.170835715899102
Epoch [33/500] Batch[10600/12648] complete. train_loss = 18.175282295245044
Epoch [33/500] Batch[10800/12648] complete. train_loss = 18.178847070535024
Epoch [33/500] Batch[11000/12648] complete. train_loss = 18.18252760601044
Epoch [33/500] Batch[11200/12648] complete. train_loss = 18.188621109809194
Epoch [33/500] Batch[11400/12648] complete. train_loss = 18.191245243591176
Epoch [33/500] Batch[11600/12648] complete. train_loss = 18.19687937859831
Epoch [33/500] Batch[11800/12648] complete. train_loss = 18.201823137331818
Epoch [33/500] Batch[12000/12648] complete. train_loss = 18.20514264623324
Epoch [33/500] Batch[12200/12648] complete. train_loss = 18.208948074168845
Epoch [33/500] Batch[12400/12648] complete. train_loss = 18.21250128522996
Epoch [33/500] Batch[12600/12648] complete. train_loss = 18.215131191450453
Epoch [33/500] Batch[12648/12648] complete. valid_loss = 19.596351861953735
Epoch [34/500] Batch[200/12648] complete. train_loss = 17.710160517692564
Epoch [34/500] Batch[400/12648] complete. train_loss = 17.7032653260231
Epoch [34/500] Batch[600/12648] complete. train_loss = 17.738942783673604
Epoch [34/500] Batch[800/12648] complete. train_loss = 17.7510575902462
Epoch [34/500] Batch[1000/12648] complete. train_loss = 17.77541908168793
Epoch [34/500] Batch[1200/12648] complete. train_loss = 17.792356682618458
Epoch [34/500] Batch[1400/12648] complete. train_loss = 17.798869592802866
Epoch [34/500] Batch[1600/12648] complete. train_loss = 17.81638147830963
Epoch [34/500] Batch[1800/12648] complete. train_loss = 17.80895745860206
Epoch [34/500] Batch[2000/12648] complete. train_loss = 17.818777243614196
Epoch [34/500] Batch[2200/12648] complete. train_loss = 17.824917472926053
Epoch [34/500] Batch[2400/12648] complete. train_loss = 17.83070232987404
Epoch [34/500] Batch[2600/12648] complete. train_loss = 17.83964523608868
Epoch [34/500] Batch[2800/12648] complete. train_loss = 17.848630375521523
Epoch [34/500] Batch[3000/12648] complete. train_loss = 17.86000055472056
Epoch [34/500] Batch[3200/12648] complete. train_loss = 17.871370476186275
Epoch [34/500] Batch[3400/12648] complete. train_loss = 17.878928821788115
Epoch [34/500] Batch[3600/12648] complete. train_loss = 17.885580667389764
Epoch [34/500] Batch[3800/12648] complete. train_loss = 17.895441454335263
Epoch [34/500] Batch[4000/12648] complete. train_loss = 17.897270572185516
Epoch [34/500] Batch[4200/12648] complete. train_loss = 17.903743114017306
Epoch [34/500] Batch[4400/12648] complete. train_loss = 17.911966000903735
Epoch [34/500] Batch[4600/12648] complete. train_loss = 17.918186595336252
Epoch [34/500] Batch[4800/12648] complete. train_loss = 17.928122856616973
Epoch [34/500] Batch[5000/12648] complete. train_loss = 17.93919955368042
Epoch [34/500] Batch[5200/12648] complete. train_loss = 17.94770719399819
Epoch [34/500] Batch[5400/12648] complete. train_loss = 17.95666697625761
Epoch [34/500] Batch[5600/12648] complete. train_loss = 17.965057493788855
Epoch [34/500] Batch[5800/12648] complete. train_loss = 17.97119414132217
Epoch [34/500] Batch[6000/12648] complete. train_loss = 17.979331167697907
Epoch [34/500] Batch[6200/12648] complete. train_loss = 17.989455740374904
Epoch [34/500] Batch[6400/12648] complete. train_loss = 17.99489190414548
Epoch [34/500] Batch[6600/12648] complete. train_loss = 17.998456641832988
Epoch [34/500] Batch[6800/12648] complete. train_loss = 18.00586147182128
Epoch [34/500] Batch[7000/12648] complete. train_loss = 18.012309230395726
Epoch [34/500] Batch[7200/12648] complete. train_loss = 18.01826420399878
Epoch [34/500] Batch[7400/12648] complete. train_loss = 18.024643850970914
Epoch [34/500] Batch[7600/12648] complete. train_loss = 18.02901964400944
Epoch [34/500] Batch[7800/12648] complete. train_loss = 18.033848020969295
Epoch [34/500] Batch[8000/12648] complete. train_loss = 18.04030376660824
Epoch [34/500] Batch[8200/12648] complete. train_loss = 18.04512723352851
Epoch [34/500] Batch[8400/12648] complete. train_loss = 18.049042610781534
Epoch [34/500] Batch[8600/12648] complete. train_loss = 18.055636185823484
Epoch [34/500] Batch[8800/12648] complete. train_loss = 18.05950374115597
Epoch [34/500] Batch[9000/12648] complete. train_loss = 18.065809255282083
Epoch [34/500] Batch[9200/12648] complete. train_loss = 18.07007607035015
Epoch [34/500] Batch[9400/12648] complete. train_loss = 18.075105909083753
Epoch [34/500] Batch[9600/12648] complete. train_loss = 18.080803496738273
Epoch [34/500] Batch[9800/12648] complete. train_loss = 18.085495271001545
Epoch [34/500] Batch[10000/12648] complete. train_loss = 18.089453450870515
Epoch [34/500] Batch[10200/12648] complete. train_loss = 18.0973303528393
Epoch [34/500] Batch[10400/12648] complete. train_loss = 18.103113877314787
Epoch [34/500] Batch[10600/12648] complete. train_loss = 18.109408294839678
Epoch [34/500] Batch[10800/12648] complete. train_loss = 18.115750499743
Epoch [34/500] Batch[11000/12648] complete. train_loss = 18.12054434230111
Epoch [34/500] Batch[11200/12648] complete. train_loss = 18.124282776543073
Epoch [34/500] Batch[11400/12648] complete. train_loss = 18.12884274775522
Epoch [34/500] Batch[11600/12648] complete. train_loss = 18.133485845615123
Epoch [34/500] Batch[11800/12648] complete. train_loss = 18.1384820106474
Epoch [34/500] Batch[12000/12648] complete. train_loss = 18.143747545957567
Epoch [34/500] Batch[12200/12648] complete. train_loss = 18.148132100730646
Epoch [34/500] Batch[12400/12648] complete. train_loss = 18.152296369229592
Epoch [34/500] Batch[12600/12648] complete. train_loss = 18.155397609301975
Epoch [34/500] Batch[12648/12648] complete. valid_loss = 19.617491006851196
Epoch [35/500] Batch[200/12648] complete. train_loss = 17.676429438591004
Epoch [35/500] Batch[400/12648] complete. train_loss = 17.6632022190094
Epoch [35/500] Batch[600/12648] complete. train_loss = 17.65702367623647
Epoch [35/500] Batch[800/12648] complete. train_loss = 17.648169038295745
Epoch [35/500] Batch[1000/12648] complete. train_loss = 17.658135018348695
Epoch [35/500] Batch[1200/12648] complete. train_loss = 17.65749738136927
Epoch [35/500] Batch[1400/12648] complete. train_loss = 17.672869151660375
Epoch [35/500] Batch[1600/12648] complete. train_loss = 17.683196162581442
Epoch [35/500] Batch[1800/12648] complete. train_loss = 17.693951982392207
Epoch [35/500] Batch[2000/12648] complete. train_loss = 17.717157690525056
Epoch [35/500] Batch[2200/12648] complete. train_loss = 17.733824190226468
Epoch [35/500] Batch[2400/12648] complete. train_loss = 17.741116429567338
Epoch [35/500] Batch[2600/12648] complete. train_loss = 17.745100932121275
Epoch [35/500] Batch[2800/12648] complete. train_loss = 17.76302782365254
Epoch [35/500] Batch[3000/12648] complete. train_loss = 17.76996985530853
Epoch [35/500] Batch[3200/12648] complete. train_loss = 17.77969458848238
Epoch [35/500] Batch[3400/12648] complete. train_loss = 17.785230963931365
Epoch [35/500] Batch[3600/12648] complete. train_loss = 17.796366688675352
Epoch [35/500] Batch[3800/12648] complete. train_loss = 17.80484287989767
Epoch [35/500] Batch[4000/12648] complete. train_loss = 17.81397843337059
Epoch [35/500] Batch[4200/12648] complete. train_loss = 17.832595620155335
Epoch [35/500] Batch[4400/12648] complete. train_loss = 17.843130145939913
Epoch [35/500] Batch[4600/12648] complete. train_loss = 17.855384586168373
Epoch [35/500] Batch[4800/12648] complete. train_loss = 17.866089724500974
Epoch [35/500] Batch[5000/12648] complete. train_loss = 17.86918945789337
Epoch [35/500] Batch[5200/12648] complete. train_loss = 17.876905289063085
Epoch [35/500] Batch[5400/12648] complete. train_loss = 17.886363307811596
Epoch [35/500] Batch[5600/12648] complete. train_loss = 17.889107597896032
Epoch [35/500] Batch[5800/12648] complete. train_loss = 17.896740839070286
Epoch [35/500] Batch[6000/12648] complete. train_loss = 17.90468022823334
Epoch [35/500] Batch[6200/12648] complete. train_loss = 17.910499738570184
Epoch [35/500] Batch[6400/12648] complete. train_loss = 17.920594147443772
Epoch [35/500] Batch[6600/12648] complete. train_loss = 17.929243364334106
Epoch [35/500] Batch[6800/12648] complete. train_loss = 17.936299833129436
Epoch [35/500] Batch[7000/12648] complete. train_loss = 17.942638038090298
Epoch [35/500] Batch[7200/12648] complete. train_loss = 17.947558506329855
Epoch [35/500] Batch[7400/12648] complete. train_loss = 17.95240634969763
Epoch [35/500] Batch[7600/12648] complete. train_loss = 17.958548164618644
Epoch [35/500] Batch[7800/12648] complete. train_loss = 17.96408778215066
Epoch [35/500] Batch[8000/12648] complete. train_loss = 17.970664272546767
Epoch [35/500] Batch[8200/12648] complete. train_loss = 17.975326108234686
Epoch [35/500] Batch[8400/12648] complete. train_loss = 17.982171072278703
Epoch [35/500] Batch[8600/12648] complete. train_loss = 17.988478352524513
Epoch [35/500] Batch[8800/12648] complete. train_loss = 17.995709853605792
Epoch [35/500] Batch[9000/12648] complete. train_loss = 18.002231934653388
Epoch [35/500] Batch[9200/12648] complete. train_loss = 18.00757144762122
Epoch [35/500] Batch[9400/12648] complete. train_loss = 18.01395485046062
Epoch [35/500] Batch[9600/12648] complete. train_loss = 18.020748759508134
Epoch [35/500] Batch[9800/12648] complete. train_loss = 18.024095362449177
Epoch [35/500] Batch[10000/12648] complete. train_loss = 18.030211477661133
Epoch [35/500] Batch[10200/12648] complete. train_loss = 18.03759684413087
Epoch [35/500] Batch[10400/12648] complete. train_loss = 18.043604744947874
Epoch [35/500] Batch[10600/12648] complete. train_loss = 18.04780576022166
Epoch [35/500] Batch[10800/12648] complete. train_loss = 18.052629737324185
Epoch [35/500] Batch[11000/12648] complete. train_loss = 18.058529718225653
Epoch [35/500] Batch[11200/12648] complete. train_loss = 18.0643128488745
Epoch [35/500] Batch[11400/12648] complete. train_loss = 18.068038672397012
Epoch [35/500] Batch[11600/12648] complete. train_loss = 18.07287640374282
Epoch [35/500] Batch[11800/12648] complete. train_loss = 18.07735837984893
Epoch [35/500] Batch[12000/12648] complete. train_loss = 18.082307804107668
Epoch [35/500] Batch[12200/12648] complete. train_loss = 18.08804359779983
Epoch [35/500] Batch[12400/12648] complete. train_loss = 18.092034540791666
Epoch [35/500] Batch[12600/12648] complete. train_loss = 18.096648610735695
Epoch [35/500] Batch[12648/12648] complete. valid_loss = 19.62636947631836
Epoch [36/500] Batch[200/12648] complete. train_loss = 17.570827808380127
Epoch [36/500] Batch[400/12648] complete. train_loss = 17.55836276292801
Epoch [36/500] Batch[600/12648] complete. train_loss = 17.581596789360045
Epoch [36/500] Batch[800/12648] complete. train_loss = 17.612815531492235
Epoch [36/500] Batch[1000/12648] complete. train_loss = 17.621160630226136
Epoch [36/500] Batch[1200/12648] complete. train_loss = 17.641767018636067
Epoch [36/500] Batch[1400/12648] complete. train_loss = 17.65145820072719
Epoch [36/500] Batch[1600/12648] complete. train_loss = 17.66376520872116
Epoch [36/500] Batch[1800/12648] complete. train_loss = 17.67077619181739
Epoch [36/500] Batch[2000/12648] complete. train_loss = 17.682761662006378
Epoch [36/500] Batch[2200/12648] complete. train_loss = 17.697962674661117
Epoch [36/500] Batch[2400/12648] complete. train_loss = 17.708965748548508
Epoch [36/500] Batch[2600/12648] complete. train_loss = 17.721981680943415
Epoch [36/500] Batch[2800/12648] complete. train_loss = 17.736905653136116
Epoch [36/500] Batch[3000/12648] complete. train_loss = 17.737667905807495
Epoch [36/500] Batch[3200/12648] complete. train_loss = 17.743432569205762
Epoch [36/500] Batch[3400/12648] complete. train_loss = 17.751023828001582
Epoch [36/500] Batch[3600/12648] complete. train_loss = 17.757734288904402
Epoch [36/500] Batch[3800/12648] complete. train_loss = 17.769473311524642
Epoch [36/500] Batch[4000/12648] complete. train_loss = 17.77981776213646
Epoch [36/500] Batch[4200/12648] complete. train_loss = 17.78698522476923
Epoch [36/500] Batch[4400/12648] complete. train_loss = 17.79717771660198
Epoch [36/500] Batch[4600/12648] complete. train_loss = 17.80486320288285
Epoch [36/500] Batch[4800/12648] complete. train_loss = 17.812630605300267
Epoch [36/500] Batch[5000/12648] complete. train_loss = 17.822743850708008
Epoch [36/500] Batch[5200/12648] complete. train_loss = 17.83218481687399
Epoch [36/500] Batch[5400/12648] complete. train_loss = 17.84266468330666
Epoch [36/500] Batch[5600/12648] complete. train_loss = 17.851417652538846
Epoch [36/500] Batch[5800/12648] complete. train_loss = 17.85863489677166
Epoch [36/500] Batch[6000/12648] complete. train_loss = 17.864578033447266
Epoch [36/500] Batch[6200/12648] complete. train_loss = 17.871911161484256
Epoch [36/500] Batch[6400/12648] complete. train_loss = 17.880085424780845
Epoch [36/500] Batch[6600/12648] complete. train_loss = 17.886082109104503
Epoch [36/500] Batch[6800/12648] complete. train_loss = 17.893628986302545
Epoch [36/500] Batch[7000/12648] complete. train_loss = 17.900799651282174
Epoch [36/500] Batch[7200/12648] complete. train_loss = 17.905419489542645
Epoch [36/500] Batch[7400/12648] complete. train_loss = 17.9123770242124
Epoch [36/500] Batch[7600/12648] complete. train_loss = 17.920860088749937
Epoch [36/500] Batch[7800/12648] complete. train_loss = 17.926150608551808
Epoch [36/500] Batch[8000/12648] complete. train_loss = 17.931076020479203
Epoch [36/500] Batch[8200/12648] complete. train_loss = 17.93367204340493
Epoch [36/500] Batch[8400/12648] complete. train_loss = 17.939609575044543
Epoch [36/500] Batch[8600/12648] complete. train_loss = 17.945452416442162
Epoch [36/500] Batch[8800/12648] complete. train_loss = 17.949714074026456
Epoch [36/500] Batch[9000/12648] complete. train_loss = 17.954918063587613
Epoch [36/500] Batch[9200/12648] complete. train_loss = 17.960943945283475
Epoch [36/500] Batch[9400/12648] complete. train_loss = 17.964999417142664
Epoch [36/500] Batch[9600/12648] complete. train_loss = 17.968376348714035
Epoch [36/500] Batch[9800/12648] complete. train_loss = 17.974116552411292
Epoch [36/500] Batch[10000/12648] complete. train_loss = 17.978866659641266
Epoch [36/500] Batch[10200/12648] complete. train_loss = 17.981355222720726
Epoch [36/500] Batch[10400/12648] complete. train_loss = 17.985937747496823
Epoch [36/500] Batch[10600/12648] complete. train_loss = 17.992819880809424
Epoch [36/500] Batch[10800/12648] complete. train_loss = 17.997613576518166
Epoch [36/500] Batch[11000/12648] complete. train_loss = 18.003218387690456
Epoch [36/500] Batch[11200/12648] complete. train_loss = 18.007041370442934
Epoch [36/500] Batch[11400/12648] complete. train_loss = 18.012133089868644
Epoch [36/500] Batch[11600/12648] complete. train_loss = 18.016189832851804
Epoch [36/500] Batch[11800/12648] complete. train_loss = 18.02108096041922
Epoch [36/500] Batch[12000/12648] complete. train_loss = 18.02423943456014
Epoch [36/500] Batch[12200/12648] complete. train_loss = 18.030194360858104
Epoch [36/500] Batch[12400/12648] complete. train_loss = 18.03521492350486
Epoch [36/500] Batch[12600/12648] complete. train_loss = 18.040177886523896
Epoch [36/500] Batch[12648/12648] complete. valid_loss = 19.658924102783203
Epoch [37/500] Batch[200/12648] complete. train_loss = 17.559215259552
Epoch [37/500] Batch[400/12648] complete. train_loss = 17.56024819135666
Epoch [37/500] Batch[600/12648] complete. train_loss = 17.568462521235148
Epoch [37/500] Batch[800/12648] complete. train_loss = 17.588954473733903
Epoch [37/500] Batch[1000/12648] complete. train_loss = 17.597723649024964
Epoch [37/500] Batch[1200/12648] complete. train_loss = 17.59587406158447
Epoch [37/500] Batch[1400/12648] complete. train_loss = 17.619113758632114
Epoch [37/500] Batch[1600/12648] complete. train_loss = 17.62520603775978
Epoch [37/500] Batch[1800/12648] complete. train_loss = 17.633912244902717
Epoch [37/500] Batch[2000/12648] complete. train_loss = 17.648240529060363
Epoch [37/500] Batch[2200/12648] complete. train_loss = 17.65778774694963
Epoch [37/500] Batch[2400/12648] complete. train_loss = 17.674872763554255
Epoch [37/500] Batch[2600/12648] complete. train_loss = 17.68039090339954
Epoch [37/500] Batch[2800/12648] complete. train_loss = 17.694921938010623
Epoch [37/500] Batch[3000/12648] complete. train_loss = 17.7014131453832
Epoch [37/500] Batch[3200/12648] complete. train_loss = 17.7134784501791
Epoch [37/500] Batch[3400/12648] complete. train_loss = 17.720449206969317
Epoch [37/500] Batch[3600/12648] complete. train_loss = 17.73421754413181
Epoch [37/500] Batch[3800/12648] complete. train_loss = 17.739356666364166
Epoch [37/500] Batch[4000/12648] complete. train_loss = 17.747140664100648
Epoch [37/500] Batch[4200/12648] complete. train_loss = 17.752764940488905
Epoch [37/500] Batch[4400/12648] complete. train_loss = 17.76237963481383
Epoch [37/500] Batch[4600/12648] complete. train_loss = 17.76662168254023
Epoch [37/500] Batch[4800/12648] complete. train_loss = 17.772712903022764
Epoch [37/500] Batch[5000/12648] complete. train_loss = 17.779121118736267
Epoch [37/500] Batch[5200/12648] complete. train_loss = 17.784862635869246
Epoch [37/500] Batch[5400/12648] complete. train_loss = 17.790512196046336
Epoch [37/500] Batch[5600/12648] complete. train_loss = 17.798720174006053
Epoch [37/500] Batch[5800/12648] complete. train_loss = 17.807761262531937
Epoch [37/500] Batch[6000/12648] complete. train_loss = 17.816679346879322
Epoch [37/500] Batch[6200/12648] complete. train_loss = 17.824152386265418
Epoch [37/500] Batch[6400/12648] complete. train_loss = 17.826815533638
Epoch [37/500] Batch[6600/12648] complete. train_loss = 17.83247249386527
Epoch [37/500] Batch[6800/12648] complete. train_loss = 17.838092068503883
Epoch [37/500] Batch[7000/12648] complete. train_loss = 17.845356943402972
Epoch [37/500] Batch[7200/12648] complete. train_loss = 17.85235984934701
Epoch [37/500] Batch[7400/12648] complete. train_loss = 17.858219466596037
Epoch [37/500] Batch[7600/12648] complete. train_loss = 17.865924460511458
Epoch [37/500] Batch[7800/12648] complete. train_loss = 17.872480449676512
Epoch [37/500] Batch[8000/12648] complete. train_loss = 17.878544318914415
Epoch [37/500] Batch[8200/12648] complete. train_loss = 17.883339373658345
Epoch [37/500] Batch[8400/12648] complete. train_loss = 17.888782129060655
Epoch [37/500] Batch[8600/12648] complete. train_loss = 17.89100504165472
Epoch [37/500] Batch[8800/12648] complete. train_loss = 17.894685691920195
Epoch [37/500] Batch[9000/12648] complete. train_loss = 17.896909657584295
Epoch [37/500] Batch[9200/12648] complete. train_loss = 17.902239188318667
Epoch [37/500] Batch[9400/12648] complete. train_loss = 17.90890673982336
Epoch [37/500] Batch[9600/12648] complete. train_loss = 17.91343509376049
Epoch [37/500] Batch[9800/12648] complete. train_loss = 17.91812088002964
Epoch [37/500] Batch[10000/12648] complete. train_loss = 17.92260830869675
Epoch [37/500] Batch[10200/12648] complete. train_loss = 17.92884150607913
Epoch [37/500] Batch[10400/12648] complete. train_loss = 17.932010274942105
Epoch [37/500] Batch[10600/12648] complete. train_loss = 17.937464414902454
Epoch [37/500] Batch[10800/12648] complete. train_loss = 17.943081814712947
Epoch [37/500] Batch[11000/12648] complete. train_loss = 17.947979969978334
Epoch [37/500] Batch[11200/12648] complete. train_loss = 17.951693279317446
Epoch [37/500] Batch[11400/12648] complete. train_loss = 17.95618066009722
Epoch [37/500] Batch[11600/12648] complete. train_loss = 17.96003305722927
Epoch [37/500] Batch[11800/12648] complete. train_loss = 17.965469840421516
Epoch [37/500] Batch[12000/12648] complete. train_loss = 17.96950051275889
Epoch [37/500] Batch[12200/12648] complete. train_loss = 17.974328977553572
Epoch [37/500] Batch[12400/12648] complete. train_loss = 17.97876842137306
Epoch [37/500] Batch[12600/12648] complete. train_loss = 17.98357583749862
Epoch [37/500] Batch[12648/12648] complete. valid_loss = 19.621164083480835
Epoch [38/500] Batch[200/12648] complete. train_loss = 17.52984058380127
Epoch [38/500] Batch[400/12648] complete. train_loss = 17.51805572748184
Epoch [38/500] Batch[600/12648] complete. train_loss = 17.483498101234435
Epoch [38/500] Batch[800/12648] complete. train_loss = 17.502912522554396
Epoch [38/500] Batch[1000/12648] complete. train_loss = 17.516771848678587
Epoch [38/500] Batch[1200/12648] complete. train_loss = 17.54381193558375
Epoch [38/500] Batch[1400/12648] complete. train_loss = 17.546775072642735
Epoch [38/500] Batch[1600/12648] complete. train_loss = 17.569911847114565
Epoch [38/500] Batch[1800/12648] complete. train_loss = 17.582278911802504
Epoch [38/500] Batch[2000/12648] complete. train_loss = 17.587119868278503
Epoch [38/500] Batch[2200/12648] complete. train_loss = 17.598665103478865
Epoch [38/500] Batch[2400/12648] complete. train_loss = 17.60842432061831
Epoch [38/500] Batch[2600/12648] complete. train_loss = 17.616297290875362
Epoch [38/500] Batch[2800/12648] complete. train_loss = 17.63142681019647
Epoch [38/500] Batch[3000/12648] complete. train_loss = 17.636430322329204
Epoch [38/500] Batch[3200/12648] complete. train_loss = 17.644984185397625
Epoch [38/500] Batch[3400/12648] complete. train_loss = 17.656176082667184
Epoch [38/500] Batch[3600/12648] complete. train_loss = 17.669346458382076
Epoch [38/500] Batch[3800/12648] complete. train_loss = 17.67424316079993
Epoch [38/500] Batch[4000/12648] complete. train_loss = 17.680375077962875
Epoch [38/500] Batch[4200/12648] complete. train_loss = 17.690498073441642
Epoch [38/500] Batch[4400/12648] complete. train_loss = 17.698211765072564
Epoch [38/500] Batch[4600/12648] complete. train_loss = 17.703647035308506
Epoch [38/500] Batch[4800/12648] complete. train_loss = 17.71096078256766
Epoch [38/500] Batch[5000/12648] complete. train_loss = 17.719728524589538
Epoch [38/500] Batch[5200/12648] complete. train_loss = 17.727196129101973
Epoch [38/500] Batch[5400/12648] complete. train_loss = 17.731466316293787
Epoch [38/500] Batch[5600/12648] complete. train_loss = 17.73984348842076
Epoch [38/500] Batch[5800/12648] complete. train_loss = 17.74863386515913
Epoch [38/500] Batch[6000/12648] complete. train_loss = 17.755203584512074
Epoch [38/500] Batch[6200/12648] complete. train_loss = 17.76107595797508
Epoch [38/500] Batch[6400/12648] complete. train_loss = 17.767428608983757
Epoch [38/500] Batch[6600/12648] complete. train_loss = 17.773323045932884
Epoch [38/500] Batch[6800/12648] complete. train_loss = 17.778853056290572
Epoch [38/500] Batch[7000/12648] complete. train_loss = 17.783722526550292
Epoch [38/500] Batch[7200/12648] complete. train_loss = 17.789903990427653
Epoch [38/500] Batch[7400/12648] complete. train_loss = 17.79713335965131
Epoch [38/500] Batch[7600/12648] complete. train_loss = 17.80119970171075
Epoch [38/500] Batch[7800/12648] complete. train_loss = 17.806996201246214
Epoch [38/500] Batch[8000/12648] complete. train_loss = 17.810796452999114
Epoch [38/500] Batch[8200/12648] complete. train_loss = 17.816085247411962
Epoch [38/500] Batch[8400/12648] complete. train_loss = 17.821351940631867
Epoch [38/500] Batch[8600/12648] complete. train_loss = 17.827454335744992
Epoch [38/500] Batch[8800/12648] complete. train_loss = 17.831330223083498
Epoch [38/500] Batch[9000/12648] complete. train_loss = 17.83565829647912
Epoch [38/500] Batch[9200/12648] complete. train_loss = 17.83991214596707
Epoch [38/500] Batch[9400/12648] complete. train_loss = 17.847205389002536
Epoch [38/500] Batch[9600/12648] complete. train_loss = 17.852475212315717
Epoch [38/500] Batch[9800/12648] complete. train_loss = 17.85908560626361
Epoch [38/500] Batch[10000/12648] complete. train_loss = 17.865356640911102
Epoch [38/500] Batch[10200/12648] complete. train_loss = 17.8704640082752
Epoch [38/500] Batch[10400/12648] complete. train_loss = 17.87509469279876
Epoch [38/500] Batch[10600/12648] complete. train_loss = 17.88067479646431
Epoch [38/500] Batch[10800/12648] complete. train_loss = 17.885466988793127
Epoch [38/500] Batch[11000/12648] complete. train_loss = 17.891195369286972
Epoch [38/500] Batch[11200/12648] complete. train_loss = 17.897189606683593
Epoch [38/500] Batch[11400/12648] complete. train_loss = 17.901028093957063
Epoch [38/500] Batch[11600/12648] complete. train_loss = 17.90582267522812
Epoch [38/500] Batch[11800/12648] complete. train_loss = 17.909696027383966
Epoch [38/500] Batch[12000/12648] complete. train_loss = 17.913955972512564
Epoch [38/500] Batch[12200/12648] complete. train_loss = 17.91870663267667
Epoch [38/500] Batch[12400/12648] complete. train_loss = 17.92232214373927
Epoch [38/500] Batch[12600/12648] complete. train_loss = 17.928464452198572
Epoch [38/500] Batch[12648/12648] complete. valid_loss = 19.633768320083618
Epoch [39/500] Batch[200/12648] complete. train_loss = 17.44046233177185
Epoch [39/500] Batch[400/12648] complete. train_loss = 17.423616194725035
Epoch [39/500] Batch[600/12648] complete. train_loss = 17.421868449846905
Epoch [39/500] Batch[800/12648] complete. train_loss = 17.467073361873627
Epoch [39/500] Batch[1000/12648] complete. train_loss = 17.48449885749817
Epoch [39/500] Batch[1200/12648] complete. train_loss = 17.491092599232992
Epoch [39/500] Batch[1400/12648] complete. train_loss = 17.509362932613918
Epoch [39/500] Batch[1600/12648] complete. train_loss = 17.52825634717941
Epoch [39/500] Batch[1800/12648] complete. train_loss = 17.525254101223418
Epoch [39/500] Batch[2000/12648] complete. train_loss = 17.542616021633147
Epoch [39/500] Batch[2200/12648] complete. train_loss = 17.557657315080817
Epoch [39/500] Batch[2400/12648] complete. train_loss = 17.56080414533615
Epoch [39/500] Batch[2600/12648] complete. train_loss = 17.568368050868695
Epoch [39/500] Batch[2800/12648] complete. train_loss = 17.583499927180153
Epoch [39/500] Batch[3000/12648] complete. train_loss = 17.59191493447622
Epoch [39/500] Batch[3200/12648] complete. train_loss = 17.606677908301354
Epoch [39/500] Batch[3400/12648] complete. train_loss = 17.619514124814202
Epoch [39/500] Batch[3600/12648] complete. train_loss = 17.626110621558297
Epoch [39/500] Batch[3800/12648] complete. train_loss = 17.63763621982775
Epoch [39/500] Batch[4000/12648] complete. train_loss = 17.644202768325805
Epoch [39/500] Batch[4200/12648] complete. train_loss = 17.649453590483894
Epoch [39/500] Batch[4400/12648] complete. train_loss = 17.658580019907518
Epoch [39/500] Batch[4600/12648] complete. train_loss = 17.66450498394344
Epoch [39/500] Batch[4800/12648] complete. train_loss = 17.66909543255965
Epoch [39/500] Batch[5000/12648] complete. train_loss = 17.677060239601136
Epoch [39/500] Batch[5200/12648] complete. train_loss = 17.683727172154647
Epoch [39/500] Batch[5400/12648] complete. train_loss = 17.692988548102203
Epoch [39/500] Batch[5600/12648] complete. train_loss = 17.698960304430553
Epoch [39/500] Batch[5800/12648] complete. train_loss = 17.704655001574547
Epoch [39/500] Batch[6000/12648] complete. train_loss = 17.709721519470214
Epoch [39/500] Batch[6200/12648] complete. train_loss = 17.714577472133023
Epoch [39/500] Batch[6400/12648] complete. train_loss = 17.723773650228978
Epoch [39/500] Batch[6600/12648] complete. train_loss = 17.730384810043105
Epoch [39/500] Batch[6800/12648] complete. train_loss = 17.73430693275788
Epoch [39/500] Batch[7000/12648] complete. train_loss = 17.739986265318734
Epoch [39/500] Batch[7200/12648] complete. train_loss = 17.744801118241416
Epoch [39/500] Batch[7400/12648] complete. train_loss = 17.748159121822667
Epoch [39/500] Batch[7600/12648] complete. train_loss = 17.752717240107685
Epoch [39/500] Batch[7800/12648] complete. train_loss = 17.7564663032385
Epoch [39/500] Batch[8000/12648] complete. train_loss = 17.76325506031513
Epoch [39/500] Batch[8200/12648] complete. train_loss = 17.769013000697626
Epoch [39/500] Batch[8400/12648] complete. train_loss = 17.773742343698228
Epoch [39/500] Batch[8600/12648] complete. train_loss = 17.77803309119025
Epoch [39/500] Batch[8800/12648] complete. train_loss = 17.78107985128056
Epoch [39/500] Batch[9000/12648] complete. train_loss = 17.786862940470378
Epoch [39/500] Batch[9200/12648] complete. train_loss = 17.79075362848199
Epoch [39/500] Batch[9400/12648] complete. train_loss = 17.79763266056142
Epoch [39/500] Batch[9600/12648] complete. train_loss = 17.802195528944335
Epoch [39/500] Batch[9800/12648] complete. train_loss = 17.807726715632846
Epoch [39/500] Batch[10000/12648] complete. train_loss = 17.813107378864288
Epoch [39/500] Batch[10200/12648] complete. train_loss = 17.81871009312424
Epoch [39/500] Batch[10400/12648] complete. train_loss = 17.825149107437866
Epoch [39/500] Batch[10600/12648] complete. train_loss = 17.830514654573406
Epoch [39/500] Batch[10800/12648] complete. train_loss = 17.833555451764
Epoch [39/500] Batch[11000/12648] complete. train_loss = 17.839062705906954
Epoch [39/500] Batch[11200/12648] complete. train_loss = 17.842368935431754
Epoch [39/500] Batch[11400/12648] complete. train_loss = 17.846125887402316
Epoch [39/500] Batch[11600/12648] complete. train_loss = 17.850624644920742
Epoch [39/500] Batch[11800/12648] complete. train_loss = 17.856615171917415
Epoch [39/500] Batch[12000/12648] complete. train_loss = 17.860358050107955
Epoch [39/500] Batch[12200/12648] complete. train_loss = 17.866601353238842
Epoch [39/500] Batch[12400/12648] complete. train_loss = 17.87004146660528
Epoch [39/500] Batch[12600/12648] complete. train_loss = 17.875507264742776
Epoch [39/500] Batch[12648/12648] complete. valid_loss = 19.60551917552948
Epoch [40/500] Batch[200/12648] complete. train_loss = 17.366528935432434
Epoch [40/500] Batch[400/12648] complete. train_loss = 17.35254200696945
Epoch [40/500] Batch[600/12648] complete. train_loss = 17.37682922999064
Epoch [40/500] Batch[800/12648] complete. train_loss = 17.398838181495666
Epoch [40/500] Batch[1000/12648] complete. train_loss = 17.418971450805664
Epoch [40/500] Batch[1200/12648] complete. train_loss = 17.41558577219645
Epoch [40/500] Batch[1400/12648] complete. train_loss = 17.423766934531077
Epoch [40/500] Batch[1600/12648] complete. train_loss = 17.450910642147065
Epoch [40/500] Batch[1800/12648] complete. train_loss = 17.460470220777722
Epoch [40/500] Batch[2000/12648] complete. train_loss = 17.47230930519104
Epoch [40/500] Batch[2200/12648] complete. train_loss = 17.484892455881294
Epoch [40/500] Batch[2400/12648] complete. train_loss = 17.49125087618828
Epoch [40/500] Batch[2600/12648] complete. train_loss = 17.506272841967068
Epoch [40/500] Batch[2800/12648] complete. train_loss = 17.520151926789964
Epoch [40/500] Batch[3000/12648] complete. train_loss = 17.528815309206646
Epoch [40/500] Batch[3200/12648] complete. train_loss = 17.539687560498713
Epoch [40/500] Batch[3400/12648] complete. train_loss = 17.550167849765103
Epoch [40/500] Batch[3600/12648] complete. train_loss = 17.55397683037652
Epoch [40/500] Batch[3800/12648] complete. train_loss = 17.55938492072256
Epoch [40/500] Batch[4000/12648] complete. train_loss = 17.569237194538115
Epoch [40/500] Batch[4200/12648] complete. train_loss = 17.580358620371136
Epoch [40/500] Batch[4400/12648] complete. train_loss = 17.58854866396297
Epoch [40/500] Batch[4600/12648] complete. train_loss = 17.596077272373698
Epoch [40/500] Batch[4800/12648] complete. train_loss = 17.602606653173765
Epoch [40/500] Batch[5000/12648] complete. train_loss = 17.608017223548888
Epoch [40/500] Batch[5200/12648] complete. train_loss = 17.61495733829645
Epoch [40/500] Batch[5400/12648] complete. train_loss = 17.622788695759244
Epoch [40/500] Batch[5600/12648] complete. train_loss = 17.62873595714569
Epoch [40/500] Batch[5800/12648] complete. train_loss = 17.63633133773146
Epoch [40/500] Batch[6000/12648] complete. train_loss = 17.643271095434823
Epoch [40/500] Batch[6200/12648] complete. train_loss = 17.650715096535222
Epoch [40/500] Batch[6400/12648] complete. train_loss = 17.66111585855484
Epoch [40/500] Batch[6600/12648] complete. train_loss = 17.66975392038172
Epoch [40/500] Batch[6800/12648] complete. train_loss = 17.67566756879582
Epoch [40/500] Batch[7000/12648] complete. train_loss = 17.680784187725614
Epoch [40/500] Batch[7200/12648] complete. train_loss = 17.686690909730064
Epoch [40/500] Batch[7400/12648] complete. train_loss = 17.69361585501078
Epoch [40/500] Batch[7600/12648] complete. train_loss = 17.701273438679543
Epoch [40/500] Batch[7800/12648] complete. train_loss = 17.708077154281813
Epoch [40/500] Batch[8000/12648] complete. train_loss = 17.714753244519233
Epoch [40/500] Batch[8200/12648] complete. train_loss = 17.718075763306967
Epoch [40/500] Batch[8400/12648] complete. train_loss = 17.723025983742307
Epoch [40/500] Batch[8600/12648] complete. train_loss = 17.729513944914174
Epoch [40/500] Batch[8800/12648] complete. train_loss = 17.734202907410534
Epoch [40/500] Batch[9000/12648] complete. train_loss = 17.739057100719876
Epoch [40/500] Batch[9200/12648] complete. train_loss = 17.74595990098041
Epoch [40/500] Batch[9400/12648] complete. train_loss = 17.750479949180114
Epoch [40/500] Batch[9600/12648] complete. train_loss = 17.757581856648127
Epoch [40/500] Batch[9800/12648] complete. train_loss = 17.763512951013993
Epoch [40/500] Batch[10000/12648] complete. train_loss = 17.769679609298706
Epoch [40/500] Batch[10200/12648] complete. train_loss = 17.774134924832513
Epoch [40/500] Batch[10400/12648] complete. train_loss = 17.780852806751543
Epoch [40/500] Batch[10600/12648] complete. train_loss = 17.78439258125593
Epoch [40/500] Batch[10800/12648] complete. train_loss = 17.78937020919941
Epoch [40/500] Batch[11000/12648] complete. train_loss = 17.7943908849196
Epoch [40/500] Batch[11200/12648] complete. train_loss = 17.79930054817881
Epoch [40/500] Batch[11400/12648] complete. train_loss = 17.80318259925173
Epoch [40/500] Batch[11600/12648] complete. train_loss = 17.807806361297082
Epoch [40/500] Batch[11800/12648] complete. train_loss = 17.81081028073521
Epoch [40/500] Batch[12000/12648] complete. train_loss = 17.815634929656984
Epoch [40/500] Batch[12200/12648] complete. train_loss = 17.81934940994763
Epoch [40/500] Batch[12400/12648] complete. train_loss = 17.824593816880256
Epoch [40/500] Batch[12600/12648] complete. train_loss = 17.828510728866334
Epoch [40/500] Batch[12648/12648] complete. valid_loss = 19.646974325180054
Epoch [41/500] Batch[200/12648] complete. train_loss = 17.28350028514862
Epoch [41/500] Batch[400/12648] complete. train_loss = 17.28673526763916
Epoch [41/500] Batch[600/12648] complete. train_loss = 17.31874036471049
Epoch [41/500] Batch[800/12648] complete. train_loss = 17.335231375694274
Epoch [41/500] Batch[1000/12648] complete. train_loss = 17.348002471923827
Epoch [41/500] Batch[1200/12648] complete. train_loss = 17.37092446724574
Epoch [41/500] Batch[1400/12648] complete. train_loss = 17.387670328957693
Epoch [41/500] Batch[1600/12648] complete. train_loss = 17.404348145723343
Epoch [41/500] Batch[1800/12648] complete. train_loss = 17.406802241007487
Epoch [41/500] Batch[2000/12648] complete. train_loss = 17.41712243461609
Epoch [41/500] Batch[2200/12648] complete. train_loss = 17.426404643492265
Epoch [41/500] Batch[2400/12648] complete. train_loss = 17.445532622337343
Epoch [41/500] Batch[2600/12648] complete. train_loss = 17.456896258867705
Epoch [41/500] Batch[2800/12648] complete. train_loss = 17.461431945051466
Epoch [41/500] Batch[3000/12648] complete. train_loss = 17.47559299278259
Epoch [41/500] Batch[3200/12648] complete. train_loss = 17.48093208283186
Epoch [41/500] Batch[3400/12648] complete. train_loss = 17.49133353429682
Epoch [41/500] Batch[3600/12648] complete. train_loss = 17.4982423737314
Epoch [41/500] Batch[3800/12648] complete. train_loss = 17.504869878417566
Epoch [41/500] Batch[4000/12648] complete. train_loss = 17.514538898468018
Epoch [41/500] Batch[4200/12648] complete. train_loss = 17.520314407121568
Epoch [41/500] Batch[4400/12648] complete. train_loss = 17.527355141422966
Epoch [41/500] Batch[4600/12648] complete. train_loss = 17.53631216215051
Epoch [41/500] Batch[4800/12648] complete. train_loss = 17.54446301062902
Epoch [41/500] Batch[5000/12648] complete. train_loss = 17.554179741859436
Epoch [41/500] Batch[5200/12648] complete. train_loss = 17.56025761769368
Epoch [41/500] Batch[5400/12648] complete. train_loss = 17.566121956860577
Epoch [41/500] Batch[5600/12648] complete. train_loss = 17.575844955103737
Epoch [41/500] Batch[5800/12648] complete. train_loss = 17.5855915396789
Epoch [41/500] Batch[6000/12648] complete. train_loss = 17.594242377122242
Epoch [41/500] Batch[6200/12648] complete. train_loss = 17.601146133022922
Epoch [41/500] Batch[6400/12648] complete. train_loss = 17.608187384456397
Epoch [41/500] Batch[6600/12648] complete. train_loss = 17.617405217922094
Epoch [41/500] Batch[6800/12648] complete. train_loss = 17.62336478219313
Epoch [41/500] Batch[7000/12648] complete. train_loss = 17.63131234264374
Epoch [41/500] Batch[7200/12648] complete. train_loss = 17.635511525736916
Epoch [41/500] Batch[7400/12648] complete. train_loss = 17.64510563257578
Epoch [41/500] Batch[7600/12648] complete. train_loss = 17.64922740898634
Epoch [41/500] Batch[7800/12648] complete. train_loss = 17.65589217528319
Epoch [41/500] Batch[8000/12648] complete. train_loss = 17.659640865325926
Epoch [41/500] Batch[8200/12648] complete. train_loss = 17.66598991126549
Epoch [41/500] Batch[8400/12648] complete. train_loss = 17.673218603020622
Epoch [41/500] Batch[8600/12648] complete. train_loss = 17.67876583132633
Epoch [41/500] Batch[8800/12648] complete. train_loss = 17.685422928008165
Epoch [41/500] Batch[9000/12648] complete. train_loss = 17.69185016579098
Epoch [41/500] Batch[9200/12648] complete. train_loss = 17.698227384712386
Epoch [41/500] Batch[9400/12648] complete. train_loss = 17.70296618329718
Epoch [41/500] Batch[9600/12648] complete. train_loss = 17.706188790897528
Epoch [41/500] Batch[9800/12648] complete. train_loss = 17.711662308342603
Epoch [41/500] Batch[10000/12648] complete. train_loss = 17.716918469619753
Epoch [41/500] Batch[10200/12648] complete. train_loss = 17.722308548572016
Epoch [41/500] Batch[10400/12648] complete. train_loss = 17.727252064393117
Epoch [41/500] Batch[10600/12648] complete. train_loss = 17.73264259185431
Epoch [41/500] Batch[10800/12648] complete. train_loss = 17.737800060819698
Epoch [41/500] Batch[11000/12648] complete. train_loss = 17.741962082169273
Epoch [41/500] Batch[11200/12648] complete. train_loss = 17.745991491845675
Epoch [41/500] Batch[11400/12648] complete. train_loss = 17.75232747973057
Epoch [41/500] Batch[11600/12648] complete. train_loss = 17.75663894546443
Epoch [41/500] Batch[11800/12648] complete. train_loss = 17.762015092009204
Epoch [41/500] Batch[12000/12648] complete. train_loss = 17.768353870153426
Epoch [41/500] Batch[12200/12648] complete. train_loss = 17.77161946664091
Epoch [41/500] Batch[12400/12648] complete. train_loss = 17.776634315829124
Epoch [41/500] Batch[12600/12648] complete. train_loss = 17.781121931832935
Epoch [41/500] Batch[12648/12648] complete. valid_loss = 19.70378351211548
Epoch [42/500] Batch[200/12648] complete. train_loss = 17.133863615989686
Epoch [42/500] Batch[400/12648] complete. train_loss = 17.212144248485565
Epoch [42/500] Batch[600/12648] complete. train_loss = 17.279315582911174
Epoch [42/500] Batch[800/12648] complete. train_loss = 17.293809571266173
Epoch [42/500] Batch[1000/12648] complete. train_loss = 17.3186933965683
Epoch [42/500] Batch[1200/12648] complete. train_loss = 17.346206726233163
Epoch [42/500] Batch[1400/12648] complete. train_loss = 17.351307851927622
Epoch [42/500] Batch[1600/12648] complete. train_loss = 17.38230701625347
Epoch [42/500] Batch[1800/12648] complete. train_loss = 17.39152231693268
Epoch [42/500] Batch[2000/12648] complete. train_loss = 17.4051080327034
Epoch [42/500] Batch[2200/12648] complete. train_loss = 17.411489816145462
Epoch [42/500] Batch[2400/12648] complete. train_loss = 17.419380726416907
Epoch [42/500] Batch[2600/12648] complete. train_loss = 17.427313950978792
Epoch [42/500] Batch[2800/12648] complete. train_loss = 17.43571710041591
Epoch [42/500] Batch[3000/12648] complete. train_loss = 17.4464690990448
Epoch [42/500] Batch[3200/12648] complete. train_loss = 17.4574846714735
Epoch [42/500] Batch[3400/12648] complete. train_loss = 17.468280591123243
Epoch [42/500] Batch[3600/12648] complete. train_loss = 17.47393765476015
Epoch [42/500] Batch[3800/12648] complete. train_loss = 17.48230942073621
Epoch [42/500] Batch[4000/12648] complete. train_loss = 17.492188368320466
Epoch [42/500] Batch[4200/12648] complete. train_loss = 17.497844296182905
Epoch [42/500] Batch[4400/12648] complete. train_loss = 17.504789818633686
Epoch [42/500] Batch[4600/12648] complete. train_loss = 17.512906477762304
Epoch [42/500] Batch[4800/12648] complete. train_loss = 17.520877636472385
Epoch [42/500] Batch[5000/12648] complete. train_loss = 17.527329240989687
Epoch [42/500] Batch[5200/12648] complete. train_loss = 17.531620976741497
Epoch [42/500] Batch[5400/12648] complete. train_loss = 17.536124379193343
Epoch [42/500] Batch[5600/12648] complete. train_loss = 17.544000332525798
Epoch [42/500] Batch[5800/12648] complete. train_loss = 17.54992399182813
Epoch [42/500] Batch[6000/12648] complete. train_loss = 17.557295926888784
Epoch [42/500] Batch[6200/12648] complete. train_loss = 17.565345376537692
Epoch [42/500] Batch[6400/12648] complete. train_loss = 17.571858749985694
Epoch [42/500] Batch[6600/12648] complete. train_loss = 17.57948721741185
Epoch [42/500] Batch[6800/12648] complete. train_loss = 17.586116109735826
Epoch [42/500] Batch[7000/12648] complete. train_loss = 17.593132716451372
Epoch [42/500] Batch[7200/12648] complete. train_loss = 17.599981302817664
Epoch [42/500] Batch[7400/12648] complete. train_loss = 17.603780403910456
Epoch [42/500] Batch[7600/12648] complete. train_loss = 17.608384271169964
Epoch [42/500] Batch[7800/12648] complete. train_loss = 17.61251240094503
Epoch [42/500] Batch[8000/12648] complete. train_loss = 17.619437214374543
Epoch [42/500] Batch[8200/12648] complete. train_loss = 17.62450428009033
Epoch [42/500] Batch[8400/12648] complete. train_loss = 17.63045730783826
Epoch [42/500] Batch[8600/12648] complete. train_loss = 17.637398488577023
Epoch [42/500] Batch[8800/12648] complete. train_loss = 17.642751725370232
Epoch [42/500] Batch[9000/12648] complete. train_loss = 17.647817573123508
Epoch [42/500] Batch[9200/12648] complete. train_loss = 17.653691028512043
Epoch [42/500] Batch[9400/12648] complete. train_loss = 17.65790138833066
Epoch [42/500] Batch[9600/12648] complete. train_loss = 17.663010567824045
Epoch [42/500] Batch[9800/12648] complete. train_loss = 17.667837471475405
Epoch [42/500] Batch[10000/12648] complete. train_loss = 17.67361884994507
Epoch [42/500] Batch[10200/12648] complete. train_loss = 17.67989977275624
Epoch [42/500] Batch[10400/12648] complete. train_loss = 17.685383018346933
Epoch [42/500] Batch[10600/12648] complete. train_loss = 17.690697595488352
Epoch [42/500] Batch[10800/12648] complete. train_loss = 17.6963694885042
Epoch [42/500] Batch[11000/12648] complete. train_loss = 17.700706839474766
Epoch [42/500] Batch[11200/12648] complete. train_loss = 17.706836953163148
Epoch [42/500] Batch[11400/12648] complete. train_loss = 17.712311986287435
Epoch [42/500] Batch[11600/12648] complete. train_loss = 17.716806147674035
Epoch [42/500] Batch[11800/12648] complete. train_loss = 17.722319430173453
Epoch [42/500] Batch[12000/12648] complete. train_loss = 17.725478198369345
Epoch [42/500] Batch[12200/12648] complete. train_loss = 17.72846936233708
Epoch [42/500] Batch[12400/12648] complete. train_loss = 17.73223855087834
Epoch [42/500] Batch[12600/12648] complete. train_loss = 17.734690261492652
Epoch [42/500] Batch[12648/12648] complete. valid_loss = 19.666470766067505
Epoch [43/500] Batch[200/12648] complete. train_loss = 17.23347056388855
Epoch [43/500] Batch[400/12648] complete. train_loss = 17.265528831481934
Epoch [43/500] Batch[600/12648] complete. train_loss = 17.28930930773417
Epoch [43/500] Batch[800/12648] complete. train_loss = 17.296328674554825
Epoch [43/500] Batch[1000/12648] complete. train_loss = 17.318636623382567
Epoch [43/500] Batch[1200/12648] complete. train_loss = 17.323093476295472
Epoch [43/500] Batch[1400/12648] complete. train_loss = 17.337258485385348
Epoch [43/500] Batch[1600/12648] complete. train_loss = 17.342251317501066
Epoch [43/500] Batch[1800/12648] complete. train_loss = 17.344535912407768
Epoch [43/500] Batch[2000/12648] complete. train_loss = 17.34970427083969
Epoch [43/500] Batch[2200/12648] complete. train_loss = 17.36273227258162
Epoch [43/500] Batch[2400/12648] complete. train_loss = 17.367894164323808
Epoch [43/500] Batch[2600/12648] complete. train_loss = 17.373411611777087
Epoch [43/500] Batch[2800/12648] complete. train_loss = 17.382822463512422
Epoch [43/500] Batch[3000/12648] complete. train_loss = 17.392683250745137
Epoch [43/500] Batch[3200/12648] complete. train_loss = 17.407323250472544
Epoch [43/500] Batch[3400/12648] complete. train_loss = 17.417833348162034
Epoch [43/500] Batch[3600/12648] complete. train_loss = 17.429420448144278
Epoch [43/500] Batch[3800/12648] complete. train_loss = 17.437458602503725
Epoch [43/500] Batch[4000/12648] complete. train_loss = 17.44551972055435
Epoch [43/500] Batch[4200/12648] complete. train_loss = 17.451240563619706
Epoch [43/500] Batch[4400/12648] complete. train_loss = 17.458150043921037
Epoch [43/500] Batch[4600/12648] complete. train_loss = 17.464792726558187
Epoch [43/500] Batch[4800/12648] complete. train_loss = 17.4726296488444
Epoch [43/500] Batch[5000/12648] complete. train_loss = 17.482884857177734
Epoch [43/500] Batch[5200/12648] complete. train_loss = 17.486734110758857
Epoch [43/500] Batch[5400/12648] complete. train_loss = 17.495625204156948
Epoch [43/500] Batch[5600/12648] complete. train_loss = 17.50178345833506
Epoch [43/500] Batch[5800/12648] complete. train_loss = 17.50584837107823
Epoch [43/500] Batch[6000/12648] complete. train_loss = 17.51158657884598
Epoch [43/500] Batch[6200/12648] complete. train_loss = 17.520343607164197
Epoch [43/500] Batch[6400/12648] complete. train_loss = 17.526195737570525
Epoch [43/500] Batch[6600/12648] complete. train_loss = 17.536173123590874
Epoch [43/500] Batch[6800/12648] complete. train_loss = 17.541539863137636
Epoch [43/500] Batch[7000/12648] complete. train_loss = 17.54745756667001
Epoch [43/500] Batch[7200/12648] complete. train_loss = 17.55289862950643
Epoch [43/500] Batch[7400/12648] complete. train_loss = 17.56011748288129
Epoch [43/500] Batch[7600/12648] complete. train_loss = 17.56662776558023
Epoch [43/500] Batch[7800/12648] complete. train_loss = 17.57072102363293
Epoch [43/500] Batch[8000/12648] complete. train_loss = 17.57404019343853
Epoch [43/500] Batch[8200/12648] complete. train_loss = 17.580738933028243
Epoch [43/500] Batch[8400/12648] complete. train_loss = 17.584100792635056
Epoch [43/500] Batch[8600/12648] complete. train_loss = 17.589501001335854
Epoch [43/500] Batch[8800/12648] complete. train_loss = 17.59417928392237
Epoch [43/500] Batch[9000/12648] complete. train_loss = 17.600264579349094
Epoch [43/500] Batch[9200/12648] complete. train_loss = 17.606989805180092
Epoch [43/500] Batch[9400/12648] complete. train_loss = 17.61442522820006
Epoch [43/500] Batch[9600/12648] complete. train_loss = 17.619788728753726
Epoch [43/500] Batch[9800/12648] complete. train_loss = 17.62574249656833
Epoch [43/500] Batch[10000/12648] complete. train_loss = 17.62889551372528
Epoch [43/500] Batch[10200/12648] complete. train_loss = 17.632513081326206
Epoch [43/500] Batch[10400/12648] complete. train_loss = 17.638593252805563
Epoch [43/500] Batch[10600/12648] complete. train_loss = 17.644367425486728
Epoch [43/500] Batch[10800/12648] complete. train_loss = 17.648825831589875
Epoch [43/500] Batch[11000/12648] complete. train_loss = 17.654762030861594
Epoch [43/500] Batch[11200/12648] complete. train_loss = 17.65983280003071
Epoch [43/500] Batch[11400/12648] complete. train_loss = 17.66475344791747
Epoch [43/500] Batch[11600/12648] complete. train_loss = 17.66987535213602
Epoch [43/500] Batch[11800/12648] complete. train_loss = 17.674445283049245
Epoch [43/500] Batch[12000/12648] complete. train_loss = 17.67873795191447
Epoch [43/500] Batch[12200/12648] complete. train_loss = 17.683431628962033
Epoch [43/500] Batch[12400/12648] complete. train_loss = 17.686990925419714
Epoch [43/500] Batch[12600/12648] complete. train_loss = 17.690161352081905
Epoch [43/500] Batch[12648/12648] complete. valid_loss = 19.608396291732788
Epoch [44/500] Batch[200/12648] complete. train_loss = 17.220475101470946
Epoch [44/500] Batch[400/12648] complete. train_loss = 17.223915979862213
Epoch [44/500] Batch[600/12648] complete. train_loss = 17.24113274892171
Epoch [44/500] Batch[800/12648] complete. train_loss = 17.23536486506462
Epoch [44/500] Batch[1000/12648] complete. train_loss = 17.264146887779237
Epoch [44/500] Batch[1200/12648] complete. train_loss = 17.265666708946227
Epoch [44/500] Batch[1400/12648] complete. train_loss = 17.285020087105888
Epoch [44/500] Batch[1600/12648] complete. train_loss = 17.286035290360452
Epoch [44/500] Batch[1800/12648] complete. train_loss = 17.29299783176846
Epoch [44/500] Batch[2000/12648] complete. train_loss = 17.299196579933167
Epoch [44/500] Batch[2200/12648] complete. train_loss = 17.31432347861203
Epoch [44/500] Batch[2400/12648] complete. train_loss = 17.320811219215393
Epoch [44/500] Batch[2600/12648] complete. train_loss = 17.32860141680791
Epoch [44/500] Batch[2800/12648] complete. train_loss = 17.344224205357687
Epoch [44/500] Batch[3000/12648] complete. train_loss = 17.351270325342814
Epoch [44/500] Batch[3200/12648] complete. train_loss = 17.363005996644496
Epoch [44/500] Batch[3400/12648] complete. train_loss = 17.372582533499774
Epoch [44/500] Batch[3600/12648] complete. train_loss = 17.380320864253573
Epoch [44/500] Batch[3800/12648] complete. train_loss = 17.391261956064323
Epoch [44/500] Batch[4000/12648] complete. train_loss = 17.402042322158813
Epoch [44/500] Batch[4200/12648] complete. train_loss = 17.409954339890252
Epoch [44/500] Batch[4400/12648] complete. train_loss = 17.42007065296173
Epoch [44/500] Batch[4600/12648] complete. train_loss = 17.4278001407955
Epoch [44/500] Batch[4800/12648] complete. train_loss = 17.43470104018847
Epoch [44/500] Batch[5000/12648] complete. train_loss = 17.444044035339356
Epoch [44/500] Batch[5200/12648] complete. train_loss = 17.451168834246122
Epoch [44/500] Batch[5400/12648] complete. train_loss = 17.458357045385572
Epoch [44/500] Batch[5600/12648] complete. train_loss = 17.465547444139208
Epoch [44/500] Batch[5800/12648] complete. train_loss = 17.467498343895222
Epoch [44/500] Batch[6000/12648] complete. train_loss = 17.47511622619629
Epoch [44/500] Batch[6200/12648] complete. train_loss = 17.47995051091717
Epoch [44/500] Batch[6400/12648] complete. train_loss = 17.486344840824604
Epoch [44/500] Batch[6600/12648] complete. train_loss = 17.49171950224674
Epoch [44/500] Batch[6800/12648] complete. train_loss = 17.498211581847247
Epoch [44/500] Batch[7000/12648] complete. train_loss = 17.50159071418217
Epoch [44/500] Batch[7200/12648] complete. train_loss = 17.508990918397902
Epoch [44/500] Batch[7400/12648] complete. train_loss = 17.51358349967647
Epoch [44/500] Batch[7600/12648] complete. train_loss = 17.520434130116513
Epoch [44/500] Batch[7800/12648] complete. train_loss = 17.527547546533437
Epoch [44/500] Batch[8000/12648] complete. train_loss = 17.535640570282936
Epoch [44/500] Batch[8200/12648] complete. train_loss = 17.540112749192772
Epoch [44/500] Batch[8400/12648] complete. train_loss = 17.546329924833206
Epoch [44/500] Batch[8600/12648] complete. train_loss = 17.550921014408733
Epoch [44/500] Batch[8800/12648] complete. train_loss = 17.555109737569637
Epoch [44/500] Batch[9000/12648] complete. train_loss = 17.560484091228908
Epoch [44/500] Batch[9200/12648] complete. train_loss = 17.565032032158065
Epoch [44/500] Batch[9400/12648] complete. train_loss = 17.57127633815116
Epoch [44/500] Batch[9600/12648] complete. train_loss = 17.576006059547264
Epoch [44/500] Batch[9800/12648] complete. train_loss = 17.580314258166723
Epoch [44/500] Batch[10000/12648] complete. train_loss = 17.585389074993135
Epoch [44/500] Batch[10200/12648] complete. train_loss = 17.592458566216862
Epoch [44/500] Batch[10400/12648] complete. train_loss = 17.597363491241747
Epoch [44/500] Batch[10600/12648] complete. train_loss = 17.60314766505979
Epoch [44/500] Batch[10800/12648] complete. train_loss = 17.607720304948312
Epoch [44/500] Batch[11000/12648] complete. train_loss = 17.611897123856977
Epoch [44/500] Batch[11200/12648] complete. train_loss = 17.61523907116481
Epoch [44/500] Batch[11400/12648] complete. train_loss = 17.62036970247302
Epoch [44/500] Batch[11600/12648] complete. train_loss = 17.62415794430108
Epoch [44/500] Batch[11800/12648] complete. train_loss = 17.629233429633963
Epoch [44/500] Batch[12000/12648] complete. train_loss = 17.634625593026477
Epoch [44/500] Batch[12200/12648] complete. train_loss = 17.63736403746683
Epoch [44/500] Batch[12400/12648] complete. train_loss = 17.642599277034883
Epoch [44/500] Batch[12600/12648] complete. train_loss = 17.64716814555819
Epoch [44/500] Batch[12648/12648] complete. valid_loss = 19.679599165916443
Epoch [45/500] Batch[200/12648] complete. train_loss = 17.17311996936798
Epoch [45/500] Batch[400/12648] complete. train_loss = 17.143775582313538
Epoch [45/500] Batch[600/12648] complete. train_loss = 17.14912696838379
Epoch [45/500] Batch[800/12648] complete. train_loss = 17.171639462709425
Epoch [45/500] Batch[1000/12648] complete. train_loss = 17.196872475624083
Epoch [45/500] Batch[1200/12648] complete. train_loss = 17.213190434773765
Epoch [45/500] Batch[1400/12648] complete. train_loss = 17.225084983280727
Epoch [45/500] Batch[1600/12648] complete. train_loss = 17.242980464696885
Epoch [45/500] Batch[1800/12648] complete. train_loss = 17.254831002023487
Epoch [45/500] Batch[2000/12648] complete. train_loss = 17.26130983400345
Epoch [45/500] Batch[2200/12648] complete. train_loss = 17.27255481676622
Epoch [45/500] Batch[2400/12648] complete. train_loss = 17.284598319133124
Epoch [45/500] Batch[2600/12648] complete. train_loss = 17.292239513397217
Epoch [45/500] Batch[2800/12648] complete. train_loss = 17.304843579701014
Epoch [45/500] Batch[3000/12648] complete. train_loss = 17.313311789194742
Epoch [45/500] Batch[3200/12648] complete. train_loss = 17.31870557397604
Epoch [45/500] Batch[3400/12648] complete. train_loss = 17.325524739658132
Epoch [45/500] Batch[3600/12648] complete. train_loss = 17.333676422172122
Epoch [45/500] Batch[3800/12648] complete. train_loss = 17.341126222359506
Epoch [45/500] Batch[4000/12648] complete. train_loss = 17.347845257997513
Epoch [45/500] Batch[4200/12648] complete. train_loss = 17.35638347012656
Epoch [45/500] Batch[4400/12648] complete. train_loss = 17.363974979357288
Epoch [45/500] Batch[4600/12648] complete. train_loss = 17.371379445532092
Epoch [45/500] Batch[4800/12648] complete. train_loss = 17.3773077549537
Epoch [45/500] Batch[5000/12648] complete. train_loss = 17.38656301937103
Epoch [45/500] Batch[5200/12648] complete. train_loss = 17.395635138291578
Epoch [45/500] Batch[5400/12648] complete. train_loss = 17.40329539952455
Epoch [45/500] Batch[5600/12648] complete. train_loss = 17.411661888701577
Epoch [45/500] Batch[5800/12648] complete. train_loss = 17.418164142740185
Epoch [45/500] Batch[6000/12648] complete. train_loss = 17.422876756191254
Epoch [45/500] Batch[6200/12648] complete. train_loss = 17.429500935000757
Epoch [45/500] Batch[6400/12648] complete. train_loss = 17.436014397442342
Epoch [45/500] Batch[6600/12648] complete. train_loss = 17.44441054936611
Epoch [45/500] Batch[6800/12648] complete. train_loss = 17.450740343682906
Epoch [45/500] Batch[7000/12648] complete. train_loss = 17.45461912236895
Epoch [45/500] Batch[7200/12648] complete. train_loss = 17.460205626752643
Epoch [45/500] Batch[7400/12648] complete. train_loss = 17.468095482748907
Epoch [45/500] Batch[7600/12648] complete. train_loss = 17.47731425084566
Epoch [45/500] Batch[7800/12648] complete. train_loss = 17.48040919841864
Epoch [45/500] Batch[8000/12648] complete. train_loss = 17.485879704117774
Epoch [45/500] Batch[8200/12648] complete. train_loss = 17.491646729213436
Epoch [45/500] Batch[8400/12648] complete. train_loss = 17.497225788093747
Epoch [45/500] Batch[8600/12648] complete. train_loss = 17.502714583485627
Epoch [45/500] Batch[8800/12648] complete. train_loss = 17.50645183910023
Epoch [45/500] Batch[9000/12648] complete. train_loss = 17.510561882442897
Epoch [45/500] Batch[9200/12648] complete. train_loss = 17.516193240621817
Epoch [45/500] Batch[9400/12648] complete. train_loss = 17.520237261082265
Epoch [45/500] Batch[9600/12648] complete. train_loss = 17.525616392989953
Epoch [45/500] Batch[9800/12648] complete. train_loss = 17.53044104683156
Epoch [45/500] Batch[10000/12648] complete. train_loss = 17.536462928295137
Epoch [45/500] Batch[10200/12648] complete. train_loss = 17.541177890347498
Epoch [45/500] Batch[10400/12648] complete. train_loss = 17.54630792892896
Epoch [45/500] Batch[10600/12648] complete. train_loss = 17.55085761772012
Epoch [45/500] Batch[10800/12648] complete. train_loss = 17.5567216402513
Epoch [45/500] Batch[11000/12648] complete. train_loss = 17.561093802105297
Epoch [45/500] Batch[11200/12648] complete. train_loss = 17.566847278986657
Epoch [45/500] Batch[11400/12648] complete. train_loss = 17.571815040404335
Epoch [45/500] Batch[11600/12648] complete. train_loss = 17.576571470869
Epoch [45/500] Batch[11800/12648] complete. train_loss = 17.581996059175264
Epoch [45/500] Batch[12000/12648] complete. train_loss = 17.587735824664435
Epoch [45/500] Batch[12200/12648] complete. train_loss = 17.59274223827925
Epoch [45/500] Batch[12400/12648] complete. train_loss = 17.597109266096545
Epoch [45/500] Batch[12600/12648] complete. train_loss = 17.602906032289777
Epoch [45/500] Batch[12648/12648] complete. valid_loss = 19.63010001182556
Epoch [46/500] Batch[200/12648] complete. train_loss = 17.05745200634003
Epoch [46/500] Batch[400/12648] complete. train_loss = 17.086633007526398
Epoch [46/500] Batch[600/12648] complete. train_loss = 17.07845363775889
Epoch [46/500] Batch[800/12648] complete. train_loss = 17.09682384252548
Epoch [46/500] Batch[1000/12648] complete. train_loss = 17.0992143163681
Epoch [46/500] Batch[1200/12648] complete. train_loss = 17.104826351801556
Epoch [46/500] Batch[1400/12648] complete. train_loss = 17.11916128567287
Epoch [46/500] Batch[1600/12648] complete. train_loss = 17.14634468138218
Epoch [46/500] Batch[1800/12648] complete. train_loss = 17.165335906876457
Epoch [46/500] Batch[2000/12648] complete. train_loss = 17.186826890945433
Epoch [46/500] Batch[2200/12648] complete. train_loss = 17.20213879585266
Epoch [46/500] Batch[2400/12648] complete. train_loss = 17.209905297756194
Epoch [46/500] Batch[2600/12648] complete. train_loss = 17.221156863432665
Epoch [46/500] Batch[2800/12648] complete. train_loss = 17.232871574674334
Epoch [46/500] Batch[3000/12648] complete. train_loss = 17.243078238805136
Epoch [46/500] Batch[3200/12648] complete. train_loss = 17.253593941032886
Epoch [46/500] Batch[3400/12648] complete. train_loss = 17.26281156203326
Epoch [46/500] Batch[3600/12648] complete. train_loss = 17.267372926606072
Epoch [46/500] Batch[3800/12648] complete. train_loss = 17.2740496969223
Epoch [46/500] Batch[4000/12648] complete. train_loss = 17.291926593303682
Epoch [46/500] Batch[4200/12648] complete. train_loss = 17.297729562577747
Epoch [46/500] Batch[4400/12648] complete. train_loss = 17.30521116473458
Epoch [46/500] Batch[4600/12648] complete. train_loss = 17.31906390335249
Epoch [46/500] Batch[4800/12648] complete. train_loss = 17.33009156405926
Epoch [46/500] Batch[5000/12648] complete. train_loss = 17.337866353988648
Epoch [46/500] Batch[5200/12648] complete. train_loss = 17.346356810606444
Epoch [46/500] Batch[5400/12648] complete. train_loss = 17.35379364879043
Epoch [46/500] Batch[5600/12648] complete. train_loss = 17.3615062890734
Epoch [46/500] Batch[5800/12648] complete. train_loss = 17.369681674694192
Epoch [46/500] Batch[6000/12648] complete. train_loss = 17.37594035021464
Epoch [46/500] Batch[6200/12648] complete. train_loss = 17.383032225947225
Epoch [46/500] Batch[6400/12648] complete. train_loss = 17.393085745871065
Epoch [46/500] Batch[6600/12648] complete. train_loss = 17.398001436753706
Epoch [46/500] Batch[6800/12648] complete. train_loss = 17.406198098379022
Epoch [46/500] Batch[7000/12648] complete. train_loss = 17.410881611824035
Epoch [46/500] Batch[7200/12648] complete. train_loss = 17.41755413730939
Epoch [46/500] Batch[7400/12648] complete. train_loss = 17.42324774226627
Epoch [46/500] Batch[7600/12648] complete. train_loss = 17.430187478190973
Epoch [46/500] Batch[7800/12648] complete. train_loss = 17.4369829362478
Epoch [46/500] Batch[8000/12648] complete. train_loss = 17.441891006588936
Epoch [46/500] Batch[8200/12648] complete. train_loss = 17.44606651085179
Epoch [46/500] Batch[8400/12648] complete. train_loss = 17.45153579496202
Epoch [46/500] Batch[8600/12648] complete. train_loss = 17.458823544812756
Epoch [46/500] Batch[8800/12648] complete. train_loss = 17.46482765002684
Epoch [46/500] Batch[9000/12648] complete. train_loss = 17.473208164215087
Epoch [46/500] Batch[9200/12648] complete. train_loss = 17.478625605417335
Epoch [46/500] Batch[9400/12648] complete. train_loss = 17.483787053696652
Epoch [46/500] Batch[9600/12648] complete. train_loss = 17.489171914259593
Epoch [46/500] Batch[9800/12648] complete. train_loss = 17.49503700314736
Epoch [46/500] Batch[10000/12648] complete. train_loss = 17.501047650909424
Epoch [46/500] Batch[10200/12648] complete. train_loss = 17.506873878497704
Epoch [46/500] Batch[10400/12648] complete. train_loss = 17.511183932561142
Epoch [46/500] Batch[10600/12648] complete. train_loss = 17.51751748714807
Epoch [46/500] Batch[10800/12648] complete. train_loss = 17.52081434806188
Epoch [46/500] Batch[11000/12648] complete. train_loss = 17.52637184524536
Epoch [46/500] Batch[11200/12648] complete. train_loss = 17.531191615462305
Epoch [46/500] Batch[11400/12648] complete. train_loss = 17.536457921161986
Epoch [46/500] Batch[11600/12648] complete. train_loss = 17.54182501554489
Epoch [46/500] Batch[11800/12648] complete. train_loss = 17.54706199734898
Epoch [46/500] Batch[12000/12648] complete. train_loss = 17.552211349248886
Epoch [46/500] Batch[12200/12648] complete. train_loss = 17.556698690320626
Epoch [46/500] Batch[12400/12648] complete. train_loss = 17.560999689948176
Epoch [46/500] Batch[12600/12648] complete. train_loss = 17.56460166507297
Epoch [46/500] Batch[12648/12648] complete. valid_loss = 19.719223260879517
Epoch [47/500] Batch[200/12648] complete. train_loss = 17.136059951782226
Epoch [47/500] Batch[400/12648] complete. train_loss = 17.083040721416474
Epoch [47/500] Batch[600/12648] complete. train_loss = 17.077521692911784
Epoch [47/500] Batch[800/12648] complete. train_loss = 17.08957051753998
Epoch [47/500] Batch[1000/12648] complete. train_loss = 17.11538467979431
Epoch [47/500] Batch[1200/12648] complete. train_loss = 17.12801693836848
Epoch [47/500] Batch[1400/12648] complete. train_loss = 17.133491296086994
Epoch [47/500] Batch[1600/12648] complete. train_loss = 17.146905789375307
Epoch [47/500] Batch[1800/12648] complete. train_loss = 17.164020518196953
Epoch [47/500] Batch[2000/12648] complete. train_loss = 17.17601114845276
Epoch [47/500] Batch[2200/12648] complete. train_loss = 17.17835554599762
Epoch [47/500] Batch[2400/12648] complete. train_loss = 17.18951113065084
Epoch [47/500] Batch[2600/12648] complete. train_loss = 17.20527012568254
Epoch [47/500] Batch[2800/12648] complete. train_loss = 17.214553874901362
Epoch [47/500] Batch[3000/12648] complete. train_loss = 17.224226362864176
Epoch [47/500] Batch[3200/12648] complete. train_loss = 17.239380560815334
Epoch [47/500] Batch[3400/12648] complete. train_loss = 17.242000048020305
Epoch [47/500] Batch[3600/12648] complete. train_loss = 17.248742209805382
Epoch [47/500] Batch[3800/12648] complete. train_loss = 17.251901663228086
Epoch [47/500] Batch[4000/12648] complete. train_loss = 17.25884762477875
Epoch [47/500] Batch[4200/12648] complete. train_loss = 17.26741731484731
Epoch [47/500] Batch[4400/12648] complete. train_loss = 17.276651752862062
Epoch [47/500] Batch[4600/12648] complete. train_loss = 17.285776648936064
Epoch [47/500] Batch[4800/12648] complete. train_loss = 17.295445712606114
Epoch [47/500] Batch[5000/12648] complete. train_loss = 17.303287845993044
Epoch [47/500] Batch[5200/12648] complete. train_loss = 17.309634669377253
Epoch [47/500] Batch[5400/12648] complete. train_loss = 17.315832164199264
Epoch [47/500] Batch[5600/12648] complete. train_loss = 17.323121708461215
Epoch [47/500] Batch[5800/12648] complete. train_loss = 17.33029082577804
Epoch [47/500] Batch[6000/12648] complete. train_loss = 17.337568932533266
Epoch [47/500] Batch[6200/12648] complete. train_loss = 17.345179618712393
Epoch [47/500] Batch[6400/12648] complete. train_loss = 17.35596512526274
Epoch [47/500] Batch[6600/12648] complete. train_loss = 17.364010433428216
Epoch [47/500] Batch[6800/12648] complete. train_loss = 17.37070467303781
Epoch [47/500] Batch[7000/12648] complete. train_loss = 17.377889706202915
Epoch [47/500] Batch[7200/12648] complete. train_loss = 17.382853211694293
Epoch [47/500] Batch[7400/12648] complete. train_loss = 17.39057142141703
Epoch [47/500] Batch[7600/12648] complete. train_loss = 17.39643506589689
Epoch [47/500] Batch[7800/12648] complete. train_loss = 17.40407805956327
Epoch [47/500] Batch[8000/12648] complete. train_loss = 17.409070361971857
Epoch [47/500] Batch[8200/12648] complete. train_loss = 17.41434398581342
Epoch [47/500] Batch[8400/12648] complete. train_loss = 17.419640742597124
Epoch [47/500] Batch[8600/12648] complete. train_loss = 17.4245092505078
Epoch [47/500] Batch[8800/12648] complete. train_loss = 17.430534207387403
Epoch [47/500] Batch[9000/12648] complete. train_loss = 17.43572305054135
Epoch [47/500] Batch[9200/12648] complete. train_loss = 17.44209796190262
Epoch [47/500] Batch[9400/12648] complete. train_loss = 17.447048706704
Epoch [47/500] Batch[9600/12648] complete. train_loss = 17.451527727941674
Epoch [47/500] Batch[9800/12648] complete. train_loss = 17.455181039985344
Epoch [47/500] Batch[10000/12648] complete. train_loss = 17.459987782287598
Epoch [47/500] Batch[10200/12648] complete. train_loss = 17.464573417551378
Epoch [47/500] Batch[10400/12648] complete. train_loss = 17.471207031653478
Epoch [47/500] Batch[10600/12648] complete. train_loss = 17.475990241968407
Epoch [47/500] Batch[10800/12648] complete. train_loss = 17.482144610087076
Epoch [47/500] Batch[11000/12648] complete. train_loss = 17.487767355312002
Epoch [47/500] Batch[11200/12648] complete. train_loss = 17.490953019942555
Epoch [47/500] Batch[11400/12648] complete. train_loss = 17.494475223056057
Epoch [47/500] Batch[11600/12648] complete. train_loss = 17.49846327880333
Epoch [47/500] Batch[11800/12648] complete. train_loss = 17.50262081720061
Epoch [47/500] Batch[12000/12648] complete. train_loss = 17.508757263819376
Epoch [47/500] Batch[12200/12648] complete. train_loss = 17.513185591854032
Epoch [47/500] Batch[12400/12648] complete. train_loss = 17.51787234936991
Epoch [47/500] Batch[12600/12648] complete. train_loss = 17.52256463005429
Epoch [47/500] Batch[12648/12648] complete. valid_loss = 19.654386520385742
Epoch [48/500] Batch[200/12648] complete. train_loss = 17.098504986763
Epoch [48/500] Batch[400/12648] complete. train_loss = 17.062004935741424
Epoch [48/500] Batch[600/12648] complete. train_loss = 17.062097056706747
Epoch [48/500] Batch[800/12648] complete. train_loss = 17.058457823991777
Epoch [48/500] Batch[1000/12648] complete. train_loss = 17.08340957069397
Epoch [48/500] Batch[1200/12648] complete. train_loss = 17.096855861345926
Epoch [48/500] Batch[1400/12648] complete. train_loss = 17.110348282541548
Epoch [48/500] Batch[1600/12648] complete. train_loss = 17.115783478021623
Epoch [48/500] Batch[1800/12648] complete. train_loss = 17.129350721571182
Epoch [48/500] Batch[2000/12648] complete. train_loss = 17.159916063308717
Epoch [48/500] Batch[2200/12648] complete. train_loss = 17.161329112919894
Epoch [48/500] Batch[2400/12648] complete. train_loss = 17.162352561155956
Epoch [48/500] Batch[2600/12648] complete. train_loss = 17.174967836600082
Epoch [48/500] Batch[2800/12648] complete. train_loss = 17.177327503136226
Epoch [48/500] Batch[3000/12648] complete. train_loss = 17.18954706923167
Epoch [48/500] Batch[3200/12648] complete. train_loss = 17.201815455257893
Epoch [48/500] Batch[3400/12648] complete. train_loss = 17.208254502801335
Epoch [48/500] Batch[3600/12648] complete. train_loss = 17.219409281412762
Epoch [48/500] Batch[3800/12648] complete. train_loss = 17.22753768142901
Epoch [48/500] Batch[4000/12648] complete. train_loss = 17.240605053663252
Epoch [48/500] Batch[4200/12648] complete. train_loss = 17.247470554170153
Epoch [48/500] Batch[4400/12648] complete. train_loss = 17.258864423361693
Epoch [48/500] Batch[4600/12648] complete. train_loss = 17.26434894769088
Epoch [48/500] Batch[4800/12648] complete. train_loss = 17.275434529185294
Epoch [48/500] Batch[5000/12648] complete. train_loss = 17.28156483402252
Epoch [48/500] Batch[5200/12648] complete. train_loss = 17.286250524154077
Epoch [48/500] Batch[5400/12648] complete. train_loss = 17.296059675746495
Epoch [48/500] Batch[5600/12648] complete. train_loss = 17.300937175580433
Epoch [48/500] Batch[5800/12648] complete. train_loss = 17.308350007780668
Epoch [48/500] Batch[6000/12648] complete. train_loss = 17.313414199352266
Epoch [48/500] Batch[6200/12648] complete. train_loss = 17.319653191566466
Epoch [48/500] Batch[6400/12648] complete. train_loss = 17.3267659945786
Epoch [48/500] Batch[6600/12648] complete. train_loss = 17.333280867663298
Epoch [48/500] Batch[6800/12648] complete. train_loss = 17.337323686515585
Epoch [48/500] Batch[7000/12648] complete. train_loss = 17.34066131401062
Epoch [48/500] Batch[7200/12648] complete. train_loss = 17.345332842667897
Epoch [48/500] Batch[7400/12648] complete. train_loss = 17.352585599615768
Epoch [48/500] Batch[7600/12648] complete. train_loss = 17.35757058658098
Epoch [48/500] Batch[7800/12648] complete. train_loss = 17.362730837112817
Epoch [48/500] Batch[8000/12648] complete. train_loss = 17.369611698031427
Epoch [48/500] Batch[8200/12648] complete. train_loss = 17.374676594617892
Epoch [48/500] Batch[8400/12648] complete. train_loss = 17.381077721459526
Epoch [48/500] Batch[8600/12648] complete. train_loss = 17.38503045059914
Epoch [48/500] Batch[8800/12648] complete. train_loss = 17.390967460870744
Epoch [48/500] Batch[9000/12648] complete. train_loss = 17.39724901390076
Epoch [48/500] Batch[9200/12648] complete. train_loss = 17.40288539202317
Epoch [48/500] Batch[9400/12648] complete. train_loss = 17.409204746814485
Epoch [48/500] Batch[9600/12648] complete. train_loss = 17.41341546813647
Epoch [48/500] Batch[9800/12648] complete. train_loss = 17.41978151554964
Epoch [48/500] Batch[10000/12648] complete. train_loss = 17.423053909873964
Epoch [48/500] Batch[10200/12648] complete. train_loss = 17.429127701217052
Epoch [48/500] Batch[10400/12648] complete. train_loss = 17.43378456198252
Epoch [48/500] Batch[10600/12648] complete. train_loss = 17.4394410358285
Epoch [48/500] Batch[10800/12648] complete. train_loss = 17.44636463942351
Epoch [48/500] Batch[11000/12648] complete. train_loss = 17.450908793709495
Epoch [48/500] Batch[11200/12648] complete. train_loss = 17.457164467402865
Epoch [48/500] Batch[11400/12648] complete. train_loss = 17.460636045305353
Epoch [48/500] Batch[11600/12648] complete. train_loss = 17.464969000240853
Epoch [48/500] Batch[11800/12648] complete. train_loss = 17.46981738227909
Epoch [48/500] Batch[12000/12648] complete. train_loss = 17.473804869095485
Epoch [48/500] Batch[12200/12648] complete. train_loss = 17.47706808543596
Epoch [48/500] Batch[12400/12648] complete. train_loss = 17.48045354920049
Epoch [48/500] Batch[12600/12648] complete. train_loss = 17.484545461715214
Epoch [48/500] Batch[12648/12648] complete. valid_loss = 19.690457820892334
Epoch [49/500] Batch[200/12648] complete. train_loss = 16.903390073776244
Epoch [49/500] Batch[400/12648] complete. train_loss = 16.970408778190613
Epoch [49/500] Batch[600/12648] complete. train_loss = 16.993788630167643
Epoch [49/500] Batch[800/12648] complete. train_loss = 17.01804357647896
Epoch [49/500] Batch[1000/12648] complete. train_loss = 17.018129199028014
Epoch [49/500] Batch[1200/12648] complete. train_loss = 17.028413658936817
Epoch [49/500] Batch[1400/12648] complete. train_loss = 17.029112683023726
Epoch [49/500] Batch[1600/12648] complete. train_loss = 17.040390092730522
Epoch [49/500] Batch[1800/12648] complete. train_loss = 17.056396823459202
Epoch [49/500] Batch[2000/12648] complete. train_loss = 17.06634207201004
Epoch [49/500] Batch[2200/12648] complete. train_loss = 17.079473060694607
Epoch [49/500] Batch[2400/12648] complete. train_loss = 17.084335583051047
Epoch [49/500] Batch[2600/12648] complete. train_loss = 17.101844514700083
Epoch [49/500] Batch[2800/12648] complete. train_loss = 17.108906135218483
Epoch [49/500] Batch[3000/12648] complete. train_loss = 17.12151518567403
Epoch [49/500] Batch[3200/12648] complete. train_loss = 17.134145447611807
Epoch [49/500] Batch[3400/12648] complete. train_loss = 17.148093297902275
Epoch [49/500] Batch[3600/12648] complete. train_loss = 17.16150021314621
Epoch [49/500] Batch[3800/12648] complete. train_loss = 17.175481071221203
Epoch [49/500] Batch[4000/12648] complete. train_loss = 17.18116574883461
Epoch [49/500] Batch[4200/12648] complete. train_loss = 17.191510695275806
Epoch [49/500] Batch[4400/12648] complete. train_loss = 17.202339192087
Epoch [49/500] Batch[4600/12648] complete. train_loss = 17.209465046550918
Epoch [49/500] Batch[4800/12648] complete. train_loss = 17.219658085505166
Epoch [49/500] Batch[5000/12648] complete. train_loss = 17.228128767585755
Epoch [49/500] Batch[5200/12648] complete. train_loss = 17.2358145904541
Epoch [49/500] Batch[5400/12648] complete. train_loss = 17.24175328572591
Epoch [49/500] Batch[5600/12648] complete. train_loss = 17.250695773363113
Epoch [49/500] Batch[5800/12648] complete. train_loss = 17.259791392622322
Epoch [49/500] Batch[6000/12648] complete. train_loss = 17.269477292378742
Epoch [49/500] Batch[6200/12648] complete. train_loss = 17.27678037028159
Epoch [49/500] Batch[6400/12648] complete. train_loss = 17.286390819251537
Epoch [49/500] Batch[6600/12648] complete. train_loss = 17.289359585588628
Epoch [49/500] Batch[6800/12648] complete. train_loss = 17.293443279266356
Epoch [49/500] Batch[7000/12648] complete. train_loss = 17.29954924433572
Epoch [49/500] Batch[7200/12648] complete. train_loss = 17.303976054986318
Epoch [49/500] Batch[7400/12648] complete. train_loss = 17.308818194672867
Epoch [49/500] Batch[7600/12648] complete. train_loss = 17.31322753391768
Epoch [49/500] Batch[7800/12648] complete. train_loss = 17.318449966601836
Epoch [49/500] Batch[8000/12648] complete. train_loss = 17.326162757635117
Epoch [49/500] Batch[8200/12648] complete. train_loss = 17.332514522482708
Epoch [49/500] Batch[8400/12648] complete. train_loss = 17.338826573916844
Epoch [49/500] Batch[8600/12648] complete. train_loss = 17.344352563702785
Epoch [49/500] Batch[8800/12648] complete. train_loss = 17.350319333076477
Epoch [49/500] Batch[9000/12648] complete. train_loss = 17.357005645328098
Epoch [49/500] Batch[9200/12648] complete. train_loss = 17.362146608103878
Epoch [49/500] Batch[9400/12648] complete. train_loss = 17.366802113817094
Epoch [49/500] Batch[9600/12648] complete. train_loss = 17.370910269717374
Epoch [49/500] Batch[9800/12648] complete. train_loss = 17.376817567397136
Epoch [49/500] Batch[10000/12648] complete. train_loss = 17.382953189086916
Epoch [49/500] Batch[10200/12648] complete. train_loss = 17.387013852269043
Epoch [49/500] Batch[10400/12648] complete. train_loss = 17.391751805085402
Epoch [49/500] Batch[10600/12648] complete. train_loss = 17.397020063580207
Epoch [49/500] Batch[10800/12648] complete. train_loss = 17.402555712593927
Epoch [49/500] Batch[11000/12648] complete. train_loss = 17.40606626952778
Epoch [49/500] Batch[11200/12648] complete. train_loss = 17.4115831720829
Epoch [49/500] Batch[11400/12648] complete. train_loss = 17.415239616862515
Epoch [49/500] Batch[11600/12648] complete. train_loss = 17.419951504838878
Epoch [49/500] Batch[11800/12648] complete. train_loss = 17.424904202445077
Epoch [49/500] Batch[12000/12648] complete. train_loss = 17.429063209692636
Epoch [49/500] Batch[12200/12648] complete. train_loss = 17.4323110098917
Epoch [49/500] Batch[12400/12648] complete. train_loss = 17.43869920515245
Epoch [49/500] Batch[12600/12648] complete. train_loss = 17.44365033301096
Epoch [49/500] Batch[12648/12648] complete. valid_loss = 19.64465832710266
Epoch [50/500] Batch[200/12648] complete. train_loss = 16.9164990568161
Epoch [50/500] Batch[400/12648] complete. train_loss = 16.912590680122374
Epoch [50/500] Batch[600/12648] complete. train_loss = 16.934204292297363
Epoch [50/500] Batch[800/12648] complete. train_loss = 16.95124634861946
Epoch [50/500] Batch[1000/12648] complete. train_loss = 16.966374423027037
Epoch [50/500] Batch[1200/12648] complete. train_loss = 16.991574393908184
Epoch [50/500] Batch[1400/12648] complete. train_loss = 17.004024339403426
Epoch [50/500] Batch[1600/12648] complete. train_loss = 17.023039163947104
Epoch [50/500] Batch[1800/12648] complete. train_loss = 17.04138325373332
Epoch [50/500] Batch[2000/12648] complete. train_loss = 17.052411718845367
Epoch [50/500] Batch[2200/12648] complete. train_loss = 17.06637605233626
Epoch [50/500] Batch[2400/12648] complete. train_loss = 17.073058865467708
Epoch [50/500] Batch[2600/12648] complete. train_loss = 17.083229918113123
Epoch [50/500] Batch[2800/12648] complete. train_loss = 17.086885507106782
Epoch [50/500] Batch[3000/12648] complete. train_loss = 17.10162966664632
Epoch [50/500] Batch[3200/12648] complete. train_loss = 17.112488667964936
Epoch [50/500] Batch[3400/12648] complete. train_loss = 17.120039999625263
Epoch [50/500] Batch[3600/12648] complete. train_loss = 17.130170217355094
Epoch [50/500] Batch[3800/12648] complete. train_loss = 17.139287404512103
Epoch [50/500] Batch[4000/12648] complete. train_loss = 17.14918046092987
Epoch [50/500] Batch[4200/12648] complete. train_loss = 17.155833398274012
Epoch [50/500] Batch[4400/12648] complete. train_loss = 17.166181206486442
Epoch [50/500] Batch[4600/12648] complete. train_loss = 17.182302535098533
Epoch [50/500] Batch[4800/12648] complete. train_loss = 17.189276474912962
Epoch [50/500] Batch[5000/12648] complete. train_loss = 17.19259868221283
Epoch [50/500] Batch[5200/12648] complete. train_loss = 17.199539247842935
Epoch [50/500] Batch[5400/12648] complete. train_loss = 17.20880298649823
Epoch [50/500] Batch[5600/12648] complete. train_loss = 17.21335643001965
Epoch [50/500] Batch[5800/12648] complete. train_loss = 17.22065600724056
Epoch [50/500] Batch[6000/12648] complete. train_loss = 17.227090393066405
Epoch [50/500] Batch[6200/12648] complete. train_loss = 17.2326608725517
Epoch [50/500] Batch[6400/12648] complete. train_loss = 17.237824973016977
Epoch [50/500] Batch[6600/12648] complete. train_loss = 17.244699133381697
Epoch [50/500] Batch[6800/12648] complete. train_loss = 17.25139780956156
Epoch [50/500] Batch[7000/12648] complete. train_loss = 17.257806798934936
Epoch [50/500] Batch[7200/12648] complete. train_loss = 17.263264662954544
Epoch [50/500] Batch[7400/12648] complete. train_loss = 17.271638704506127
Epoch [50/500] Batch[7600/12648] complete. train_loss = 17.27702937176353
Epoch [50/500] Batch[7800/12648] complete. train_loss = 17.28329899213253
Epoch [50/500] Batch[8000/12648] complete. train_loss = 17.290077118515967
Epoch [50/500] Batch[8200/12648] complete. train_loss = 17.295639736594225
Epoch [50/500] Batch[8400/12648] complete. train_loss = 17.301018235115777
Epoch [50/500] Batch[8600/12648] complete. train_loss = 17.30430336131606
Epoch [50/500] Batch[8800/12648] complete. train_loss = 17.310751309286463
Epoch [50/500] Batch[9000/12648] complete. train_loss = 17.315960934638976
Epoch [50/500] Batch[9200/12648] complete. train_loss = 17.319853295554285
Epoch [50/500] Batch[9400/12648] complete. train_loss = 17.326972102915988
Epoch [50/500] Batch[9600/12648] complete. train_loss = 17.333566334545612
Epoch [50/500] Batch[9800/12648] complete. train_loss = 17.33864782333374
Epoch [50/500] Batch[10000/12648] complete. train_loss = 17.34633502893448
Epoch [50/500] Batch[10200/12648] complete. train_loss = 17.35063462004942
Epoch [50/500] Batch[10400/12648] complete. train_loss = 17.35577729179309
Epoch [50/500] Batch[10600/12648] complete. train_loss = 17.361074371067982
Epoch [50/500] Batch[10800/12648] complete. train_loss = 17.364604028419212
Epoch [50/500] Batch[11000/12648] complete. train_loss = 17.36988342926719
Epoch [50/500] Batch[11200/12648] complete. train_loss = 17.374659403307096
Epoch [50/500] Batch[11400/12648] complete. train_loss = 17.37919083862974
Epoch [50/500] Batch[11600/12648] complete. train_loss = 17.38218002270008
Epoch [50/500] Batch[11800/12648] complete. train_loss = 17.386790339421417
Epoch [50/500] Batch[12000/12648] complete. train_loss = 17.391967009941737
Epoch [50/500] Batch[12200/12648] complete. train_loss = 17.397328125922407
Epoch [50/500] Batch[12400/12648] complete. train_loss = 17.402683206527463
Epoch [50/500] Batch[12600/12648] complete. train_loss = 17.408837276110575
Epoch [50/500] Batch[12648/12648] complete. valid_loss = 19.71523928642273
Epoch [51/500] Batch[200/12648] complete. train_loss = 16.893035650253296
Epoch [51/500] Batch[400/12648] complete. train_loss = 16.921010954380037
Epoch [51/500] Batch[600/12648] complete. train_loss = 16.926525479952495
Epoch [51/500] Batch[800/12648] complete. train_loss = 16.937542822360992
Epoch [51/500] Batch[1000/12648] complete. train_loss = 16.96189715194702
Epoch [51/500] Batch[1200/12648] complete. train_loss = 16.96841993014018
Epoch [51/500] Batch[1400/12648] complete. train_loss = 16.985996382577078
Epoch [51/500] Batch[1600/12648] complete. train_loss = 17.00235623419285
Epoch [51/500] Batch[1800/12648] complete. train_loss = 17.010388179885016
Epoch [51/500] Batch[2000/12648] complete. train_loss = 17.016660542011262
Epoch [51/500] Batch[2200/12648] complete. train_loss = 17.028920125961303
Epoch [51/500] Batch[2400/12648] complete. train_loss = 17.041371421813963
Epoch [51/500] Batch[2600/12648] complete. train_loss = 17.05181172664349
Epoch [51/500] Batch[2800/12648] complete. train_loss = 17.063092159543718
Epoch [51/500] Batch[3000/12648] complete. train_loss = 17.07019689273834
Epoch [51/500] Batch[3200/12648] complete. train_loss = 17.07866738408804
Epoch [51/500] Batch[3400/12648] complete. train_loss = 17.08850139477674
Epoch [51/500] Batch[3600/12648] complete. train_loss = 17.098150349193148
Epoch [51/500] Batch[3800/12648] complete. train_loss = 17.107965505750556
Epoch [51/500] Batch[4000/12648] complete. train_loss = 17.11695239686966
Epoch [51/500] Batch[4200/12648] complete. train_loss = 17.12318448952266
Epoch [51/500] Batch[4400/12648] complete. train_loss = 17.134504396265203
Epoch [51/500] Batch[4600/12648] complete. train_loss = 17.144352098133254
Epoch [51/500] Batch[4800/12648] complete. train_loss = 17.154220331112544
Epoch [51/500] Batch[5000/12648] complete. train_loss = 17.160914459800722
Epoch [51/500] Batch[5200/12648] complete. train_loss = 17.16574709892273
Epoch [51/500] Batch[5400/12648] complete. train_loss = 17.172098731641416
Epoch [51/500] Batch[5600/12648] complete. train_loss = 17.17863623074123
Epoch [51/500] Batch[5800/12648] complete. train_loss = 17.187597178261857
Epoch [51/500] Batch[6000/12648] complete. train_loss = 17.19436666250229
Epoch [51/500] Batch[6200/12648] complete. train_loss = 17.199863691329956
Epoch [51/500] Batch[6400/12648] complete. train_loss = 17.207505580186844
Epoch [51/500] Batch[6600/12648] complete. train_loss = 17.216072755004422
Epoch [51/500] Batch[6800/12648] complete. train_loss = 17.22469524046954
Epoch [51/500] Batch[7000/12648] complete. train_loss = 17.231178135871886
Epoch [51/500] Batch[7200/12648] complete. train_loss = 17.236495682928297
Epoch [51/500] Batch[7400/12648] complete. train_loss = 17.239837810413256
Epoch [51/500] Batch[7600/12648] complete. train_loss = 17.246870501417863
Epoch [51/500] Batch[7800/12648] complete. train_loss = 17.251633352622008
Epoch [51/500] Batch[8000/12648] complete. train_loss = 17.258031650781632
Epoch [51/500] Batch[8200/12648] complete. train_loss = 17.26605149327255
Epoch [51/500] Batch[8400/12648] complete. train_loss = 17.272494570981888
Epoch [51/500] Batch[8600/12648] complete. train_loss = 17.278332242411235
Epoch [51/500] Batch[8800/12648] complete. train_loss = 17.284005141908473
Epoch [51/500] Batch[9000/12648] complete. train_loss = 17.28820442475213
Epoch [51/500] Batch[9200/12648] complete. train_loss = 17.2929576339929
Epoch [51/500] Batch[9400/12648] complete. train_loss = 17.29760162597007
Epoch [51/500] Batch[9600/12648] complete. train_loss = 17.301736604472
Epoch [51/500] Batch[9800/12648] complete. train_loss = 17.306503723397547
Epoch [51/500] Batch[10000/12648] complete. train_loss = 17.309826638507843
Epoch [51/500] Batch[10200/12648] complete. train_loss = 17.317079750790317
Epoch [51/500] Batch[10400/12648] complete. train_loss = 17.32130008844229
Epoch [51/500] Batch[10600/12648] complete. train_loss = 17.325954573109463
Epoch [51/500] Batch[10800/12648] complete. train_loss = 17.33081188201904
Epoch [51/500] Batch[11000/12648] complete. train_loss = 17.33586342525482
Epoch [51/500] Batch[11200/12648] complete. train_loss = 17.3416791250876
Epoch [51/500] Batch[11400/12648] complete. train_loss = 17.34700052269718
Epoch [51/500] Batch[11600/12648] complete. train_loss = 17.350354368933317
Epoch [51/500] Batch[11800/12648] complete. train_loss = 17.35526723481841
Epoch [51/500] Batch[12000/12648] complete. train_loss = 17.360630056937534
Epoch [51/500] Batch[12200/12648] complete. train_loss = 17.364317624686194
Epoch [51/500] Batch[12400/12648] complete. train_loss = 17.3684750074725
Epoch [51/500] Batch[12600/12648] complete. train_loss = 17.372557806287492
Epoch [51/500] Batch[12648/12648] complete. valid_loss = 19.674546480178833
Epoch [52/500] Batch[200/12648] complete. train_loss = 16.856522583961485
Epoch [52/500] Batch[400/12648] complete. train_loss = 16.875034198760986
Epoch [52/500] Batch[600/12648] complete. train_loss = 16.852870434125265
Epoch [52/500] Batch[800/12648] complete. train_loss = 16.880827249288558
Epoch [52/500] Batch[1000/12648] complete. train_loss = 16.913246212005614
Epoch [52/500] Batch[1200/12648] complete. train_loss = 16.92279628276825
Epoch [52/500] Batch[1400/12648] complete. train_loss = 16.938096787588936
Epoch [52/500] Batch[1600/12648] complete. train_loss = 16.95253781378269
Epoch [52/500] Batch[1800/12648] complete. train_loss = 16.966870659722222
Epoch [52/500] Batch[2000/12648] complete. train_loss = 16.9799824924469
Epoch [52/500] Batch[2200/12648] complete. train_loss = 16.988413058627735
Epoch [52/500] Batch[2400/12648] complete. train_loss = 17.003354144493738
Epoch [52/500] Batch[2600/12648] complete. train_loss = 17.0147859111199
Epoch [52/500] Batch[2800/12648] complete. train_loss = 17.027154143537793
Epoch [52/500] Batch[3000/12648] complete. train_loss = 17.03664524904887
Epoch [52/500] Batch[3200/12648] complete. train_loss = 17.04771639674902
Epoch [52/500] Batch[3400/12648] complete. train_loss = 17.05347009630764
Epoch [52/500] Batch[3600/12648] complete. train_loss = 17.060138581593833
Epoch [52/500] Batch[3800/12648] complete. train_loss = 17.067831428427446
Epoch [52/500] Batch[4000/12648] complete. train_loss = 17.076179355859757
Epoch [52/500] Batch[4200/12648] complete. train_loss = 17.0857388594037
Epoch [52/500] Batch[4400/12648] complete. train_loss = 17.09524741346186
Epoch [52/500] Batch[4600/12648] complete. train_loss = 17.102303543712782
Epoch [52/500] Batch[4800/12648] complete. train_loss = 17.116842343211175
Epoch [52/500] Batch[5000/12648] complete. train_loss = 17.12089536113739
Epoch [52/500] Batch[5200/12648] complete. train_loss = 17.126699167765103
Epoch [52/500] Batch[5400/12648] complete. train_loss = 17.13622939515997
Epoch [52/500] Batch[5600/12648] complete. train_loss = 17.145298048768726
Epoch [52/500] Batch[5800/12648] complete. train_loss = 17.154268894853264
Epoch [52/500] Batch[6000/12648] complete. train_loss = 17.161963830629986
Epoch [52/500] Batch[6200/12648] complete. train_loss = 17.169243941460888
Epoch [52/500] Batch[6400/12648] complete. train_loss = 17.177231829613447
Epoch [52/500] Batch[6600/12648] complete. train_loss = 17.18542348500454
Epoch [52/500] Batch[6800/12648] complete. train_loss = 17.193062862227944
Epoch [52/500] Batch[7000/12648] complete. train_loss = 17.197867435455322
Epoch [52/500] Batch[7200/12648] complete. train_loss = 17.203449062108994
Epoch [52/500] Batch[7400/12648] complete. train_loss = 17.20782407103358
Epoch [52/500] Batch[7600/12648] complete. train_loss = 17.214449161479347
Epoch [52/500] Batch[7800/12648] complete. train_loss = 17.217204908101987
Epoch [52/500] Batch[8000/12648] complete. train_loss = 17.222934812426566
Epoch [52/500] Batch[8200/12648] complete. train_loss = 17.22692154802927
Epoch [52/500] Batch[8400/12648] complete. train_loss = 17.232853212015968
Epoch [52/500] Batch[8600/12648] complete. train_loss = 17.238135536992274
Epoch [52/500] Batch[8800/12648] complete. train_loss = 17.24518697977066
Epoch [52/500] Batch[9000/12648] complete. train_loss = 17.252216698328652
Epoch [52/500] Batch[9200/12648] complete. train_loss = 17.257578821804213
Epoch [52/500] Batch[9400/12648] complete. train_loss = 17.263110924274365
Epoch [52/500] Batch[9600/12648] complete. train_loss = 17.269072073698045
Epoch [52/500] Batch[9800/12648] complete. train_loss = 17.272965059183083
Epoch [52/500] Batch[10000/12648] complete. train_loss = 17.278126562309264
Epoch [52/500] Batch[10200/12648] complete. train_loss = 17.283515969351225
Epoch [52/500] Batch[10400/12648] complete. train_loss = 17.28648386615973
Epoch [52/500] Batch[10600/12648] complete. train_loss = 17.289166867688017
Epoch [52/500] Batch[10800/12648] complete. train_loss = 17.29657818591153
Epoch [52/500] Batch[11000/12648] complete. train_loss = 17.300889474435287
Epoch [52/500] Batch[11200/12648] complete. train_loss = 17.30473448038101
Epoch [52/500] Batch[11400/12648] complete. train_loss = 17.309530211498863
Epoch [52/500] Batch[11600/12648] complete. train_loss = 17.314486604147945
Epoch [52/500] Batch[11800/12648] complete. train_loss = 17.319086643962535
Epoch [52/500] Batch[12000/12648] complete. train_loss = 17.32286646914482
Epoch [52/500] Batch[12200/12648] complete. train_loss = 17.327324985754295
Epoch [52/500] Batch[12400/12648] complete. train_loss = 17.334302504985562
Epoch [52/500] Batch[12600/12648] complete. train_loss = 17.338149842610434
Epoch [52/500] Batch[12648/12648] complete. valid_loss = 19.717191219329834
Epoch [53/500] Batch[200/12648] complete. train_loss = 16.814153332710266
Epoch [53/500] Batch[400/12648] complete. train_loss = 16.795654323101044
Epoch [53/500] Batch[600/12648] complete. train_loss = 16.844000350634257
Epoch [53/500] Batch[800/12648] complete. train_loss = 16.861230288743972
Epoch [53/500] Batch[1000/12648] complete. train_loss = 16.870867297172545
Epoch [53/500] Batch[1200/12648] complete. train_loss = 16.892396141688028
Epoch [53/500] Batch[1400/12648] complete. train_loss = 16.90005358491625
Epoch [53/500] Batch[1600/12648] complete. train_loss = 16.918679822683334
Epoch [53/500] Batch[1800/12648] complete. train_loss = 16.94325455453661
Epoch [53/500] Batch[2000/12648] complete. train_loss = 16.959470881462096
Epoch [53/500] Batch[2200/12648] complete. train_loss = 16.961345087398183
Epoch [53/500] Batch[2400/12648] complete. train_loss = 16.972013926903408
Epoch [53/500] Batch[2600/12648] complete. train_loss = 16.985024857154258
Epoch [53/500] Batch[2800/12648] complete. train_loss = 16.994113316535948
Epoch [53/500] Batch[3000/12648] complete. train_loss = 17.000541907310485
Epoch [53/500] Batch[3200/12648] complete. train_loss = 17.010991108715533
Epoch [53/500] Batch[3400/12648] complete. train_loss = 17.017549389670876
Epoch [53/500] Batch[3600/12648] complete. train_loss = 17.026829170650906
Epoch [53/500] Batch[3800/12648] complete. train_loss = 17.036758624378002
Epoch [53/500] Batch[4000/12648] complete. train_loss = 17.04339915060997
Epoch [53/500] Batch[4200/12648] complete. train_loss = 17.05349300498054
Epoch [53/500] Batch[4400/12648] complete. train_loss = 17.05377985672517
Epoch [53/500] Batch[4600/12648] complete. train_loss = 17.06380912511245
Epoch [53/500] Batch[4800/12648] complete. train_loss = 17.073229058384896
Epoch [53/500] Batch[5000/12648] complete. train_loss = 17.078821211624145
Epoch [53/500] Batch[5200/12648] complete. train_loss = 17.085250866229718
Epoch [53/500] Batch[5400/12648] complete. train_loss = 17.09522208796607
Epoch [53/500] Batch[5600/12648] complete. train_loss = 17.10248844351087
Epoch [53/500] Batch[5800/12648] complete. train_loss = 17.111190747063734
Epoch [53/500] Batch[6000/12648] complete. train_loss = 17.12113205830256
Epoch [53/500] Batch[6200/12648] complete. train_loss = 17.128578807461647
Epoch [53/500] Batch[6400/12648] complete. train_loss = 17.130890554338695
Epoch [53/500] Batch[6600/12648] complete. train_loss = 17.138329146847582
Epoch [53/500] Batch[6800/12648] complete. train_loss = 17.143139726835138
Epoch [53/500] Batch[7000/12648] complete. train_loss = 17.150448783329555
Epoch [53/500] Batch[7200/12648] complete. train_loss = 17.158991011778514
Epoch [53/500] Batch[7400/12648] complete. train_loss = 17.16651116770667
Epoch [53/500] Batch[7600/12648] complete. train_loss = 17.171035056867098
Epoch [53/500] Batch[7800/12648] complete. train_loss = 17.17546136917212
Epoch [53/500] Batch[8000/12648] complete. train_loss = 17.18221040403843
Epoch [53/500] Batch[8200/12648] complete. train_loss = 17.188892001058996
Epoch [53/500] Batch[8400/12648] complete. train_loss = 17.194091314701808
Epoch [53/500] Batch[8600/12648] complete. train_loss = 17.198490114101144
Epoch [53/500] Batch[8800/12648] complete. train_loss = 17.20376285217025
Epoch [53/500] Batch[9000/12648] complete. train_loss = 17.210939991527134
Epoch [53/500] Batch[9200/12648] complete. train_loss = 17.215584331284397
Epoch [53/500] Batch[9400/12648] complete. train_loss = 17.220246657919375
Epoch [53/500] Batch[9600/12648] complete. train_loss = 17.222646075487138
Epoch [53/500] Batch[9800/12648] complete. train_loss = 17.230012221141738
Epoch [53/500] Batch[10000/12648] complete. train_loss = 17.23520720129013
Epoch [53/500] Batch[10200/12648] complete. train_loss = 17.2396705791062
Epoch [53/500] Batch[10400/12648] complete. train_loss = 17.241535851588615
Epoch [53/500] Batch[10600/12648] complete. train_loss = 17.24725689950979
Epoch [53/500] Batch[10800/12648] complete. train_loss = 17.25299868080351
Epoch [53/500] Batch[11000/12648] complete. train_loss = 17.25756601108204
Epoch [53/500] Batch[11200/12648] complete. train_loss = 17.262493726781436
Epoch [53/500] Batch[11400/12648] complete. train_loss = 17.26772213074199
Epoch [53/500] Batch[11600/12648] complete. train_loss = 17.274893687840166
Epoch [53/500] Batch[11800/12648] complete. train_loss = 17.28130841230942
Epoch [53/500] Batch[12000/12648] complete. train_loss = 17.28581669251124
Epoch [53/500] Batch[12200/12648] complete. train_loss = 17.291725431504798
Epoch [53/500] Batch[12400/12648] complete. train_loss = 17.29622730239745
Epoch [53/500] Batch[12600/12648] complete. train_loss = 17.301872735174875
Epoch [53/500] Batch[12648/12648] complete. valid_loss = 19.742745876312256
Epoch [54/500] Batch[200/12648] complete. train_loss = 16.73070768356323
Epoch [54/500] Batch[400/12648] complete. train_loss = 16.729703793525697
Epoch [54/500] Batch[600/12648] complete. train_loss = 16.78341816107432
Epoch [54/500] Batch[800/12648] complete. train_loss = 16.81180871486664
Epoch [54/500] Batch[1000/12648] complete. train_loss = 16.82375784778595
Epoch [54/500] Batch[1200/12648] complete. train_loss = 16.846264328161876
Epoch [54/500] Batch[1400/12648] complete. train_loss = 16.854420498439243
Epoch [54/500] Batch[1600/12648] complete. train_loss = 16.860770169496536
Epoch [54/500] Batch[1800/12648] complete. train_loss = 16.88008285416497
Epoch [54/500] Batch[2000/12648] complete. train_loss = 16.895497401714326
Epoch [54/500] Batch[2200/12648] complete. train_loss = 16.90122994596308
Epoch [54/500] Batch[2400/12648] complete. train_loss = 16.916947017510733
Epoch [54/500] Batch[2600/12648] complete. train_loss = 16.9292758838947
Epoch [54/500] Batch[2800/12648] complete. train_loss = 16.93989191668374
Epoch [54/500] Batch[3000/12648] complete. train_loss = 16.94942553806305
Epoch [54/500] Batch[3200/12648] complete. train_loss = 16.9637004250288
Epoch [54/500] Batch[3400/12648] complete. train_loss = 16.977245213564704
Epoch [54/500] Batch[3600/12648] complete. train_loss = 16.99005367252562
Epoch [54/500] Batch[3800/12648] complete. train_loss = 16.996818678002608
Epoch [54/500] Batch[4000/12648] complete. train_loss = 17.00278178167343
Epoch [54/500] Batch[4200/12648] complete. train_loss = 17.011469343730383
Epoch [54/500] Batch[4400/12648] complete. train_loss = 17.022169678211213
Epoch [54/500] Batch[4600/12648] complete. train_loss = 17.024795084414276
Epoch [54/500] Batch[4800/12648] complete. train_loss = 17.032436380187672
Epoch [54/500] Batch[5000/12648] complete. train_loss = 17.03916914806366
Epoch [54/500] Batch[5200/12648] complete. train_loss = 17.047346123365255
Epoch [54/500] Batch[5400/12648] complete. train_loss = 17.0557706868207
Epoch [54/500] Batch[5600/12648] complete. train_loss = 17.06360986300877
Epoch [54/500] Batch[5800/12648] complete. train_loss = 17.071988269378398
Epoch [54/500] Batch[6000/12648] complete. train_loss = 17.07868814388911
Epoch [54/500] Batch[6200/12648] complete. train_loss = 17.086327185938437
Epoch [54/500] Batch[6400/12648] complete. train_loss = 17.09341963455081
Epoch [54/500] Batch[6600/12648] complete. train_loss = 17.101316620219837
Epoch [54/500] Batch[6800/12648] complete. train_loss = 17.107791191970602
Epoch [54/500] Batch[7000/12648] complete. train_loss = 17.113919808523995
Epoch [54/500] Batch[7200/12648] complete. train_loss = 17.120704679224225
Epoch [54/500] Batch[7400/12648] complete. train_loss = 17.12912056536288
Epoch [54/500] Batch[7600/12648] complete. train_loss = 17.132568848885988
Epoch [54/500] Batch[7800/12648] complete. train_loss = 17.13812539968735
Epoch [54/500] Batch[8000/12648] complete. train_loss = 17.1455894895792
Epoch [54/500] Batch[8200/12648] complete. train_loss = 17.152672633426945
Epoch [54/500] Batch[8400/12648] complete. train_loss = 17.158295772075654
Epoch [54/500] Batch[8600/12648] complete. train_loss = 17.16420915847601
Epoch [54/500] Batch[8800/12648] complete. train_loss = 17.169404507983813
Epoch [54/500] Batch[9000/12648] complete. train_loss = 17.175456930478415
Epoch [54/500] Batch[9200/12648] complete. train_loss = 17.18151057585426
Epoch [54/500] Batch[9400/12648] complete. train_loss = 17.185899410552167
Epoch [54/500] Batch[9600/12648] complete. train_loss = 17.190005689164003
Epoch [54/500] Batch[9800/12648] complete. train_loss = 17.193935773323993
Epoch [54/500] Batch[10000/12648] complete. train_loss = 17.19860660953522
Epoch [54/500] Batch[10200/12648] complete. train_loss = 17.204512361171197
Epoch [54/500] Batch[10400/12648] complete. train_loss = 17.20915036054758
Epoch [54/500] Batch[10600/12648] complete. train_loss = 17.216116732651333
Epoch [54/500] Batch[10800/12648] complete. train_loss = 17.222914189321024
Epoch [54/500] Batch[11000/12648] complete. train_loss = 17.227725121931595
Epoch [54/500] Batch[11200/12648] complete. train_loss = 17.23205232168947
Epoch [54/500] Batch[11400/12648] complete. train_loss = 17.237339046294228
Epoch [54/500] Batch[11600/12648] complete. train_loss = 17.240667480271437
Epoch [54/500] Batch[11800/12648] complete. train_loss = 17.246292328592073
Epoch [54/500] Batch[12000/12648] complete. train_loss = 17.251449345032373
Epoch [54/500] Batch[12200/12648] complete. train_loss = 17.255719650065313
Epoch [54/500] Batch[12400/12648] complete. train_loss = 17.259987949094466
Epoch [54/500] Batch[12600/12648] complete. train_loss = 17.266763011841547
Epoch [54/500] Batch[12648/12648] complete. valid_loss = 19.69543170928955
Epoch [55/500] Batch[200/12648] complete. train_loss = 16.8219167470932
Epoch [55/500] Batch[400/12648] complete. train_loss = 16.770955736637116
Epoch [55/500] Batch[600/12648] complete. train_loss = 16.824594093958538
Epoch [55/500] Batch[800/12648] complete. train_loss = 16.82319943189621
Epoch [55/500] Batch[1000/12648] complete. train_loss = 16.82010587310791
Epoch [55/500] Batch[1200/12648] complete. train_loss = 16.826193743546803
Epoch [55/500] Batch[1400/12648] complete. train_loss = 16.838013248443602
Epoch [55/500] Batch[1600/12648] complete. train_loss = 16.858871891498566
Epoch [55/500] Batch[1800/12648] complete. train_loss = 16.866779195467632
Epoch [55/500] Batch[2000/12648] complete. train_loss = 16.88624260520935
Epoch [55/500] Batch[2200/12648] complete. train_loss = 16.898158678141506
Epoch [55/500] Batch[2400/12648] complete. train_loss = 16.903003014326096
Epoch [55/500] Batch[2600/12648] complete. train_loss = 16.918008176363433
Epoch [55/500] Batch[2800/12648] complete. train_loss = 16.927729347433363
Epoch [55/500] Batch[3000/12648] complete. train_loss = 16.940088651974996
Epoch [55/500] Batch[3200/12648] complete. train_loss = 16.947026110589505
Epoch [55/500] Batch[3400/12648] complete. train_loss = 16.95833807075725
Epoch [55/500] Batch[3600/12648] complete. train_loss = 16.96770286904441
Epoch [55/500] Batch[3800/12648] complete. train_loss = 16.974068147759688
Epoch [55/500] Batch[4000/12648] complete. train_loss = 16.979679697990417
Epoch [55/500] Batch[4200/12648] complete. train_loss = 16.989951106253123
Epoch [55/500] Batch[4400/12648] complete. train_loss = 17.00030235377225
Epoch [55/500] Batch[4600/12648] complete. train_loss = 17.007233909938645
Epoch [55/500] Batch[4800/12648] complete. train_loss = 17.01392887413502
Epoch [55/500] Batch[5000/12648] complete. train_loss = 17.02107827682495
Epoch [55/500] Batch[5200/12648] complete. train_loss = 17.027155692393965
Epoch [55/500] Batch[5400/12648] complete. train_loss = 17.033872916963364
Epoch [55/500] Batch[5600/12648] complete. train_loss = 17.042989589486805
Epoch [55/500] Batch[5800/12648] complete. train_loss = 17.050058374569335
Epoch [55/500] Batch[6000/12648] complete. train_loss = 17.05598436578115
Epoch [55/500] Batch[6200/12648] complete. train_loss = 17.062106616881586
Epoch [55/500] Batch[6400/12648] complete. train_loss = 17.068973299711942
Epoch [55/500] Batch[6600/12648] complete. train_loss = 17.07437341487769
Epoch [55/500] Batch[6800/12648] complete. train_loss = 17.078841119373546
Epoch [55/500] Batch[7000/12648] complete. train_loss = 17.086999955858502
Epoch [55/500] Batch[7200/12648] complete. train_loss = 17.091388209528393
Epoch [55/500] Batch[7400/12648] complete. train_loss = 17.09712438132312
Epoch [55/500] Batch[7600/12648] complete. train_loss = 17.10109588986949
Epoch [55/500] Batch[7800/12648] complete. train_loss = 17.10557173521091
Epoch [55/500] Batch[8000/12648] complete. train_loss = 17.111516855359078
Epoch [55/500] Batch[8200/12648] complete. train_loss = 17.12021554400281
Epoch [55/500] Batch[8400/12648] complete. train_loss = 17.127444062119437
Epoch [55/500] Batch[8600/12648] complete. train_loss = 17.134511623715245
Epoch [55/500] Batch[8800/12648] complete. train_loss = 17.14069904706695
Epoch [55/500] Batch[9000/12648] complete. train_loss = 17.145255084991454
Epoch [55/500] Batch[9200/12648] complete. train_loss = 17.150807181026625
Epoch [55/500] Batch[9400/12648] complete. train_loss = 17.156023236234137
Epoch [55/500] Batch[9600/12648] complete. train_loss = 17.161651949286462
Epoch [55/500] Batch[9800/12648] complete. train_loss = 17.167188922921007
Epoch [55/500] Batch[10000/12648] complete. train_loss = 17.172883977127075
Epoch [55/500] Batch[10200/12648] complete. train_loss = 17.178213081172867
Epoch [55/500] Batch[10400/12648] complete. train_loss = 17.183397790010158
Epoch [55/500] Batch[10600/12648] complete. train_loss = 17.189081300519547
Epoch [55/500] Batch[10800/12648] complete. train_loss = 17.19310345331828
Epoch [55/500] Batch[11000/12648] complete. train_loss = 17.197848303881557
Epoch [55/500] Batch[11200/12648] complete. train_loss = 17.201624418837685
Epoch [55/500] Batch[11400/12648] complete. train_loss = 17.206474188754434
Epoch [55/500] Batch[11600/12648] complete. train_loss = 17.210184186491475
Epoch [55/500] Batch[11800/12648] complete. train_loss = 17.215458521923775
Epoch [55/500] Batch[12000/12648] complete. train_loss = 17.21821982630094
Epoch [55/500] Batch[12200/12648] complete. train_loss = 17.2230758732655
Epoch [55/500] Batch[12400/12648] complete. train_loss = 17.227814694681474
Epoch [55/500] Batch[12600/12648] complete. train_loss = 17.232004793485007
Epoch [55/500] Batch[12648/12648] complete. valid_loss = 19.711803913116455
Epoch [56/500] Batch[200/12648] complete. train_loss = 16.601412873268128
Epoch [56/500] Batch[400/12648] complete. train_loss = 16.63661471605301
Epoch [56/500] Batch[600/12648] complete. train_loss = 16.6627813911438
Epoch [56/500] Batch[800/12648] complete. train_loss = 16.710073900222778
Epoch [56/500] Batch[1000/12648] complete. train_loss = 16.74006798553467
Epoch [56/500] Batch[1200/12648] complete. train_loss = 16.763292798201242
Epoch [56/500] Batch[1400/12648] complete. train_loss = 16.780586677959988
Epoch [56/500] Batch[1600/12648] complete. train_loss = 16.797619460225107
Epoch [56/500] Batch[1800/12648] complete. train_loss = 16.81535597377353
Epoch [56/500] Batch[2000/12648] complete. train_loss = 16.82416495990753
Epoch [56/500] Batch[2200/12648] complete. train_loss = 16.831462225480514
Epoch [56/500] Batch[2400/12648] complete. train_loss = 16.843078809579215
Epoch [56/500] Batch[2600/12648] complete. train_loss = 16.854278858624973
Epoch [56/500] Batch[2800/12648] complete. train_loss = 16.86254131793976
Epoch [56/500] Batch[3000/12648] complete. train_loss = 16.87127574825287
Epoch [56/500] Batch[3200/12648] complete. train_loss = 16.88168130815029
Epoch [56/500] Batch[3400/12648] complete. train_loss = 16.89140137616326
Epoch [56/500] Batch[3600/12648] complete. train_loss = 16.902272648546433
Epoch [56/500] Batch[3800/12648] complete. train_loss = 16.91416120027241
Epoch [56/500] Batch[4000/12648] complete. train_loss = 16.927220143556596
Epoch [56/500] Batch[4200/12648] complete. train_loss = 16.93580298332941
Epoch [56/500] Batch[4400/12648] complete. train_loss = 16.94399407820268
Epoch [56/500] Batch[4600/12648] complete. train_loss = 16.95619108884231
Epoch [56/500] Batch[4800/12648] complete. train_loss = 16.966128085255622
Epoch [56/500] Batch[5000/12648] complete. train_loss = 16.974883458328247
Epoch [56/500] Batch[5200/12648] complete. train_loss = 16.98200957481678
Epoch [56/500] Batch[5400/12648] complete. train_loss = 16.989989378363997
Epoch [56/500] Batch[5600/12648] complete. train_loss = 16.997514342580523
Epoch [56/500] Batch[5800/12648] complete. train_loss = 17.001907472117193
Epoch [56/500] Batch[6000/12648] complete. train_loss = 17.00848580503464
Epoch [56/500] Batch[6200/12648] complete. train_loss = 17.01655443729893
Epoch [56/500] Batch[6400/12648] complete. train_loss = 17.024175142496823
Epoch [56/500] Batch[6600/12648] complete. train_loss = 17.032905275604943
Epoch [56/500] Batch[6800/12648] complete. train_loss = 17.039469251632692
Epoch [56/500] Batch[7000/12648] complete. train_loss = 17.04833483709608
Epoch [56/500] Batch[7200/12648] complete. train_loss = 17.053810633685853
Epoch [56/500] Batch[7400/12648] complete. train_loss = 17.061751923432222
Epoch [56/500] Batch[7600/12648] complete. train_loss = 17.06770952023958
Epoch [56/500] Batch[7800/12648] complete. train_loss = 17.076034486721724
Epoch [56/500] Batch[8000/12648] complete. train_loss = 17.083390894412993
Epoch [56/500] Batch[8200/12648] complete. train_loss = 17.08855679186379
Epoch [56/500] Batch[8400/12648] complete. train_loss = 17.094612972055163
Epoch [56/500] Batch[8600/12648] complete. train_loss = 17.10131764955299
Epoch [56/500] Batch[8800/12648] complete. train_loss = 17.106489328687843
Epoch [56/500] Batch[9000/12648] complete. train_loss = 17.113347931861878
Epoch [56/500] Batch[9200/12648] complete. train_loss = 17.119166791335395
Epoch [56/500] Batch[9400/12648] complete. train_loss = 17.123582808819222
Epoch [56/500] Batch[9600/12648] complete. train_loss = 17.128715458114943
Epoch [56/500] Batch[9800/12648] complete. train_loss = 17.13367974407819
Epoch [56/500] Batch[10000/12648] complete. train_loss = 17.13926125192642
Epoch [56/500] Batch[10200/12648] complete. train_loss = 17.14498381689483
Epoch [56/500] Batch[10400/12648] complete. train_loss = 17.147916595477323
Epoch [56/500] Batch[10600/12648] complete. train_loss = 17.152675299914378
Epoch [56/500] Batch[10800/12648] complete. train_loss = 17.1567466935405
Epoch [56/500] Batch[11000/12648] complete. train_loss = 17.162264836398037
Epoch [56/500] Batch[11200/12648] complete. train_loss = 17.168038323351315
Epoch [56/500] Batch[11400/12648] complete. train_loss = 17.172783460449754
Epoch [56/500] Batch[11600/12648] complete. train_loss = 17.178324595648668
Epoch [56/500] Batch[11800/12648] complete. train_loss = 17.18354998750202
Epoch [56/500] Batch[12000/12648] complete. train_loss = 17.187671985228857
Epoch [56/500] Batch[12200/12648] complete. train_loss = 17.192869906269134
Epoch [56/500] Batch[12400/12648] complete. train_loss = 17.197849938561838
Epoch [56/500] Batch[12600/12648] complete. train_loss = 17.20118867276207
Epoch [56/500] Batch[12648/12648] complete. valid_loss = 19.67380142211914
Epoch [57/500] Batch[200/12648] complete. train_loss = 16.692371878623963
Epoch [57/500] Batch[400/12648] complete. train_loss = 16.712741401195526
Epoch [57/500] Batch[600/12648] complete. train_loss = 16.737186980247497
Epoch [57/500] Batch[800/12648] complete. train_loss = 16.749077439308167
Epoch [57/500] Batch[1000/12648] complete. train_loss = 16.77030817985535
Epoch [57/500] Batch[1200/12648] complete. train_loss = 16.769678138891855
Epoch [57/500] Batch[1400/12648] complete. train_loss = 16.790352957589285
Epoch [57/500] Batch[1600/12648] complete. train_loss = 16.797108638882637
Epoch [57/500] Batch[1800/12648] complete. train_loss = 16.798912012312147
Epoch [57/500] Batch[2000/12648] complete. train_loss = 16.814371110916138
Epoch [57/500] Batch[2200/12648] complete. train_loss = 16.82062546556646
Epoch [57/500] Batch[2400/12648] complete. train_loss = 16.826890059709548
Epoch [57/500] Batch[2600/12648] complete. train_loss = 16.843627521441533
Epoch [57/500] Batch[2800/12648] complete. train_loss = 16.85772739171982
Epoch [57/500] Batch[3000/12648] complete. train_loss = 16.867707160631817
Epoch [57/500] Batch[3200/12648] complete. train_loss = 16.87236765474081
Epoch [57/500] Batch[3400/12648] complete. train_loss = 16.882088498788722
Epoch [57/500] Batch[3600/12648] complete. train_loss = 16.889328394465977
Epoch [57/500] Batch[3800/12648] complete. train_loss = 16.900777024971813
Epoch [57/500] Batch[4000/12648] complete. train_loss = 16.91024393439293
Epoch [57/500] Batch[4200/12648] complete. train_loss = 16.919951972961425
Epoch [57/500] Batch[4400/12648] complete. train_loss = 16.93061224980788
Epoch [57/500] Batch[4600/12648] complete. train_loss = 16.938308070846226
Epoch [57/500] Batch[4800/12648] complete. train_loss = 16.947207971811295
Epoch [57/500] Batch[5000/12648] complete. train_loss = 16.958361236572266
Epoch [57/500] Batch[5200/12648] complete. train_loss = 16.96532697219115
Epoch [57/500] Batch[5400/12648] complete. train_loss = 16.971715401720118
Epoch [57/500] Batch[5600/12648] complete. train_loss = 16.978408060925346
Epoch [57/500] Batch[5800/12648] complete. train_loss = 16.981469788880183
Epoch [57/500] Batch[6000/12648] complete. train_loss = 16.988256030400596
Epoch [57/500] Batch[6200/12648] complete. train_loss = 16.995086998785695
Epoch [57/500] Batch[6400/12648] complete. train_loss = 17.002555010318755
Epoch [57/500] Batch[6600/12648] complete. train_loss = 17.008381714242876
Epoch [57/500] Batch[6800/12648] complete. train_loss = 17.012845750135533
Epoch [57/500] Batch[7000/12648] complete. train_loss = 17.020567186764307
Epoch [57/500] Batch[7200/12648] complete. train_loss = 17.02369788752662
Epoch [57/500] Batch[7400/12648] complete. train_loss = 17.029700783909977
Epoch [57/500] Batch[7600/12648] complete. train_loss = 17.03652541863291
Epoch [57/500] Batch[7800/12648] complete. train_loss = 17.043021571941864
Epoch [57/500] Batch[8000/12648] complete. train_loss = 17.047926661133765
Epoch [57/500] Batch[8200/12648] complete. train_loss = 17.05357405546235
Epoch [57/500] Batch[8400/12648] complete. train_loss = 17.06242854186467
Epoch [57/500] Batch[8600/12648] complete. train_loss = 17.069450745360797
Epoch [57/500] Batch[8800/12648] complete. train_loss = 17.075392751476983
Epoch [57/500] Batch[9000/12648] complete. train_loss = 17.08113878832923
Epoch [57/500] Batch[9200/12648] complete. train_loss = 17.086487156722857
Epoch [57/500] Batch[9400/12648] complete. train_loss = 17.091855687283456
Epoch [57/500] Batch[9600/12648] complete. train_loss = 17.097653883596262
Epoch [57/500] Batch[9800/12648] complete. train_loss = 17.102676333602595
Epoch [57/500] Batch[10000/12648] complete. train_loss = 17.108744494724274
Epoch [57/500] Batch[10200/12648] complete. train_loss = 17.11099956970589
Epoch [57/500] Batch[10400/12648] complete. train_loss = 17.115892172776736
Epoch [57/500] Batch[10600/12648] complete. train_loss = 17.121057411409772
Epoch [57/500] Batch[10800/12648] complete. train_loss = 17.125639975600773
Epoch [57/500] Batch[11000/12648] complete. train_loss = 17.130656444289468
Epoch [57/500] Batch[11200/12648] complete. train_loss = 17.136442795481
Epoch [57/500] Batch[11400/12648] complete. train_loss = 17.14039813928437
Epoch [57/500] Batch[11600/12648] complete. train_loss = 17.143498920243363
Epoch [57/500] Batch[11800/12648] complete. train_loss = 17.147310286618897
Epoch [57/500] Batch[12000/12648] complete. train_loss = 17.151902606487273
Epoch [57/500] Batch[12200/12648] complete. train_loss = 17.157995083058466
Epoch [57/500] Batch[12400/12648] complete. train_loss = 17.16238011021768
Epoch [57/500] Batch[12600/12648] complete. train_loss = 17.167322833348834
Epoch [57/500] Batch[12648/12648] complete. valid_loss = 19.702789545059204
Epoch [58/500] Batch[200/12648] complete. train_loss = 16.65116744041443
Epoch [58/500] Batch[400/12648] complete. train_loss = 16.67976976633072
Epoch [58/500] Batch[600/12648] complete. train_loss = 16.69403063774109
Epoch [58/500] Batch[800/12648] complete. train_loss = 16.712620475292205
Epoch [58/500] Batch[1000/12648] complete. train_loss = 16.725551267623903
Epoch [58/500] Batch[1200/12648] complete. train_loss = 16.732021775245666
Epoch [58/500] Batch[1400/12648] complete. train_loss = 16.74108357361385
Epoch [58/500] Batch[1600/12648] complete. train_loss = 16.758696165680885
Epoch [58/500] Batch[1800/12648] complete. train_loss = 16.779258642196655
Epoch [58/500] Batch[2000/12648] complete. train_loss = 16.78813366317749
Epoch [58/500] Batch[2200/12648] complete. train_loss = 16.786739835305646
Epoch [58/500] Batch[2400/12648] complete. train_loss = 16.79823570887248
Epoch [58/500] Batch[2600/12648] complete. train_loss = 16.80771680538471
Epoch [58/500] Batch[2800/12648] complete. train_loss = 16.821003751073565
Epoch [58/500] Batch[3000/12648] complete. train_loss = 16.82936462434133
Epoch [58/500] Batch[3200/12648] complete. train_loss = 16.841148775219917
Epoch [58/500] Batch[3400/12648] complete. train_loss = 16.851304715100458
Epoch [58/500] Batch[3600/12648] complete. train_loss = 16.859710643556383
Epoch [58/500] Batch[3800/12648] complete. train_loss = 16.86600551329161
Epoch [58/500] Batch[4000/12648] complete. train_loss = 16.8745050907135
Epoch [58/500] Batch[4200/12648] complete. train_loss = 16.88222797734397
Epoch [58/500] Batch[4400/12648] complete. train_loss = 16.88774085781791
Epoch [58/500] Batch[4600/12648] complete. train_loss = 16.898852154068326
Epoch [58/500] Batch[4800/12648] complete. train_loss = 16.904112356702488
Epoch [58/500] Batch[5000/12648] complete. train_loss = 16.915198704910278
Epoch [58/500] Batch[5200/12648] complete. train_loss = 16.922286796386427
Epoch [58/500] Batch[5400/12648] complete. train_loss = 16.9289136173107
Epoch [58/500] Batch[5600/12648] complete. train_loss = 16.9381034215859
Epoch [58/500] Batch[5800/12648] complete. train_loss = 16.942318010165774
Epoch [58/500] Batch[6000/12648] complete. train_loss = 16.948847572962443
Epoch [58/500] Batch[6200/12648] complete. train_loss = 16.95579169704068
Epoch [58/500] Batch[6400/12648] complete. train_loss = 16.964242974966766
Epoch [58/500] Batch[6600/12648] complete. train_loss = 16.970577120491953
Epoch [58/500] Batch[6800/12648] complete. train_loss = 16.97859904681935
Epoch [58/500] Batch[7000/12648] complete. train_loss = 16.983565056119648
Epoch [58/500] Batch[7200/12648] complete. train_loss = 16.989547620481915
Epoch [58/500] Batch[7400/12648] complete. train_loss = 16.997719339937778
Epoch [58/500] Batch[7600/12648] complete. train_loss = 17.00213533602263
Epoch [58/500] Batch[7800/12648] complete. train_loss = 17.009304299599084
Epoch [58/500] Batch[8000/12648] complete. train_loss = 17.01653418123722
Epoch [58/500] Batch[8200/12648] complete. train_loss = 17.021218999537027
Epoch [58/500] Batch[8400/12648] complete. train_loss = 17.026602073396955
Epoch [58/500] Batch[8600/12648] complete. train_loss = 17.03139223819555
Epoch [58/500] Batch[8800/12648] complete. train_loss = 17.037697205001656
Epoch [58/500] Batch[9000/12648] complete. train_loss = 17.044607498910693
Epoch [58/500] Batch[9200/12648] complete. train_loss = 17.0507797186271
Epoch [58/500] Batch[9400/12648] complete. train_loss = 17.05795596518415
Epoch [58/500] Batch[9600/12648] complete. train_loss = 17.06188601354758
Epoch [58/500] Batch[9800/12648] complete. train_loss = 17.06715190410614
Epoch [58/500] Batch[10000/12648] complete. train_loss = 17.071149524116517
Epoch [58/500] Batch[10200/12648] complete. train_loss = 17.077006869035607
Epoch [58/500] Batch[10400/12648] complete. train_loss = 17.08229635165288
Epoch [58/500] Batch[10600/12648] complete. train_loss = 17.087468902479927
Epoch [58/500] Batch[10800/12648] complete. train_loss = 17.093700229061973
Epoch [58/500] Batch[11000/12648] complete. train_loss = 17.098451554731888
Epoch [58/500] Batch[11200/12648] complete. train_loss = 17.103234171271325
Epoch [58/500] Batch[11400/12648] complete. train_loss = 17.108649580185872
Epoch [58/500] Batch[11600/12648] complete. train_loss = 17.111443338229737
Epoch [58/500] Batch[11800/12648] complete. train_loss = 17.117336072921752
Epoch [58/500] Batch[12000/12648] complete. train_loss = 17.12254479376475
Epoch [58/500] Batch[12200/12648] complete. train_loss = 17.128215657296728
Epoch [58/500] Batch[12400/12648] complete. train_loss = 17.132647498115418
Epoch [58/500] Batch[12600/12648] complete. train_loss = 17.137443493737116
Epoch [58/500] Batch[12648/12648] complete. valid_loss = 19.77523446083069
Epoch [59/500] Batch[200/12648] complete. train_loss = 16.585805816650392
Epoch [59/500] Batch[400/12648] complete. train_loss = 16.63072476387024
Epoch [59/500] Batch[600/12648] complete. train_loss = 16.61835962295532
Epoch [59/500] Batch[800/12648] complete. train_loss = 16.67181842446327
Epoch [59/500] Batch[1000/12648] complete. train_loss = 16.682132328987123
Epoch [59/500] Batch[1200/12648] complete. train_loss = 16.684194904168447
Epoch [59/500] Batch[1400/12648] complete. train_loss = 16.692273800032478
Epoch [59/500] Batch[1600/12648] complete. train_loss = 16.705830941796304
Epoch [59/500] Batch[1800/12648] complete. train_loss = 16.725937163035073
Epoch [59/500] Batch[2000/12648] complete. train_loss = 16.73419439792633
Epoch [59/500] Batch[2200/12648] complete. train_loss = 16.7431579468467
Epoch [59/500] Batch[2400/12648] complete. train_loss = 16.74890493154526
Epoch [59/500] Batch[2600/12648] complete. train_loss = 16.75990394408886
Epoch [59/500] Batch[2800/12648] complete. train_loss = 16.776136964389256
Epoch [59/500] Batch[3000/12648] complete. train_loss = 16.788806170463562
Epoch [59/500] Batch[3200/12648] complete. train_loss = 16.80648728042841
Epoch [59/500] Batch[3400/12648] complete. train_loss = 16.816452980602488
Epoch [59/500] Batch[3600/12648] complete. train_loss = 16.828836215072208
Epoch [59/500] Batch[3800/12648] complete. train_loss = 16.839262567068403
Epoch [59/500] Batch[4000/12648] complete. train_loss = 16.85189906716347
Epoch [59/500] Batch[4200/12648] complete. train_loss = 16.860824845858982
Epoch [59/500] Batch[4400/12648] complete. train_loss = 16.86842658779838
Epoch [59/500] Batch[4600/12648] complete. train_loss = 16.871545432339545
Epoch [59/500] Batch[4800/12648] complete. train_loss = 16.880825566450756
Epoch [59/500] Batch[5000/12648] complete. train_loss = 16.889187480926513
Epoch [59/500] Batch[5200/12648] complete. train_loss = 16.89505001801711
Epoch [59/500] Batch[5400/12648] complete. train_loss = 16.9005752047786
Epoch [59/500] Batch[5600/12648] complete. train_loss = 16.910473065887178
Epoch [59/500] Batch[5800/12648] complete. train_loss = 16.916031250953676
Epoch [59/500] Batch[6000/12648] complete. train_loss = 16.920338708877562
Epoch [59/500] Batch[6200/12648] complete. train_loss = 16.929633965646065
Epoch [59/500] Batch[6400/12648] complete. train_loss = 16.93561087295413
Epoch [59/500] Batch[6600/12648] complete. train_loss = 16.941583315820406
Epoch [59/500] Batch[6800/12648] complete. train_loss = 16.95041586300906
Epoch [59/500] Batch[7000/12648] complete. train_loss = 16.954043189457483
Epoch [59/500] Batch[7200/12648] complete. train_loss = 16.959282256232367
Epoch [59/500] Batch[7400/12648] complete. train_loss = 16.967973260750643
Epoch [59/500] Batch[7600/12648] complete. train_loss = 16.973409319425883
Epoch [59/500] Batch[7800/12648] complete. train_loss = 16.98209246513171
Epoch [59/500] Batch[8000/12648] complete. train_loss = 16.987921674251556
Epoch [59/500] Batch[8200/12648] complete. train_loss = 16.994582688401383
Epoch [59/500] Batch[8400/12648] complete. train_loss = 17.00005380880265
Epoch [59/500] Batch[8600/12648] complete. train_loss = 17.00617190028346
Epoch [59/500] Batch[8800/12648] complete. train_loss = 17.011090120293876
Epoch [59/500] Batch[9000/12648] complete. train_loss = 17.017996127870347
Epoch [59/500] Batch[9200/12648] complete. train_loss = 17.025499679109323
Epoch [59/500] Batch[9400/12648] complete. train_loss = 17.030117425005486
Epoch [59/500] Batch[9600/12648] complete. train_loss = 17.035625842412312
Epoch [59/500] Batch[9800/12648] complete. train_loss = 17.040377957772236
Epoch [59/500] Batch[10000/12648] complete. train_loss = 17.044318082237243
Epoch [59/500] Batch[10200/12648] complete. train_loss = 17.049568327548457
Epoch [59/500] Batch[10400/12648] complete. train_loss = 17.053726514486165
Epoch [59/500] Batch[10600/12648] complete. train_loss = 17.058598628493975
Epoch [59/500] Batch[10800/12648] complete. train_loss = 17.06258358284279
Epoch [59/500] Batch[11000/12648] complete. train_loss = 17.068493216081098
Epoch [59/500] Batch[11200/12648] complete. train_loss = 17.074516018288477
Epoch [59/500] Batch[11400/12648] complete. train_loss = 17.07920344218873
Epoch [59/500] Batch[11600/12648] complete. train_loss = 17.08382082445868
Epoch [59/500] Batch[11800/12648] complete. train_loss = 17.08883718838126
Epoch [59/500] Batch[12000/12648] complete. train_loss = 17.092594133615492
Epoch [59/500] Batch[12200/12648] complete. train_loss = 17.099433059614213
Epoch [59/500] Batch[12400/12648] complete. train_loss = 17.10331372668666
Epoch [59/500] Batch[12600/12648] complete. train_loss = 17.108382243807355
Epoch [59/500] Batch[12648/12648] complete. valid_loss = 19.858848094940186
Epoch [60/500] Batch[200/12648] complete. train_loss = 16.625978350639343
Epoch [60/500] Batch[400/12648] complete. train_loss = 16.609612081050873
Epoch [60/500] Batch[600/12648] complete. train_loss = 16.635308726628622
Epoch [60/500] Batch[800/12648] complete. train_loss = 16.65845506429672
Epoch [60/500] Batch[1000/12648] complete. train_loss = 16.671513864517213
Epoch [60/500] Batch[1200/12648] complete. train_loss = 16.67560460329056
Epoch [60/500] Batch[1400/12648] complete. train_loss = 16.685770366532463
Epoch [60/500] Batch[1600/12648] complete. train_loss = 16.693860500454903
Epoch [60/500] Batch[1800/12648] complete. train_loss = 16.699627060890197
Epoch [60/500] Batch[2000/12648] complete. train_loss = 16.710472182750703
Epoch [60/500] Batch[2200/12648] complete. train_loss = 16.72251774441112
Epoch [60/500] Batch[2400/12648] complete. train_loss = 16.73268130858739
Epoch [60/500] Batch[2600/12648] complete. train_loss = 16.744073666059055
Epoch [60/500] Batch[2800/12648] complete. train_loss = 16.756670784269062
Epoch [60/500] Batch[3000/12648] complete. train_loss = 16.76145298989614
Epoch [60/500] Batch[3200/12648] complete. train_loss = 16.77360839366913
Epoch [60/500] Batch[3400/12648] complete. train_loss = 16.784144607151255
Epoch [60/500] Batch[3600/12648] complete. train_loss = 16.794501221179964
Epoch [60/500] Batch[3800/12648] complete. train_loss = 16.803163161779704
Epoch [60/500] Batch[4000/12648] complete. train_loss = 16.813902525424957
Epoch [60/500] Batch[4200/12648] complete. train_loss = 16.818317048436118
Epoch [60/500] Batch[4400/12648] complete. train_loss = 16.825062040849165
Epoch [60/500] Batch[4600/12648] complete. train_loss = 16.83546595075856
Epoch [60/500] Batch[4800/12648] complete. train_loss = 16.845354926188786
Epoch [60/500] Batch[5000/12648] complete. train_loss = 16.85288965797424
Epoch [60/500] Batch[5200/12648] complete. train_loss = 16.863971855090213
Epoch [60/500] Batch[5400/12648] complete. train_loss = 16.86899082360444
Epoch [60/500] Batch[5600/12648] complete. train_loss = 16.877748131922313
Epoch [60/500] Batch[5800/12648] complete. train_loss = 16.88616571311293
Epoch [60/500] Batch[6000/12648] complete. train_loss = 16.89070274098714
Epoch [60/500] Batch[6200/12648] complete. train_loss = 16.898147929560754
Epoch [60/500] Batch[6400/12648] complete. train_loss = 16.906708469241856
Epoch [60/500] Batch[6600/12648] complete. train_loss = 16.913642590262672
Epoch [60/500] Batch[6800/12648] complete. train_loss = 16.920681660876554
Epoch [60/500] Batch[7000/12648] complete. train_loss = 16.926779570988245
Epoch [60/500] Batch[7200/12648] complete. train_loss = 16.933418778181075
Epoch [60/500] Batch[7400/12648] complete. train_loss = 16.94035710128578
Epoch [60/500] Batch[7600/12648] complete. train_loss = 16.945962597696404
Epoch [60/500] Batch[7800/12648] complete. train_loss = 16.951206545218444
Epoch [60/500] Batch[8000/12648] complete. train_loss = 16.959067617297173
Epoch [60/500] Batch[8200/12648] complete. train_loss = 16.965684479038888
Epoch [60/500] Batch[8400/12648] complete. train_loss = 16.97165492818469
Epoch [60/500] Batch[8600/12648] complete. train_loss = 16.977958299725554
Epoch [60/500] Batch[8800/12648] complete. train_loss = 16.984355802752756
Epoch [60/500] Batch[9000/12648] complete. train_loss = 16.989302201377022
Epoch [60/500] Batch[9200/12648] complete. train_loss = 16.995407115583834
Epoch [60/500] Batch[9400/12648] complete. train_loss = 16.99754761908917
Epoch [60/500] Batch[9600/12648] complete. train_loss = 17.0025444556276
Epoch [60/500] Batch[9800/12648] complete. train_loss = 17.007864165889973
Epoch [60/500] Batch[10000/12648] complete. train_loss = 17.012752897071838
Epoch [60/500] Batch[10200/12648] complete. train_loss = 17.019413013271258
Epoch [60/500] Batch[10400/12648] complete. train_loss = 17.02517248896452
Epoch [60/500] Batch[10600/12648] complete. train_loss = 17.029373635436006
Epoch [60/500] Batch[10800/12648] complete. train_loss = 17.034808889936517
Epoch [60/500] Batch[11000/12648] complete. train_loss = 17.03870325270566
Epoch [60/500] Batch[11200/12648] complete. train_loss = 17.04274674509253
Epoch [60/500] Batch[11400/12648] complete. train_loss = 17.04764175030223
Epoch [60/500] Batch[11600/12648] complete. train_loss = 17.052983002087167
Epoch [60/500] Batch[11800/12648] complete. train_loss = 17.05921121467978
Epoch [60/500] Batch[12000/12648] complete. train_loss = 17.06468180235227
Epoch [60/500] Batch[12200/12648] complete. train_loss = 17.06872045360628
Epoch [60/500] Batch[12400/12648] complete. train_loss = 17.073422981539082
Epoch [60/500] Batch[12600/12648] complete. train_loss = 17.079687608764285
Epoch [60/500] Batch[12648/12648] complete. valid_loss = 19.78451180458069
Epoch [61/500] Batch[200/12648] complete. train_loss = 16.606126446723938
Epoch [61/500] Batch[400/12648] complete. train_loss = 16.586193697452543
Epoch [61/500] Batch[600/12648] complete. train_loss = 16.62325464407603
Epoch [61/500] Batch[800/12648] complete. train_loss = 16.61739073038101
Epoch [61/500] Batch[1000/12648] complete. train_loss = 16.636010887145996
Epoch [61/500] Batch[1200/12648] complete. train_loss = 16.65419194539388
Epoch [61/500] Batch[1400/12648] complete. train_loss = 16.672890662465775
Epoch [61/500] Batch[1600/12648] complete. train_loss = 16.681354848742487
Epoch [61/500] Batch[1800/12648] complete. train_loss = 16.682392466862996
Epoch [61/500] Batch[2000/12648] complete. train_loss = 16.689899542808533
Epoch [61/500] Batch[2200/12648] complete. train_loss = 16.697259350689976
Epoch [61/500] Batch[2400/12648] complete. train_loss = 16.706536192496618
Epoch [61/500] Batch[2600/12648] complete. train_loss = 16.720429849624633
Epoch [61/500] Batch[2800/12648] complete. train_loss = 16.724012555054255
Epoch [61/500] Batch[3000/12648] complete. train_loss = 16.730357666333518
Epoch [61/500] Batch[3200/12648] complete. train_loss = 16.739358682334423
Epoch [61/500] Batch[3400/12648] complete. train_loss = 16.750153003019445
Epoch [61/500] Batch[3600/12648] complete. train_loss = 16.765948768456777
Epoch [61/500] Batch[3800/12648] complete. train_loss = 16.770742622425683
Epoch [61/500] Batch[4000/12648] complete. train_loss = 16.777322547912597
Epoch [61/500] Batch[4200/12648] complete. train_loss = 16.787050958360943
Epoch [61/500] Batch[4400/12648] complete. train_loss = 16.79502609122883
Epoch [61/500] Batch[4600/12648] complete. train_loss = 16.805953948808753
Epoch [61/500] Batch[4800/12648] complete. train_loss = 16.814279571970303
Epoch [61/500] Batch[5000/12648] complete. train_loss = 16.821916935157777
Epoch [61/500] Batch[5200/12648] complete. train_loss = 16.82871846822592
Epoch [61/500] Batch[5400/12648] complete. train_loss = 16.838606008600305
Epoch [61/500] Batch[5600/12648] complete. train_loss = 16.848347170863832
Epoch [61/500] Batch[5800/12648] complete. train_loss = 16.854525922249103
Epoch [61/500] Batch[6000/12648] complete. train_loss = 16.86227028385798
Epoch [61/500] Batch[6200/12648] complete. train_loss = 16.86743501186371
Epoch [61/500] Batch[6400/12648] complete. train_loss = 16.876517609804868
Epoch [61/500] Batch[6600/12648] complete. train_loss = 16.88308117909865
Epoch [61/500] Batch[6800/12648] complete. train_loss = 16.893353251008428
Epoch [61/500] Batch[7000/12648] complete. train_loss = 16.901058537619456
Epoch [61/500] Batch[7200/12648] complete. train_loss = 16.90700981934865
Epoch [61/500] Batch[7400/12648] complete. train_loss = 16.913339423617803
Epoch [61/500] Batch[7600/12648] complete. train_loss = 16.920825590459923
Epoch [61/500] Batch[7800/12648] complete. train_loss = 16.927508153181808
Epoch [61/500] Batch[8000/12648] complete. train_loss = 16.934972561359405
Epoch [61/500] Batch[8200/12648] complete. train_loss = 16.94295327035392
Epoch [61/500] Batch[8400/12648] complete. train_loss = 16.94856166998545
Epoch [61/500] Batch[8600/12648] complete. train_loss = 16.95331489030705
Epoch [61/500] Batch[8800/12648] complete. train_loss = 16.959019304188814
Epoch [61/500] Batch[9000/12648] complete. train_loss = 16.964246646457248
Epoch [61/500] Batch[9200/12648] complete. train_loss = 16.9676630089594
Epoch [61/500] Batch[9400/12648] complete. train_loss = 16.972588471757604
Epoch [61/500] Batch[9600/12648] complete. train_loss = 16.97786895811558
Epoch [61/500] Batch[9800/12648] complete. train_loss = 16.98190372340533
Epoch [61/500] Batch[10000/12648] complete. train_loss = 16.987361799812316
Epoch [61/500] Batch[10200/12648] complete. train_loss = 16.993115011850993
Epoch [61/500] Batch[10400/12648] complete. train_loss = 16.997866412859697
Epoch [61/500] Batch[10600/12648] complete. train_loss = 17.002101707818372
Epoch [61/500] Batch[10800/12648] complete. train_loss = 17.007185521743917
Epoch [61/500] Batch[11000/12648] complete. train_loss = 17.012989344943655
Epoch [61/500] Batch[11200/12648] complete. train_loss = 17.017676111119133
Epoch [61/500] Batch[11400/12648] complete. train_loss = 17.022364112452458
Epoch [61/500] Batch[11600/12648] complete. train_loss = 17.02657975739446
Epoch [61/500] Batch[11800/12648] complete. train_loss = 17.032224444858098
Epoch [61/500] Batch[12000/12648] complete. train_loss = 17.03671517221133
Epoch [61/500] Batch[12200/12648] complete. train_loss = 17.041760125160216
Epoch [61/500] Batch[12400/12648] complete. train_loss = 17.046380136397577
Epoch [61/500] Batch[12600/12648] complete. train_loss = 17.051188921398587
Epoch [61/500] Batch[12648/12648] complete. valid_loss = 19.73031735420227
Epoch [62/500] Batch[200/12648] complete. train_loss = 16.572245125770568
Epoch [62/500] Batch[400/12648] complete. train_loss = 16.59232547044754
Epoch [62/500] Batch[600/12648] complete. train_loss = 16.590558164914448
Epoch [62/500] Batch[800/12648] complete. train_loss = 16.609322493076323
Epoch [62/500] Batch[1000/12648] complete. train_loss = 16.60967669868469
Epoch [62/500] Batch[1200/12648] complete. train_loss = 16.606453113555908
Epoch [62/500] Batch[1400/12648] complete. train_loss = 16.629023629597256
Epoch [62/500] Batch[1600/12648] complete. train_loss = 16.63254509329796
Epoch [62/500] Batch[1800/12648] complete. train_loss = 16.640880996386212
Epoch [62/500] Batch[2000/12648] complete. train_loss = 16.64460207462311
Epoch [62/500] Batch[2200/12648] complete. train_loss = 16.661551978804848
Epoch [62/500] Batch[2400/12648] complete. train_loss = 16.676204739014306
Epoch [62/500] Batch[2600/12648] complete. train_loss = 16.68198153972626
Epoch [62/500] Batch[2800/12648] complete. train_loss = 16.697998840808868
Epoch [62/500] Batch[3000/12648] complete. train_loss = 16.70659093570709
Epoch [62/500] Batch[3200/12648] complete. train_loss = 16.715981214642525
Epoch [62/500] Batch[3400/12648] complete. train_loss = 16.72686263925889
Epoch [62/500] Batch[3600/12648] complete. train_loss = 16.734134442806244
Epoch [62/500] Batch[3800/12648] complete. train_loss = 16.741280144641273
Epoch [62/500] Batch[4000/12648] complete. train_loss = 16.754724302768707
Epoch [62/500] Batch[4200/12648] complete. train_loss = 16.76263184456598
Epoch [62/500] Batch[4400/12648] complete. train_loss = 16.768167410547083
Epoch [62/500] Batch[4600/12648] complete. train_loss = 16.777586348575095
Epoch [62/500] Batch[4800/12648] complete. train_loss = 16.786770923137667
Epoch [62/500] Batch[5000/12648] complete. train_loss = 16.794385905075075
Epoch [62/500] Batch[5200/12648] complete. train_loss = 16.80588660643651
Epoch [62/500] Batch[5400/12648] complete. train_loss = 16.81412296383469
Epoch [62/500] Batch[5600/12648] complete. train_loss = 16.824217066253933
Epoch [62/500] Batch[5800/12648] complete. train_loss = 16.83289252429173
Epoch [62/500] Batch[6000/12648] complete. train_loss = 16.838706848144533
Epoch [62/500] Batch[6200/12648] complete. train_loss = 16.844321401657595
Epoch [62/500] Batch[6400/12648] complete. train_loss = 16.85181654036045
Epoch [62/500] Batch[6600/12648] complete. train_loss = 16.857318563027814
Epoch [62/500] Batch[6800/12648] complete. train_loss = 16.862494229989892
Epoch [62/500] Batch[7000/12648] complete. train_loss = 16.868538281304495
Epoch [62/500] Batch[7200/12648] complete. train_loss = 16.872911398145888
Epoch [62/500] Batch[7400/12648] complete. train_loss = 16.878841357102264
Epoch [62/500] Batch[7600/12648] complete. train_loss = 16.884602427231638
Epoch [62/500] Batch[7800/12648] complete. train_loss = 16.89056678588574
Epoch [62/500] Batch[8000/12648] complete. train_loss = 16.89479915034771
Epoch [62/500] Batch[8200/12648] complete. train_loss = 16.9013604328109
Epoch [62/500] Batch[8400/12648] complete. train_loss = 16.907632413251058
Epoch [62/500] Batch[8600/12648] complete. train_loss = 16.91546573638916
Epoch [62/500] Batch[8800/12648] complete. train_loss = 16.922720637646588
Epoch [62/500] Batch[9000/12648] complete. train_loss = 16.928369326061674
Epoch [62/500] Batch[9200/12648] complete. train_loss = 16.932368508525517
Epoch [62/500] Batch[9400/12648] complete. train_loss = 16.939026021957396
Epoch [62/500] Batch[9600/12648] complete. train_loss = 16.944477638999622
Epoch [62/500] Batch[9800/12648] complete. train_loss = 16.950742577144077
Epoch [62/500] Batch[10000/12648] complete. train_loss = 16.95686650428772
Epoch [62/500] Batch[10200/12648] complete. train_loss = 16.962240845081855
Epoch [62/500] Batch[10400/12648] complete. train_loss = 16.968047103881837
Epoch [62/500] Batch[10600/12648] complete. train_loss = 16.97318676381741
Epoch [62/500] Batch[10800/12648] complete. train_loss = 16.978182829662604
Epoch [62/500] Batch[11000/12648] complete. train_loss = 16.98268214000355
Epoch [62/500] Batch[11200/12648] complete. train_loss = 16.986862154347556
Epoch [62/500] Batch[11400/12648] complete. train_loss = 16.990667996573865
Epoch [62/500] Batch[11600/12648] complete. train_loss = 16.994653848861827
Epoch [62/500] Batch[11800/12648] complete. train_loss = 17.000864069583052
Epoch [62/500] Batch[12000/12648] complete. train_loss = 17.00536812345187
Epoch [62/500] Batch[12200/12648] complete. train_loss = 17.011281089391865
Epoch [62/500] Batch[12400/12648] complete. train_loss = 17.015655034203682
Epoch [62/500] Batch[12600/12648] complete. train_loss = 17.020503582348898
Epoch [62/500] Batch[12648/12648] complete. valid_loss = 19.746268272399902
Epoch [63/500] Batch[200/12648] complete. train_loss = 16.52330662250519
Epoch [63/500] Batch[400/12648] complete. train_loss = 16.492352187633514
Epoch [63/500] Batch[600/12648] complete. train_loss = 16.510477313995363
Epoch [63/500] Batch[800/12648] complete. train_loss = 16.54366162419319
Epoch [63/500] Batch[1000/12648] complete. train_loss = 16.56832725906372
Epoch [63/500] Batch[1200/12648] complete. train_loss = 16.5729039144516
Epoch [63/500] Batch[1400/12648] complete. train_loss = 16.59738553728376
Epoch [63/500] Batch[1600/12648] complete. train_loss = 16.62287854194641
Epoch [63/500] Batch[1800/12648] complete. train_loss = 16.630012779765657
Epoch [63/500] Batch[2000/12648] complete. train_loss = 16.634806211948394
Epoch [63/500] Batch[2200/12648] complete. train_loss = 16.650575162714176
Epoch [63/500] Batch[2400/12648] complete. train_loss = 16.67007013440132
Epoch [63/500] Batch[2600/12648] complete. train_loss = 16.685652879568245
Epoch [63/500] Batch[2800/12648] complete. train_loss = 16.69232254743576
Epoch [63/500] Batch[3000/12648] complete. train_loss = 16.70253659915924
Epoch [63/500] Batch[3200/12648] complete. train_loss = 16.711516122221948
Epoch [63/500] Batch[3400/12648] complete. train_loss = 16.71784232896917
Epoch [63/500] Batch[3600/12648] complete. train_loss = 16.726476033793556
Epoch [63/500] Batch[3800/12648] complete. train_loss = 16.739180243893674
Epoch [63/500] Batch[4000/12648] complete. train_loss = 16.74913207292557
Epoch [63/500] Batch[4200/12648] complete. train_loss = 16.756845637957255
Epoch [63/500] Batch[4400/12648] complete. train_loss = 16.761983869075774
Epoch [63/500] Batch[4600/12648] complete. train_loss = 16.767479099812714
Epoch [63/500] Batch[4800/12648] complete. train_loss = 16.774072387417156
Epoch [63/500] Batch[5000/12648] complete. train_loss = 16.7820060880661
Epoch [63/500] Batch[5200/12648] complete. train_loss = 16.791299221515654
Epoch [63/500] Batch[5400/12648] complete. train_loss = 16.80061657022547
Epoch [63/500] Batch[5600/12648] complete. train_loss = 16.80958441700254
Epoch [63/500] Batch[5800/12648] complete. train_loss = 16.817458649997054
Epoch [63/500] Batch[6000/12648] complete. train_loss = 16.8232248284022
Epoch [63/500] Batch[6200/12648] complete. train_loss = 16.83098578637646
Epoch [63/500] Batch[6400/12648] complete. train_loss = 16.83607512488961
Epoch [63/500] Batch[6600/12648] complete. train_loss = 16.843854033730246
Epoch [63/500] Batch[6800/12648] complete. train_loss = 16.851337761878966
Epoch [63/500] Batch[7000/12648] complete. train_loss = 16.857838359151568
Epoch [63/500] Batch[7200/12648] complete. train_loss = 16.86680967370669
Epoch [63/500] Batch[7400/12648] complete. train_loss = 16.87133877741324
Epoch [63/500] Batch[7600/12648] complete. train_loss = 16.876408178555337
Epoch [63/500] Batch[7800/12648] complete. train_loss = 16.882322755104457
Epoch [63/500] Batch[8000/12648] complete. train_loss = 16.88740770328045
Epoch [63/500] Batch[8200/12648] complete. train_loss = 16.893941000961675
Epoch [63/500] Batch[8400/12648] complete. train_loss = 16.89812290044058
Epoch [63/500] Batch[8600/12648] complete. train_loss = 16.90375913741977
Epoch [63/500] Batch[8800/12648] complete. train_loss = 16.90791204680096
Epoch [63/500] Batch[9000/12648] complete. train_loss = 16.912138328764172
Epoch [63/500] Batch[9200/12648] complete. train_loss = 16.91806805268578
Epoch [63/500] Batch[9400/12648] complete. train_loss = 16.92213769851847
Epoch [63/500] Batch[9600/12648] complete. train_loss = 16.927464661697545
Epoch [63/500] Batch[9800/12648] complete. train_loss = 16.932012005630806
