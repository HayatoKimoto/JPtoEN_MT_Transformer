cuda
Epoch [1/500] Batch[200/1720] complete. train_loss = 76.42904388427735
Epoch [1/500] Batch[400/1720] complete. train_loss = 70.41389850616456
Epoch [1/500] Batch[600/1720] complete. train_loss = 66.76345792770385
Epoch [1/500] Batch[800/1720] complete. train_loss = 64.15713031768799
Epoch [1/500] Batch[1000/1720] complete. train_loss = 62.16659702682495
Epoch [1/500] Batch[1200/1720] complete. train_loss = 60.58580550829569
Epoch [1/500] Batch[1400/1720] complete. train_loss = 59.28625089100429
Epoch [1/500] Batch[1600/1720] complete. train_loss = 58.171636486053465
Epoch [1/500] Batch[1720/1720] complete. valid_loss = 46.37573127746582
best models saved
Best Valid Loss = 46.37573127746582 (Epoch: 1)


Epoch [2/500] Batch[200/1720] complete. train_loss = 48.6704439163208
Epoch [2/500] Batch[400/1720] complete. train_loss = 48.35423105239868
Epoch [2/500] Batch[600/1720] complete. train_loss = 48.04409614562988
Epoch [2/500] Batch[800/1720] complete. train_loss = 47.748425788879395
Epoch [2/500] Batch[1000/1720] complete. train_loss = 47.435145698547366
Epoch [2/500] Batch[1200/1720] complete. train_loss = 47.148927218119304
Epoch [2/500] Batch[1400/1720] complete. train_loss = 46.88144684655326
Epoch [2/500] Batch[1600/1720] complete. train_loss = 46.630235712528226
Epoch [2/500] Batch[1720/1720] complete. valid_loss = 41.51186637878418
best models saved
Best Valid Loss = 41.51186637878418 (Epoch: 2)


Epoch [3/500] Batch[200/1720] complete. train_loss = 43.80733602523804
Epoch [3/500] Batch[400/1720] complete. train_loss = 43.69076029777527
Epoch [3/500] Batch[600/1720] complete. train_loss = 43.53206678390503
Epoch [3/500] Batch[800/1720] complete. train_loss = 43.36154928684235
Epoch [3/500] Batch[1000/1720] complete. train_loss = 43.23064767074585
Epoch [3/500] Batch[1200/1720] complete. train_loss = 43.076079781850176
Epoch [3/500] Batch[1400/1720] complete. train_loss = 42.911124071393694
Epoch [3/500] Batch[1600/1720] complete. train_loss = 42.779259650707246
Epoch [3/500] Batch[1720/1720] complete. valid_loss = 39.00472450256348
best models saved
Best Valid Loss = 39.00472450256348 (Epoch: 3)


Epoch [4/500] Batch[200/1720] complete. train_loss = 41.02925428390503
Epoch [4/500] Batch[400/1720] complete. train_loss = 40.84737970352173
Epoch [4/500] Batch[600/1720] complete. train_loss = 40.731671447753904
Epoch [4/500] Batch[800/1720] complete. train_loss = 40.645871710777286
Epoch [4/500] Batch[1000/1720] complete. train_loss = 40.51257090377808
Epoch [4/500] Batch[1200/1720] complete. train_loss = 40.40062646230062
Epoch [4/500] Batch[1400/1720] complete. train_loss = 40.33090735026768
Epoch [4/500] Batch[1600/1720] complete. train_loss = 40.22843847990036
Epoch [4/500] Batch[1720/1720] complete. valid_loss = 37.14327163696289
best models saved
Best Valid Loss = 37.14327163696289 (Epoch: 4)


Epoch [5/500] Batch[200/1720] complete. train_loss = 38.66436143875122
Epoch [5/500] Batch[400/1720] complete. train_loss = 38.5755260181427
Epoch [5/500] Batch[600/1720] complete. train_loss = 38.57734933853149
Epoch [5/500] Batch[800/1720] complete. train_loss = 38.4906848192215
Epoch [5/500] Batch[1000/1720] complete. train_loss = 38.430130016326906
Epoch [5/500] Batch[1200/1720] complete. train_loss = 38.34781503677368
Epoch [5/500] Batch[1400/1720] complete. train_loss = 38.300889320373535
Epoch [5/500] Batch[1600/1720] complete. train_loss = 38.23034971475601
Epoch [5/500] Batch[1720/1720] complete. valid_loss = 35.818054580688475
best models saved
Best Valid Loss = 35.818054580688475 (Epoch: 5)


Epoch [6/500] Batch[200/1720] complete. train_loss = 36.802874145507815
Epoch [6/500] Batch[400/1720] complete. train_loss = 36.694156856536864
Epoch [6/500] Batch[600/1720] complete. train_loss = 36.665813280741375
Epoch [6/500] Batch[800/1720] complete. train_loss = 36.590010571479795
Epoch [6/500] Batch[1000/1720] complete. train_loss = 36.535871257781984
Epoch [6/500] Batch[1200/1720] complete. train_loss = 36.474239622751874
Epoch [6/500] Batch[1400/1720] complete. train_loss = 36.41715447562081
Epoch [6/500] Batch[1600/1720] complete. train_loss = 36.34642054080963
Epoch [6/500] Batch[1720/1720] complete. valid_loss = 34.24014434814453
best models saved
Best Valid Loss = 34.24014434814453 (Epoch: 6)


Epoch [7/500] Batch[200/1720] complete. train_loss = 34.8768782043457
Epoch [7/500] Batch[400/1720] complete. train_loss = 34.85854117393494
Epoch [7/500] Batch[600/1720] complete. train_loss = 34.7855708694458
Epoch [7/500] Batch[800/1720] complete. train_loss = 34.77247292995453
Epoch [7/500] Batch[1000/1720] complete. train_loss = 34.69762993621826
Epoch [7/500] Batch[1200/1720] complete. train_loss = 34.656850264867145
Epoch [7/500] Batch[1400/1720] complete. train_loss = 34.60966597557068
Epoch [7/500] Batch[1600/1720] complete. train_loss = 34.54467971920967
Epoch [7/500] Batch[1720/1720] complete. valid_loss = 32.73602523803711
best models saved
Best Valid Loss = 32.73602523803711 (Epoch: 7)


Epoch [8/500] Batch[200/1720] complete. train_loss = 33.067167644500735
Epoch [8/500] Batch[400/1720] complete. train_loss = 33.05628891944885
Epoch [8/500] Batch[600/1720] complete. train_loss = 33.02204789161682
Epoch [8/500] Batch[800/1720] complete. train_loss = 32.99431965112686
Epoch [8/500] Batch[1000/1720] complete. train_loss = 32.95086546707153
Epoch [8/500] Batch[1200/1720] complete. train_loss = 32.89921404361725
Epoch [8/500] Batch[1400/1720] complete. train_loss = 32.84247653143746
Epoch [8/500] Batch[1600/1720] complete. train_loss = 32.77968406438828
Epoch [8/500] Batch[1720/1720] complete. valid_loss = 31.05888557434082
best models saved
Best Valid Loss = 31.05888557434082 (Epoch: 8)


Epoch [9/500] Batch[200/1720] complete. train_loss = 31.280597553253173
Epoch [9/500] Batch[400/1720] complete. train_loss = 31.290272278785707
Epoch [9/500] Batch[600/1720] complete. train_loss = 31.308598912556967
Epoch [9/500] Batch[800/1720] complete. train_loss = 31.29714012145996
Epoch [9/500] Batch[1000/1720] complete. train_loss = 31.268308528900146
Epoch [9/500] Batch[1200/1720] complete. train_loss = 31.207738176981607
Epoch [9/500] Batch[1400/1720] complete. train_loss = 31.16232715879168
Epoch [9/500] Batch[1600/1720] complete. train_loss = 31.094649711847307
Epoch [9/500] Batch[1720/1720] complete. valid_loss = 29.71683540344238
best models saved
Best Valid Loss = 29.71683540344238 (Epoch: 9)


Epoch [10/500] Batch[200/1720] complete. train_loss = 29.794707021713258
Epoch [10/500] Batch[400/1720] complete. train_loss = 29.763547892570497
Epoch [10/500] Batch[600/1720] complete. train_loss = 29.70743584314982
Epoch [10/500] Batch[800/1720] complete. train_loss = 29.684838435649873
Epoch [10/500] Batch[1000/1720] complete. train_loss = 29.650417518615722
Epoch [10/500] Batch[1200/1720] complete. train_loss = 29.607259481747946
Epoch [10/500] Batch[1400/1720] complete. train_loss = 29.580002311979023
Epoch [10/500] Batch[1600/1720] complete. train_loss = 29.54356853246689
Epoch [10/500] Batch[1720/1720] complete. valid_loss = 28.730694580078126
best models saved
Best Valid Loss = 28.730694580078126 (Epoch: 10)


Epoch [11/500] Batch[200/1720] complete. train_loss = 28.27062466621399
Epoch [11/500] Batch[400/1720] complete. train_loss = 28.25024569988251
Epoch [11/500] Batch[600/1720] complete. train_loss = 28.209998540878296
Epoch [11/500] Batch[800/1720] complete. train_loss = 28.20870022535324
Epoch [11/500] Batch[1000/1720] complete. train_loss = 28.207429977416993
Epoch [11/500] Batch[1200/1720] complete. train_loss = 28.201654353141784
Epoch [11/500] Batch[1400/1720] complete. train_loss = 28.1921054322379
Epoch [11/500] Batch[1600/1720] complete. train_loss = 28.18199242711067
Epoch [11/500] Batch[1720/1720] complete. valid_loss = 27.81628761291504
best models saved
Best Valid Loss = 27.81628761291504 (Epoch: 11)


Epoch [12/500] Batch[200/1720] complete. train_loss = 26.983236989974976
Epoch [12/500] Batch[400/1720] complete. train_loss = 27.02030715942383
Epoch [12/500] Batch[600/1720] complete. train_loss = 27.014041465123494
Epoch [12/500] Batch[800/1720] complete. train_loss = 27.02204097032547
Epoch [12/500] Batch[1000/1720] complete. train_loss = 27.01875517845154
Epoch [12/500] Batch[1200/1720] complete. train_loss = 27.00194261868795
Epoch [12/500] Batch[1400/1720] complete. train_loss = 26.992929865973338
Epoch [12/500] Batch[1600/1720] complete. train_loss = 27.001563600301743
Epoch [12/500] Batch[1720/1720] complete. valid_loss = 27.391840362548827
best models saved
Best Valid Loss = 27.391840362548827 (Epoch: 12)


Epoch [13/500] Batch[200/1720] complete. train_loss = 25.700105714797974
Epoch [13/500] Batch[400/1720] complete. train_loss = 25.828741083145143
Epoch [13/500] Batch[600/1720] complete. train_loss = 25.857735169728596
Epoch [13/500] Batch[800/1720] complete. train_loss = 25.87297601222992
Epoch [13/500] Batch[1000/1720] complete. train_loss = 25.90859853935242
Epoch [13/500] Batch[1200/1720] complete. train_loss = 25.914523547490436
Epoch [13/500] Batch[1400/1720] complete. train_loss = 25.930137711933682
Epoch [13/500] Batch[1600/1720] complete. train_loss = 25.934475457668306
Epoch [13/500] Batch[1720/1720] complete. valid_loss = 26.922033882141115
best models saved
Best Valid Loss = 26.922033882141115 (Epoch: 13)


Epoch [14/500] Batch[200/1720] complete. train_loss = 24.816314144134523
Epoch [14/500] Batch[400/1720] complete. train_loss = 24.905998849868773
Epoch [14/500] Batch[600/1720] complete. train_loss = 24.925817464192708
Epoch [14/500] Batch[800/1720] complete. train_loss = 24.9567139005661
Epoch [14/500] Batch[1000/1720] complete. train_loss = 24.959724964141845
Epoch [14/500] Batch[1200/1720] complete. train_loss = 24.97253954410553
Epoch [14/500] Batch[1400/1720] complete. train_loss = 24.960224975858416
Epoch [14/500] Batch[1600/1720] complete. train_loss = 24.969207680225374
Epoch [14/500] Batch[1720/1720] complete. valid_loss = 26.296234321594238
best models saved
Best Valid Loss = 26.296234321594238 (Epoch: 14)


Epoch [15/500] Batch[200/1720] complete. train_loss = 23.925246238708496
Epoch [15/500] Batch[400/1720] complete. train_loss = 23.907859501838683
Epoch [15/500] Batch[600/1720] complete. train_loss = 23.967287759780884
Epoch [15/500] Batch[800/1720] complete. train_loss = 23.988754832744597
Epoch [15/500] Batch[1000/1720] complete. train_loss = 24.019761600494384
Epoch [15/500] Batch[1200/1720] complete. train_loss = 24.042261573473613
Epoch [15/500] Batch[1400/1720] complete. train_loss = 24.06892275401524
Epoch [15/500] Batch[1600/1720] complete. train_loss = 24.08966804265976
Epoch [15/500] Batch[1720/1720] complete. valid_loss = 26.201252365112303
best models saved
Best Valid Loss = 26.201252365112303 (Epoch: 15)


Epoch [16/500] Batch[200/1720] complete. train_loss = 23.062705993652344
Epoch [16/500] Batch[400/1720] complete. train_loss = 23.05363832950592
Epoch [16/500] Batch[600/1720] complete. train_loss = 23.08248919169108
Epoch [16/500] Batch[800/1720] complete. train_loss = 23.15039421081543
Epoch [16/500] Batch[1000/1720] complete. train_loss = 23.20132232284546
Epoch [16/500] Batch[1200/1720] complete. train_loss = 23.240475516319275
Epoch [16/500] Batch[1400/1720] complete. train_loss = 23.255151598794118
Epoch [16/500] Batch[1600/1720] complete. train_loss = 23.27024970650673
Epoch [16/500] Batch[1720/1720] complete. valid_loss = 25.810954093933105
best models saved
Best Valid Loss = 25.810954093933105 (Epoch: 16)


Epoch [17/500] Batch[200/1720] complete. train_loss = 22.278168687820436
Epoch [17/500] Batch[400/1720] complete. train_loss = 22.3235927772522
Epoch [17/500] Batch[600/1720] complete. train_loss = 22.375308945973714
Epoch [17/500] Batch[800/1720] complete. train_loss = 22.417397215366364
Epoch [17/500] Batch[1000/1720] complete. train_loss = 22.44545171928406
Epoch [17/500] Batch[1200/1720] complete. train_loss = 22.467088538805644
Epoch [17/500] Batch[1400/1720] complete. train_loss = 22.499879179000853
Epoch [17/500] Batch[1600/1720] complete. train_loss = 22.522674006223678
Epoch [17/500] Batch[1720/1720] complete. valid_loss = 25.65402717590332
best models saved
Best Valid Loss = 25.65402717590332 (Epoch: 17)


Epoch [18/500] Batch[200/1720] complete. train_loss = 21.459791498184202
Epoch [18/500] Batch[400/1720] complete. train_loss = 21.526568322181703
Epoch [18/500] Batch[600/1720] complete. train_loss = 21.630011835098266
Epoch [18/500] Batch[800/1720] complete. train_loss = 21.68488613128662
Epoch [18/500] Batch[1000/1720] complete. train_loss = 21.720656204223634
Epoch [18/500] Batch[1200/1720] complete. train_loss = 21.772874496777852
Epoch [18/500] Batch[1400/1720] complete. train_loss = 21.79745473589216
Epoch [18/500] Batch[1600/1720] complete. train_loss = 21.822089030742646
Epoch [18/500] Batch[1720/1720] complete. valid_loss = 25.47185707092285
best models saved
Best Valid Loss = 25.47185707092285 (Epoch: 18)


Epoch [19/500] Batch[200/1720] complete. train_loss = 20.90534872055054
Epoch [19/500] Batch[400/1720] complete. train_loss = 20.892723321914673
Epoch [19/500] Batch[600/1720] complete. train_loss = 20.929087902704875
Epoch [19/500] Batch[800/1720] complete. train_loss = 21.007327408790587
Epoch [19/500] Batch[1000/1720] complete. train_loss = 21.071135728836058
Epoch [19/500] Batch[1200/1720] complete. train_loss = 21.10712511062622
Epoch [19/500] Batch[1400/1720] complete. train_loss = 21.13313552720206
Epoch [19/500] Batch[1600/1720] complete. train_loss = 21.161881309747695
Epoch [19/500] Batch[1720/1720] complete. valid_loss = 25.30353527069092
best models saved
Best Valid Loss = 25.30353527069092 (Epoch: 19)


Epoch [20/500] Batch[200/1720] complete. train_loss = 20.169736728668212
Epoch [20/500] Batch[400/1720] complete. train_loss = 20.25470950603485
Epoch [20/500] Batch[600/1720] complete. train_loss = 20.343261919021607
Epoch [20/500] Batch[800/1720] complete. train_loss = 20.397982048988343
Epoch [20/500] Batch[1000/1720] complete. train_loss = 20.463395517349245
Epoch [20/500] Batch[1200/1720] complete. train_loss = 20.495019585291544
Epoch [20/500] Batch[1400/1720] complete. train_loss = 20.531343593597413
Epoch [20/500] Batch[1600/1720] complete. train_loss = 20.556648074388505
Epoch [20/500] Batch[1720/1720] complete. valid_loss = 25.425671768188476
Epoch [21/500] Batch[200/1720] complete. train_loss = 19.640092821121215
Epoch [21/500] Batch[400/1720] complete. train_loss = 19.74292944908142
Epoch [21/500] Batch[600/1720] complete. train_loss = 19.746188151041668
Epoch [21/500] Batch[800/1720] complete. train_loss = 19.808331899642944
Epoch [21/500] Batch[1000/1720] complete. train_loss = 19.852745769500732
Epoch [21/500] Batch[1200/1720] complete. train_loss = 19.889924017588296
Epoch [21/500] Batch[1400/1720] complete. train_loss = 19.928664375032696
Epoch [21/500] Batch[1600/1720] complete. train_loss = 19.96417271852493
Epoch [21/500] Batch[1720/1720] complete. valid_loss = 25.192754554748536
best models saved
Best Valid Loss = 25.192754554748536 (Epoch: 21)


Epoch [22/500] Batch[200/1720] complete. train_loss = 19.0056555557251
Epoch [22/500] Batch[400/1720] complete. train_loss = 19.046458740234375
Epoch [22/500] Batch[600/1720] complete. train_loss = 19.166767460505167
Epoch [22/500] Batch[800/1720] complete. train_loss = 19.22900534629822
Epoch [22/500] Batch[1000/1720] complete. train_loss = 19.29279397201538
Epoch [22/500] Batch[1200/1720] complete. train_loss = 19.3392329565684
Epoch [22/500] Batch[1400/1720] complete. train_loss = 19.381014783041817
Epoch [22/500] Batch[1600/1720] complete. train_loss = 19.41166250228882
Epoch [22/500] Batch[1720/1720] complete. valid_loss = 25.09750442504883
best models saved
Best Valid Loss = 25.09750442504883 (Epoch: 22)


Epoch [23/500] Batch[200/1720] complete. train_loss = 18.441135711669922
Epoch [23/500] Batch[400/1720] complete. train_loss = 18.57171670436859
Epoch [23/500] Batch[600/1720] complete. train_loss = 18.628178749084473
Epoch [23/500] Batch[800/1720] complete. train_loss = 18.690432102680205
Epoch [23/500] Batch[1000/1720] complete. train_loss = 18.74622765159607
Epoch [23/500] Batch[1200/1720] complete. train_loss = 18.79859511534373
Epoch [23/500] Batch[1400/1720] complete. train_loss = 18.82828766959054
Epoch [23/500] Batch[1600/1720] complete. train_loss = 18.866331847906114
Epoch [23/500] Batch[1720/1720] complete. valid_loss = 25.004890632629394
best models saved
Best Valid Loss = 25.004890632629394 (Epoch: 23)


Epoch [24/500] Batch[200/1720] complete. train_loss = 17.979236316680907
Epoch [24/500] Batch[400/1720] complete. train_loss = 18.032466049194337
Epoch [24/500] Batch[600/1720] complete. train_loss = 18.090357131958008
Epoch [24/500] Batch[800/1720] complete. train_loss = 18.18013732433319
Epoch [24/500] Batch[1000/1720] complete. train_loss = 18.236905694961546
Epoch [24/500] Batch[1200/1720] complete. train_loss = 18.276381041208904
Epoch [24/500] Batch[1400/1720] complete. train_loss = 18.325939707074845
Epoch [24/500] Batch[1600/1720] complete. train_loss = 18.374578667879106
Epoch [24/500] Batch[1720/1720] complete. valid_loss = 25.253371810913087
Epoch [25/500] Batch[200/1720] complete. train_loss = 17.529232063293456
Epoch [25/500] Batch[400/1720] complete. train_loss = 17.612184133529663
Epoch [25/500] Batch[600/1720] complete. train_loss = 17.646187438964844
Epoch [25/500] Batch[800/1720] complete. train_loss = 17.71070423603058
Epoch [25/500] Batch[1000/1720] complete. train_loss = 17.76997720336914
Epoch [25/500] Batch[1200/1720] complete. train_loss = 17.81652191956838
Epoch [25/500] Batch[1400/1720] complete. train_loss = 17.856956352506366
Epoch [25/500] Batch[1600/1720] complete. train_loss = 17.887936054468156
Epoch [25/500] Batch[1720/1720] complete. valid_loss = 25.151012802124022
Epoch [26/500] Batch[200/1720] complete. train_loss = 16.99436559677124
Epoch [26/500] Batch[400/1720] complete. train_loss = 17.086953856945037
Epoch [26/500] Batch[600/1720] complete. train_loss = 17.172760113080344
Epoch [26/500] Batch[800/1720] complete. train_loss = 17.229564929008482
Epoch [26/500] Batch[1000/1720] complete. train_loss = 17.273131338119505
Epoch [26/500] Batch[1200/1720] complete. train_loss = 17.333170653978982
Epoch [26/500] Batch[1400/1720] complete. train_loss = 17.381290040016175
Epoch [26/500] Batch[1600/1720] complete. train_loss = 17.425417620539665
Epoch [26/500] Batch[1720/1720] complete. valid_loss = 25.1778657913208
Epoch [27/500] Batch[200/1720] complete. train_loss = 16.513551898002625
Epoch [27/500] Batch[400/1720] complete. train_loss = 16.627881247997284
Epoch [27/500] Batch[600/1720] complete. train_loss = 16.702496751149496
Epoch [27/500] Batch[800/1720] complete. train_loss = 16.763990247249602
Epoch [27/500] Batch[1000/1720] complete. train_loss = 16.82077451610565
Epoch [27/500] Batch[1200/1720] complete. train_loss = 16.871716628869375
Epoch [27/500] Batch[1400/1720] complete. train_loss = 16.927104388645716
Epoch [27/500] Batch[1600/1720] complete. train_loss = 16.9686341047287
Epoch [27/500] Batch[1720/1720] complete. valid_loss = 25.40499782562256
Epoch [28/500] Batch[200/1720] complete. train_loss = 16.168706917762755
Epoch [28/500] Batch[400/1720] complete. train_loss = 16.195137746334076
Epoch [28/500] Batch[600/1720] complete. train_loss = 16.282805012067158
Epoch [28/500] Batch[800/1720] complete. train_loss = 16.354430730342866
Epoch [28/500] Batch[1000/1720] complete. train_loss = 16.411969017982482
Epoch [28/500] Batch[1200/1720] complete. train_loss = 16.448536405563356
Epoch [28/500] Batch[1400/1720] complete. train_loss = 16.49089447907039
Epoch [28/500] Batch[1600/1720] complete. train_loss = 16.53931816995144
Epoch [28/500] Batch[1720/1720] complete. valid_loss = 25.390782737731932
Epoch [29/500] Batch[200/1720] complete. train_loss = 15.67998788356781
Epoch [29/500] Batch[400/1720] complete. train_loss = 15.790921721458435
Epoch [29/500] Batch[600/1720] complete. train_loss = 15.823333868980408
Epoch [29/500] Batch[800/1720] complete. train_loss = 15.902874982357025
Epoch [29/500] Batch[1000/1720] complete. train_loss = 15.948807097434997
Epoch [29/500] Batch[1200/1720] complete. train_loss = 16.00462339401245
Epoch [29/500] Batch[1400/1720] complete. train_loss = 16.067071947370255
Epoch [29/500] Batch[1600/1720] complete. train_loss = 16.11192294716835
Epoch [29/500] Batch[1720/1720] complete. valid_loss = 25.34518356323242
Epoch [30/500] Batch[200/1720] complete. train_loss = 15.196804957389832
Epoch [30/500] Batch[400/1720] complete. train_loss = 15.296462025642395
Epoch [30/500] Batch[600/1720] complete. train_loss = 15.392281654675802
Epoch [30/500] Batch[800/1720] complete. train_loss = 15.469796838760375
Epoch [30/500] Batch[1000/1720] complete. train_loss = 15.54806337928772
Epoch [30/500] Batch[1200/1720] complete. train_loss = 15.611546770731609
Epoch [30/500] Batch[1400/1720] complete. train_loss = 15.66866070679256
Epoch [30/500] Batch[1600/1720] complete. train_loss = 15.720712277889252
Epoch [30/500] Batch[1720/1720] complete. valid_loss = 25.408843803405762
Epoch [31/500] Batch[200/1720] complete. train_loss = 14.84753821849823
Epoch [31/500] Batch[400/1720] complete. train_loss = 14.962286837100983
Epoch [31/500] Batch[600/1720] complete. train_loss = 15.048253809611003
Epoch [31/500] Batch[800/1720] complete. train_loss = 15.097378506660462
Epoch [31/500] Batch[1000/1720] complete. train_loss = 15.15871415901184
Epoch [31/500] Batch[1200/1720] complete. train_loss = 15.205746966997783
Epoch [31/500] Batch[1400/1720] complete. train_loss = 15.256461200032915
Epoch [31/500] Batch[1600/1720] complete. train_loss = 15.315752670168877
Epoch [31/500] Batch[1720/1720] complete. valid_loss = 25.601490783691407
Epoch [32/500] Batch[200/1720] complete. train_loss = 14.507374172210694
Epoch [32/500] Batch[400/1720] complete. train_loss = 14.568287997245788
Epoch [32/500] Batch[600/1720] complete. train_loss = 14.653695228894552
Epoch [32/500] Batch[800/1720] complete. train_loss = 14.71805674314499
Epoch [32/500] Batch[1000/1720] complete. train_loss = 14.770952733039856
Epoch [32/500] Batch[1200/1720] complete. train_loss = 14.832238542238871
Epoch [32/500] Batch[1400/1720] complete. train_loss = 14.889257037980215
Epoch [32/500] Batch[1600/1720] complete. train_loss = 14.946102547049522
Epoch [32/500] Batch[1720/1720] complete. valid_loss = 25.76343688964844
Epoch [33/500] Batch[200/1720] complete. train_loss = 14.059569268226623
Epoch [33/500] Batch[400/1720] complete. train_loss = 14.159374380111695
Epoch [33/500] Batch[600/1720] complete. train_loss = 14.260386422475179
Epoch [33/500] Batch[800/1720] complete. train_loss = 14.324880110025406
Epoch [33/500] Batch[1000/1720] complete. train_loss = 14.396471019744872
Epoch [33/500] Batch[1200/1720] complete. train_loss = 14.46347882827123
Epoch [33/500] Batch[1400/1720] complete. train_loss = 14.51472124849047
Epoch [33/500] Batch[1600/1720] complete. train_loss = 14.571569771766663
Epoch [33/500] Batch[1720/1720] complete. valid_loss = 25.79640140533447
Epoch [34/500] Batch[200/1720] complete. train_loss = 13.745660667419434
Epoch [34/500] Batch[400/1720] complete. train_loss = 13.846639118194581
Epoch [34/500] Batch[600/1720] complete. train_loss = 13.930004671414693
Epoch [34/500] Batch[800/1720] complete. train_loss = 14.005042332410813
Epoch [34/500] Batch[1000/1720] complete. train_loss = 14.062847208976745
Epoch [34/500] Batch[1200/1720] complete. train_loss = 14.122819454669953
Epoch [34/500] Batch[1400/1720] complete. train_loss = 14.171888278552464
Epoch [34/500] Batch[1600/1720] complete. train_loss = 14.226767199635505
Epoch [34/500] Batch[1720/1720] complete. valid_loss = 26.10246810913086
Epoch [35/500] Batch[200/1720] complete. train_loss = 13.415383162498474
Epoch [35/500] Batch[400/1720] complete. train_loss = 13.51049993276596
Epoch [35/500] Batch[600/1720] complete. train_loss = 13.560158960024516
Epoch [35/500] Batch[800/1720] complete. train_loss = 13.653096021413804
Epoch [35/500] Batch[1000/1720] complete. train_loss = 13.705555280685426
Epoch [35/500] Batch[1200/1720] complete. train_loss = 13.759549691677094
Epoch [35/500] Batch[1400/1720] complete. train_loss = 13.815505628585816
Epoch [35/500] Batch[1600/1720] complete. train_loss = 13.869939203858376
Epoch [35/500] Batch[1720/1720] complete. valid_loss = 26.243218612670898
Epoch [36/500] Batch[200/1720] complete. train_loss = 13.045274019241333
Epoch [36/500] Batch[400/1720] complete. train_loss = 13.128887650966645
Epoch [36/500] Batch[600/1720] complete. train_loss = 13.191770615577697
Epoch [36/500] Batch[800/1720] complete. train_loss = 13.275180299282074
Epoch [36/500] Batch[1000/1720] complete. train_loss = 13.336835466384887
Epoch [36/500] Batch[1200/1720] complete. train_loss = 13.414378101825713
Epoch [36/500] Batch[1400/1720] complete. train_loss = 13.473690391949244
Epoch [36/500] Batch[1600/1720] complete. train_loss = 13.524682821035386
Epoch [36/500] Batch[1720/1720] complete. valid_loss = 26.40118408203125
Epoch [37/500] Batch[200/1720] complete. train_loss = 12.68856056213379
Epoch [37/500] Batch[400/1720] complete. train_loss = 12.76466642856598
Epoch [37/500] Batch[600/1720] complete. train_loss = 12.872200492223104
Epoch [37/500] Batch[800/1720] complete. train_loss = 12.95410357952118
Epoch [37/500] Batch[1000/1720] complete. train_loss = 13.017609214782714
Epoch [37/500] Batch[1200/1720] complete. train_loss = 13.09346859296163
Epoch [37/500] Batch[1400/1720] complete. train_loss = 13.141466980661665
Epoch [37/500] Batch[1600/1720] complete. train_loss = 13.193105187416077
Epoch [37/500] Batch[1720/1720] complete. valid_loss = 26.54223346710205
Epoch [38/500] Batch[200/1720] complete. train_loss = 12.359618935585022
Epoch [38/500] Batch[400/1720] complete. train_loss = 12.477986013889312
Epoch [38/500] Batch[600/1720] complete. train_loss = 12.544761198361714
Epoch [38/500] Batch[800/1720] complete. train_loss = 12.617191962003709
Epoch [38/500] Batch[1000/1720] complete. train_loss = 12.685224168777467
Epoch [38/500] Batch[1200/1720] complete. train_loss = 12.758622376918792
Epoch [38/500] Batch[1400/1720] complete. train_loss = 12.817724389348712
Epoch [38/500] Batch[1600/1720] complete. train_loss = 12.864738321900369
Epoch [38/500] Batch[1720/1720] complete. valid_loss = 26.660812759399413
Epoch [39/500] Batch[200/1720] complete. train_loss = 12.03982283592224
Epoch [39/500] Batch[400/1720] complete. train_loss = 12.123853135108948
Epoch [39/500] Batch[600/1720] complete. train_loss = 12.223828290303548
Epoch [39/500] Batch[800/1720] complete. train_loss = 12.312103592157364
Epoch [39/500] Batch[1000/1720] complete. train_loss = 12.372399393081665
Epoch [39/500] Batch[1200/1720] complete. train_loss = 12.443769428730011
Epoch [39/500] Batch[1400/1720] complete. train_loss = 12.50453291620527
Epoch [39/500] Batch[1600/1720] complete. train_loss = 12.558561837077141
Epoch [39/500] Batch[1720/1720] complete. valid_loss = 26.87643966674805
Epoch [40/500] Batch[200/1720] complete. train_loss = 11.713083372116088
Epoch [40/500] Batch[400/1720] complete. train_loss = 11.814175038337707
Epoch [40/500] Batch[600/1720] complete. train_loss = 11.899713678359985
Epoch [40/500] Batch[800/1720] complete. train_loss = 11.993346326351165
Epoch [40/500] Batch[1000/1720] complete. train_loss = 12.075242677688598
Epoch [40/500] Batch[1200/1720] complete. train_loss = 12.14105284055074
Epoch [40/500] Batch[1400/1720] complete. train_loss = 12.20320111819676
Epoch [40/500] Batch[1600/1720] complete. train_loss = 12.259222994446754
Epoch [40/500] Batch[1720/1720] complete. valid_loss = 27.101322174072266
Epoch [41/500] Batch[200/1720] complete. train_loss = 11.451099457740783
Epoch [41/500] Batch[400/1720] complete. train_loss = 11.540262658596038
Epoch [41/500] Batch[600/1720] complete. train_loss = 11.6132994445165
Epoch [41/500] Batch[800/1720] complete. train_loss = 11.697617818117141
Epoch [41/500] Batch[1000/1720] complete. train_loss = 11.755440992355346
Epoch [41/500] Batch[1200/1720] complete. train_loss = 11.820047394434612
Epoch [41/500] Batch[1400/1720] complete. train_loss = 11.89362486430577
Epoch [41/500] Batch[1600/1720] complete. train_loss = 11.945388582348823
Epoch [41/500] Batch[1720/1720] complete. valid_loss = 27.21448211669922
Epoch [42/500] Batch[200/1720] complete. train_loss = 11.161091723442077
Epoch [42/500] Batch[400/1720] complete. train_loss = 11.245572242736817
Epoch [42/500] Batch[600/1720] complete. train_loss = 11.314110641479493
Epoch [42/500] Batch[800/1720] complete. train_loss = 11.39609617471695
Epoch [42/500] Batch[1000/1720] complete. train_loss = 11.47156761932373
Epoch [42/500] Batch[1200/1720] complete. train_loss = 11.540197092692058
Epoch [42/500] Batch[1400/1720] complete. train_loss = 11.60652915273394
Epoch [42/500] Batch[1600/1720] complete. train_loss = 11.658418011665344
Epoch [42/500] Batch[1720/1720] complete. valid_loss = 27.54611473083496
Epoch [43/500] Batch[200/1720] complete. train_loss = 10.807621212005616
Epoch [43/500] Batch[400/1720] complete. train_loss = 10.956560270786285
Epoch [43/500] Batch[600/1720] complete. train_loss = 11.043393619855244
Epoch [43/500] Batch[800/1720] complete. train_loss = 11.11399713397026
Epoch [43/500] Batch[1000/1720] complete. train_loss = 11.178904842376708
Epoch [43/500] Batch[1200/1720] complete. train_loss = 11.249968540668487
Epoch [43/500] Batch[1400/1720] complete. train_loss = 11.314014195714678
Epoch [43/500] Batch[1600/1720] complete. train_loss = 11.375576016306876
Epoch [43/500] Batch[1720/1720] complete. valid_loss = 27.487100982666014
Epoch [44/500] Batch[200/1720] complete. train_loss = 10.539443359375
Epoch [44/500] Batch[400/1720] complete. train_loss = 10.651169192790984
Epoch [44/500] Batch[600/1720] complete. train_loss = 10.740660705566405
Epoch [44/500] Batch[800/1720] complete. train_loss = 10.825296736955643
Epoch [44/500] Batch[1000/1720] complete. train_loss = 10.908760381698608
Epoch [44/500] Batch[1200/1720] complete. train_loss = 10.974306624730428
Epoch [44/500] Batch[1400/1720] complete. train_loss = 11.036573209081377
Epoch [44/500] Batch[1600/1720] complete. train_loss = 11.096535766720772
Epoch [44/500] Batch[1720/1720] complete. valid_loss = 28.06631851196289
Epoch [45/500] Batch[200/1720] complete. train_loss = 10.28524067878723
Epoch [45/500] Batch[400/1720] complete. train_loss = 10.41429433107376
Epoch [45/500] Batch[600/1720] complete. train_loss = 10.499235394795736
Epoch [45/500] Batch[800/1720] complete. train_loss = 10.574387154579163
Epoch [45/500] Batch[1000/1720] complete. train_loss = 10.645906054496765
Epoch [45/500] Batch[1200/1720] complete. train_loss = 10.712389770348867
Epoch [45/500] Batch[1400/1720] complete. train_loss = 10.776125356129237
Epoch [45/500] Batch[1600/1720] complete. train_loss = 10.824864502549172
Epoch [45/500] Batch[1720/1720] complete. valid_loss = 28.107431411743164
Epoch [46/500] Batch[200/1720] complete. train_loss = 10.071073484420776
Epoch [46/500] Batch[400/1720] complete. train_loss = 10.133442573547363
Epoch [46/500] Batch[600/1720] complete. train_loss = 10.223834778467815
Epoch [46/500] Batch[800/1720] complete. train_loss = 10.287473924160004
Epoch [46/500] Batch[1000/1720] complete. train_loss = 10.375551476478577
Epoch [46/500] Batch[1200/1720] complete. train_loss = 10.445286486943562
Epoch [46/500] Batch[1400/1720] complete. train_loss = 10.509095166070122
Epoch [46/500] Batch[1600/1720] complete. train_loss = 10.565059519410134
Epoch [46/500] Batch[1720/1720] complete. valid_loss = 28.135070610046387
Epoch [47/500] Batch[200/1720] complete. train_loss = 9.79072268486023
Epoch [47/500] Batch[400/1720] complete. train_loss = 9.881174473762512
Epoch [47/500] Batch[600/1720] complete. train_loss = 9.957498356501262
Epoch [47/500] Batch[800/1720] complete. train_loss = 10.036663330793381
Epoch [47/500] Batch[1000/1720] complete. train_loss = 10.122573583602906
Epoch [47/500] Batch[1200/1720] complete. train_loss = 10.193948719501496
Epoch [47/500] Batch[1400/1720] complete. train_loss = 10.248625611577715
Epoch [47/500] Batch[1600/1720] complete. train_loss = 10.303561831712722
Epoch [47/500] Batch[1720/1720] complete. valid_loss = 28.554552841186524
Epoch [48/500] Batch[200/1720] complete. train_loss = 9.49564483642578
Epoch [48/500] Batch[400/1720] complete. train_loss = 9.63110591173172
Epoch [48/500] Batch[600/1720] complete. train_loss = 9.730201479593912
Epoch [48/500] Batch[800/1720] complete. train_loss = 9.799622294902802
Epoch [48/500] Batch[1000/1720] complete. train_loss = 9.879519560813904
Epoch [48/500] Batch[1200/1720] complete. train_loss = 9.939501870473226
Epoch [48/500] Batch[1400/1720] complete. train_loss = 9.997608063561575
Epoch [48/500] Batch[1600/1720] complete. train_loss = 10.05647327542305
Epoch [48/500] Batch[1720/1720] complete. valid_loss = 28.830010223388673
Epoch [49/500] Batch[200/1720] complete. train_loss = 9.25529106616974
Epoch [49/500] Batch[400/1720] complete. train_loss = 9.375898642539978
Epoch [49/500] Batch[600/1720] complete. train_loss = 9.470968108177185
Epoch [49/500] Batch[800/1720] complete. train_loss = 9.554482811689377
Epoch [49/500] Batch[1000/1720] complete. train_loss = 9.618604473114013
Epoch [49/500] Batch[1200/1720] complete. train_loss = 9.682262151241302
Epoch [49/500] Batch[1400/1720] complete. train_loss = 9.746362178666251
Epoch [49/500] Batch[1600/1720] complete. train_loss = 9.807743961215019
Epoch [49/500] Batch[1720/1720] complete. valid_loss = 28.685845565795898
Epoch [50/500] Batch[200/1720] complete. train_loss = 9.051999526023865
Epoch [50/500] Batch[400/1720] complete. train_loss = 9.146799657344818
Epoch [50/500] Batch[600/1720] complete. train_loss = 9.209324154853821
Epoch [50/500] Batch[800/1720] complete. train_loss = 9.296770589351654
Epoch [50/500] Batch[1000/1720] complete. train_loss = 9.366601048469544
Epoch [50/500] Batch[1200/1720] complete. train_loss = 9.440706196626028
Epoch [50/500] Batch[1400/1720] complete. train_loss = 9.50559110232762
Epoch [50/500] Batch[1600/1720] complete. train_loss = 9.565498093962669
Epoch [50/500] Batch[1720/1720] complete. valid_loss = 29.2797794342041
Epoch [51/500] Batch[200/1720] complete. train_loss = 8.815508444309234
Epoch [51/500] Batch[400/1720] complete. train_loss = 8.915178394317627
Epoch [51/500] Batch[600/1720] complete. train_loss = 9.008065208594005
Epoch [51/500] Batch[800/1720] complete. train_loss = 9.081830508112908
Epoch [51/500] Batch[1000/1720] complete. train_loss = 9.152531915187836
Epoch [51/500] Batch[1200/1720] complete. train_loss = 9.22003076672554
Epoch [51/500] Batch[1400/1720] complete. train_loss = 9.283189128807614
Epoch [51/500] Batch[1600/1720] complete. train_loss = 9.34384489685297
Epoch [51/500] Batch[1720/1720] complete. valid_loss = 29.490272521972656
Epoch [52/500] Batch[200/1720] complete. train_loss = 8.55654011964798
Epoch [52/500] Batch[400/1720] complete. train_loss = 8.691451678276062
Epoch [52/500] Batch[600/1720] complete. train_loss = 8.772024075984955
Epoch [52/500] Batch[800/1720] complete. train_loss = 8.853560456633568
Epoch [52/500] Batch[1000/1720] complete. train_loss = 8.921833021163941
Epoch [52/500] Batch[1200/1720] complete. train_loss = 8.98721799135208
Epoch [52/500] Batch[1400/1720] complete. train_loss = 9.04698121888297
Epoch [52/500] Batch[1600/1720] complete. train_loss = 9.111940469145775
Epoch [52/500] Batch[1720/1720] complete. valid_loss = 29.631117248535155
Epoch [53/500] Batch[200/1720] complete. train_loss = 8.315096700191498
Epoch [53/500] Batch[400/1720] complete. train_loss = 8.43189644932747
Epoch [53/500] Batch[600/1720] complete. train_loss = 8.517801038424174
Epoch [53/500] Batch[800/1720] complete. train_loss = 8.6102235943079
Epoch [53/500] Batch[1000/1720] complete. train_loss = 8.684242991924286
Epoch [53/500] Batch[1200/1720] complete. train_loss = 8.752904214461644
Epoch [53/500] Batch[1400/1720] complete. train_loss = 8.819791775090353
Epoch [53/500] Batch[1600/1720] complete. train_loss = 8.887909932434559
Epoch [53/500] Batch[1720/1720] complete. valid_loss = 29.974649047851564
Epoch [54/500] Batch[200/1720] complete. train_loss = 8.081733937263488
Epoch [54/500] Batch[400/1720] complete. train_loss = 8.205439714193345
Epoch [54/500] Batch[600/1720] complete. train_loss = 8.296599893569946
Epoch [54/500] Batch[800/1720] complete. train_loss = 8.386589778661728
Epoch [54/500] Batch[1000/1720] complete. train_loss = 8.463441409111024
Epoch [54/500] Batch[1200/1720] complete. train_loss = 8.547673784891764
Epoch [54/500] Batch[1400/1720] complete. train_loss = 8.60587166922433
Epoch [54/500] Batch[1600/1720] complete. train_loss = 8.671900541186332
Epoch [54/500] Batch[1720/1720] complete. valid_loss = 30.05962257385254
Epoch [55/500] Batch[200/1720] complete. train_loss = 7.929212267398834
Epoch [55/500] Batch[400/1720] complete. train_loss = 8.037250380516053
Epoch [55/500] Batch[600/1720] complete. train_loss = 8.111188026269277
Epoch [55/500] Batch[800/1720] complete. train_loss = 8.193139621019363
Epoch [55/500] Batch[1000/1720] complete. train_loss = 8.267382319927215
Epoch [55/500] Batch[1200/1720] complete. train_loss = 8.329585880041122
Epoch [55/500] Batch[1400/1720] complete. train_loss = 8.402384007317679
Epoch [55/500] Batch[1600/1720] complete. train_loss = 8.466381603479386
Epoch [55/500] Batch[1720/1720] complete. valid_loss = 30.57976837158203
Epoch [56/500] Batch[200/1720] complete. train_loss = 7.699320216178894
Epoch [56/500] Batch[400/1720] complete. train_loss = 7.8116789102554325
Epoch [56/500] Batch[600/1720] complete. train_loss = 7.897525159517924
Epoch [56/500] Batch[800/1720] complete. train_loss = 7.992588603496552
Epoch [56/500] Batch[1000/1720] complete. train_loss = 8.062271605014802
Epoch [56/500] Batch[1200/1720] complete. train_loss = 8.13202410419782
Epoch [56/500] Batch[1400/1720] complete. train_loss = 8.198312139511108
Epoch [56/500] Batch[1600/1720] complete. train_loss = 8.267411065995693
Epoch [56/500] Batch[1720/1720] complete. valid_loss = 30.501188659667967
Epoch [57/500] Batch[200/1720] complete. train_loss = 7.570143122673034
Epoch [57/500] Batch[400/1720] complete. train_loss = 7.657386672496796
Epoch [57/500] Batch[600/1720] complete. train_loss = 7.738433628877004
Epoch [57/500] Batch[800/1720] complete. train_loss = 7.8080919462442395
Epoch [57/500] Batch[1000/1720] complete. train_loss = 7.87633762216568
Epoch [57/500] Batch[1200/1720] complete. train_loss = 7.936844989856084
Epoch [57/500] Batch[1400/1720] complete. train_loss = 8.003812143802643
Epoch [57/500] Batch[1600/1720] complete. train_loss = 8.0632580524683
Epoch [57/500] Batch[1720/1720] complete. valid_loss = 30.7675350189209
Epoch [58/500] Batch[200/1720] complete. train_loss = 7.3409100532531735
Epoch [58/500] Batch[400/1720] complete. train_loss = 7.4412701642513275
Epoch [58/500] Batch[600/1720] complete. train_loss = 7.544564999739329
Epoch [58/500] Batch[800/1720] complete. train_loss = 7.61787122130394
Epoch [58/500] Batch[1000/1720] complete. train_loss = 7.690506077766418
Epoch [58/500] Batch[1200/1720] complete. train_loss = 7.7521109819412235
Epoch [58/500] Batch[1400/1720] complete. train_loss = 7.814670193195343
Epoch [58/500] Batch[1600/1720] complete. train_loss = 7.872497402727604
Epoch [58/500] Batch[1720/1720] complete. valid_loss = 30.977833557128907
Epoch [59/500] Batch[200/1720] complete. train_loss = 7.204730892181397
Epoch [59/500] Batch[400/1720] complete. train_loss = 7.26139160990715
Epoch [59/500] Batch[600/1720] complete. train_loss = 7.337979058424632
Epoch [59/500] Batch[800/1720] complete. train_loss = 7.421345856785774
Epoch [59/500] Batch[1000/1720] complete. train_loss = 7.490849724292755
Epoch [59/500] Batch[1200/1720] complete. train_loss = 7.560667152404785
Epoch [59/500] Batch[1400/1720] complete. train_loss = 7.61814428125109
Epoch [59/500] Batch[1600/1720] complete. train_loss = 7.682971164882183
Epoch [59/500] Batch[1720/1720] complete. valid_loss = 31.15782012939453
Epoch [60/500] Batch[200/1720] complete. train_loss = 7.019343602657318
Epoch [60/500] Batch[400/1720] complete. train_loss = 7.11267246723175
Epoch [60/500] Batch[600/1720] complete. train_loss = 7.190613320668539
Epoch [60/500] Batch[800/1720] complete. train_loss = 7.256548948287964
Epoch [60/500] Batch[1000/1720] complete. train_loss = 7.31689890575409
Epoch [60/500] Batch[1200/1720] complete. train_loss = 7.387756632963816
Epoch [60/500] Batch[1400/1720] complete. train_loss = 7.44777252129146
Epoch [60/500] Batch[1600/1720] complete. train_loss = 7.501403128802776
Epoch [60/500] Batch[1720/1720] complete. valid_loss = 31.4245849609375
Epoch [61/500] Batch[200/1720] complete. train_loss = 6.813692033290863
Epoch [61/500] Batch[400/1720] complete. train_loss = 6.916869251728058
Epoch [61/500] Batch[600/1720] complete. train_loss = 6.994390981197357
Epoch [61/500] Batch[800/1720] complete. train_loss = 7.062141700387001
Epoch [61/500] Batch[1000/1720] complete. train_loss = 7.134705723762512
Epoch [61/500] Batch[1200/1720] complete. train_loss = 7.204208233356476
Epoch [61/500] Batch[1400/1720] complete. train_loss = 7.273906452655792
Epoch [61/500] Batch[1600/1720] complete. train_loss = 7.327848827540874
Epoch [61/500] Batch[1720/1720] complete. valid_loss = 31.837047576904297
Epoch [62/500] Batch[200/1720] complete. train_loss = 6.640369911193847
Epoch [62/500] Batch[400/1720] complete. train_loss = 6.745981886386871
Epoch [62/500] Batch[600/1720] complete. train_loss = 6.837343596617381
Epoch [62/500] Batch[800/1720] complete. train_loss = 6.9174209666252136
Epoch [62/500] Batch[1000/1720] complete. train_loss = 6.982519454956055
Epoch [62/500] Batch[1200/1720] complete. train_loss = 7.0397955779234564
Epoch [62/500] Batch[1400/1720] complete. train_loss = 7.102167016778673
Epoch [62/500] Batch[1600/1720] complete. train_loss = 7.156616399288177
Epoch [62/500] Batch[1720/1720] complete. valid_loss = 31.77347297668457
Epoch [63/500] Batch[200/1720] complete. train_loss = 6.523844895362854
Epoch [63/500] Batch[400/1720] complete. train_loss = 6.597369943857193
Epoch [63/500] Batch[600/1720] complete. train_loss = 6.681568756898244
Epoch [63/500] Batch[800/1720] complete. train_loss = 6.74055632352829
Epoch [63/500] Batch[1000/1720] complete. train_loss = 6.813710799694062
Epoch [63/500] Batch[1200/1720] complete. train_loss = 6.879077195723852
Epoch [63/500] Batch[1400/1720] complete. train_loss = 6.93509053673063
Epoch [63/500] Batch[1600/1720] complete. train_loss = 6.989011832773685
Epoch [63/500] Batch[1720/1720] complete. valid_loss = 31.953157424926758
Epoch [64/500] Batch[200/1720] complete. train_loss = 6.293257350921631
Epoch [64/500] Batch[400/1720] complete. train_loss = 6.409210879802703
Epoch [64/500] Batch[600/1720] complete. train_loss = 6.493976584275564
Epoch [64/500] Batch[800/1720] complete. train_loss = 6.573422244191169
Epoch [64/500] Batch[1000/1720] complete. train_loss = 6.653630005359649
Epoch [64/500] Batch[1200/1720] complete. train_loss = 6.711009951829911
Epoch [64/500] Batch[1400/1720] complete. train_loss = 6.773455989701407
Epoch [64/500] Batch[1600/1720] complete. train_loss = 6.831975867748261
Epoch [64/500] Batch[1720/1720] complete. valid_loss = 32.05909957885742
Epoch [65/500] Batch[200/1720] complete. train_loss = 6.192589917182922
Epoch [65/500] Batch[400/1720] complete. train_loss = 6.301920156478882
Epoch [65/500] Batch[600/1720] complete. train_loss = 6.372038942972819
Epoch [65/500] Batch[800/1720] complete. train_loss = 6.439905704259872
Epoch [65/500] Batch[1000/1720] complete. train_loss = 6.507810287952423
Epoch [65/500] Batch[1200/1720] complete. train_loss = 6.565216043790182
Epoch [65/500] Batch[1400/1720] complete. train_loss = 6.627367195401873
Epoch [65/500] Batch[1600/1720] complete. train_loss = 6.680960100889206
Epoch [65/500] Batch[1720/1720] complete. valid_loss = 32.25186271667481
Epoch [66/500] Batch[200/1720] complete. train_loss = 6.076691296100616
Epoch [66/500] Batch[400/1720] complete. train_loss = 6.15497857093811
Epoch [66/500] Batch[600/1720] complete. train_loss = 6.242099250157674
Epoch [66/500] Batch[800/1720] complete. train_loss = 6.311282991170883
Epoch [66/500] Batch[1000/1720] complete. train_loss = 6.37124226474762
Epoch [66/500] Batch[1200/1720] complete. train_loss = 6.4265157787005105
Epoch [66/500] Batch[1400/1720] complete. train_loss = 6.485281630243574
Epoch [66/500] Batch[1600/1720] complete. train_loss = 6.5394087147712705
Epoch [66/500] Batch[1720/1720] complete. valid_loss = 32.8348991394043
Epoch [67/500] Batch[200/1720] complete. train_loss = 5.8943622159957885
Epoch [67/500] Batch[400/1720] complete. train_loss = 5.986163656711579
Epoch [67/500] Batch[600/1720] complete. train_loss = 6.074700033664703
Epoch [67/500] Batch[800/1720] complete. train_loss = 6.15524722635746
Epoch [67/500] Batch[1000/1720] complete. train_loss = 6.214507650375366
Epoch [67/500] Batch[1200/1720] complete. train_loss = 6.272984802325567
Epoch [67/500] Batch[1400/1720] complete. train_loss = 6.32705742427281
Epoch [67/500] Batch[1600/1720] complete. train_loss = 6.380335138440132
Epoch [67/500] Batch[1720/1720] complete. valid_loss = 33.0060173034668
Epoch [68/500] Batch[200/1720] complete. train_loss = 5.770630068778992
Epoch [68/500] Batch[400/1720] complete. train_loss = 5.827441589832306
Epoch [68/500] Batch[600/1720] complete. train_loss = 5.912700916131337
Epoch [68/500] Batch[800/1720] complete. train_loss = 5.994889555573463
Epoch [68/500] Batch[1000/1720] complete. train_loss = 6.068680057048797
Epoch [68/500] Batch[1200/1720] complete. train_loss = 6.134527747631073
Epoch [68/500] Batch[1400/1720] complete. train_loss = 6.191998877184732
Epoch [68/500] Batch[1600/1720] complete. train_loss = 6.243688941001892
Epoch [68/500] Batch[1720/1720] complete. valid_loss = 33.1350772857666
Epoch [69/500] Batch[200/1720] complete. train_loss = 5.630879375934601
Epoch [69/500] Batch[400/1720] complete. train_loss = 5.719305145740509
Epoch [69/500] Batch[600/1720] complete. train_loss = 5.8122798768679305
Epoch [69/500] Batch[800/1720] complete. train_loss = 5.877831060886383
Epoch [69/500] Batch[1000/1720] complete. train_loss = 5.942685966968536
Epoch [69/500] Batch[1200/1720] complete. train_loss = 5.999498283068339
Epoch [69/500] Batch[1400/1720] complete. train_loss = 6.054068053109305
Epoch [69/500] Batch[1600/1720] complete. train_loss = 6.109277156889439
Epoch [69/500] Batch[1720/1720] complete. valid_loss = 33.15765647888183
Epoch [70/500] Batch[200/1720] complete. train_loss = 5.508409554958344
Epoch [70/500] Batch[400/1720] complete. train_loss = 5.60822420835495
Epoch [70/500] Batch[600/1720] complete. train_loss = 5.6835783576965335
Epoch [70/500] Batch[800/1720] complete. train_loss = 5.7451505869626995
Epoch [70/500] Batch[1000/1720] complete. train_loss = 5.808329227924347
Epoch [70/500] Batch[1200/1720] complete. train_loss = 5.868332594633102
Epoch [70/500] Batch[1400/1720] complete. train_loss = 5.923380657264165
Epoch [70/500] Batch[1600/1720] complete. train_loss = 5.976027997434139
Epoch [70/500] Batch[1720/1720] complete. valid_loss = 33.6554458618164
Epoch [71/500] Batch[200/1720] complete. train_loss = 5.35388429403305
Epoch [71/500] Batch[400/1720] complete. train_loss = 5.459365713596344
Epoch [71/500] Batch[600/1720] complete. train_loss = 5.543942794005076
Epoch [71/500] Batch[800/1720] complete. train_loss = 5.609857555627823
Epoch [71/500] Batch[1000/1720] complete. train_loss = 5.679668876647949
Epoch [71/500] Batch[1200/1720] complete. train_loss = 5.735216494401296
Epoch [71/500] Batch[1400/1720] complete. train_loss = 5.794388966219766
Epoch [71/500] Batch[1600/1720] complete. train_loss = 5.8515541952848436
Epoch [71/500] Batch[1720/1720] complete. valid_loss = 33.75278244018555
Epoch [72/500] Batch[200/1720] complete. train_loss = 5.256958608627319
Epoch [72/500] Batch[400/1720] complete. train_loss = 5.35446072936058
Epoch [72/500] Batch[600/1720] complete. train_loss = 5.435220007896423
Epoch [72/500] Batch[800/1720] complete. train_loss = 5.5000912010669705
Epoch [72/500] Batch[1000/1720] complete. train_loss = 5.557121898651123
Epoch [72/500] Batch[1200/1720] complete. train_loss = 5.613258743683497
Epoch [72/500] Batch[1400/1720] complete. train_loss = 5.670151865141732
Epoch [72/500] Batch[1600/1720] complete. train_loss = 5.722336806058884
Epoch [72/500] Batch[1720/1720] complete. valid_loss = 33.91781883239746
Epoch [73/500] Batch[200/1720] complete. train_loss = 5.167894918918609
Epoch [73/500] Batch[400/1720] complete. train_loss = 5.250512523651123
Epoch [73/500] Batch[600/1720] complete. train_loss = 5.310713886419932
Epoch [73/500] Batch[800/1720] complete. train_loss = 5.370195935368538
Epoch [73/500] Batch[1000/1720] complete. train_loss = 5.436593528747559
Epoch [73/500] Batch[1200/1720] complete. train_loss = 5.495895956754684
Epoch [73/500] Batch[1400/1720] complete. train_loss = 5.54776458127158
Epoch [73/500] Batch[1600/1720] complete. train_loss = 5.6025487187504766
Epoch [73/500] Batch[1720/1720] complete. valid_loss = 33.9966625213623
Epoch [74/500] Batch[200/1720] complete. train_loss = 5.041593971252442
Epoch [74/500] Batch[400/1720] complete. train_loss = 5.107826716899872
Epoch [74/500] Batch[600/1720] complete. train_loss = 5.190273102919261
Epoch [74/500] Batch[800/1720] complete. train_loss = 5.270470221638679
Epoch [74/500] Batch[1000/1720] complete. train_loss = 5.336778552532196
Epoch [74/500] Batch[1200/1720] complete. train_loss = 5.393946184714635
Epoch [74/500] Batch[1400/1720] complete. train_loss = 5.440981049537658
Epoch [74/500] Batch[1600/1720] complete. train_loss = 5.487724004983902
Epoch [74/500] Batch[1720/1720] complete. valid_loss = 34.39052963256836
Epoch [75/500] Batch[200/1720] complete. train_loss = 4.912559087276459
Epoch [75/500] Batch[400/1720] complete. train_loss = 4.996691969633102
Epoch [75/500] Batch[600/1720] complete. train_loss = 5.067140041987101
Epoch [75/500] Batch[800/1720] complete. train_loss = 5.1311409050226215
Epoch [75/500] Batch[1000/1720] complete. train_loss = 5.203992956638336
Epoch [75/500] Batch[1200/1720] complete. train_loss = 5.2640139412879945
Epoch [75/500] Batch[1400/1720] complete. train_loss = 5.3191564144407
Epoch [75/500] Batch[1600/1720] complete. train_loss = 5.372790107131005
Epoch [75/500] Batch[1720/1720] complete. valid_loss = 34.57742004394531
Epoch [76/500] Batch[200/1720] complete. train_loss = 4.847676389217376
Epoch [76/500] Batch[400/1720] complete. train_loss = 4.915229979753494
Epoch [76/500] Batch[600/1720] complete. train_loss = 5.00107541402181
Epoch [76/500] Batch[800/1720] complete. train_loss = 5.067509611845017
Epoch [76/500] Batch[1000/1720] complete. train_loss = 5.117152398586273
Epoch [76/500] Batch[1200/1720] complete. train_loss = 5.1709367044766745
Epoch [76/500] Batch[1400/1720] complete. train_loss = 5.224051661150796
Epoch [76/500] Batch[1600/1720] complete. train_loss = 5.273974557518959
Epoch [76/500] Batch[1720/1720] complete. valid_loss = 34.55208511352539
Epoch [77/500] Batch[200/1720] complete. train_loss = 4.7414256596565245
Epoch [77/500] Batch[400/1720] complete. train_loss = 4.819284455776215
Epoch [77/500] Batch[600/1720] complete. train_loss = 4.885143240292867
Epoch [77/500] Batch[800/1720] complete. train_loss = 4.944625597596168
Epoch [77/500] Batch[1000/1720] complete. train_loss = 5.002805653572082
Epoch [77/500] Batch[1200/1720] complete. train_loss = 5.0548963872591655
Epoch [77/500] Batch[1400/1720] complete. train_loss = 5.111836877550398
Epoch [77/500] Batch[1600/1720] complete. train_loss = 5.160777924656868
Epoch [77/500] Batch[1720/1720] complete. valid_loss = 34.83518524169922
Epoch [78/500] Batch[200/1720] complete. train_loss = 4.614824559688568
Epoch [78/500] Batch[400/1720] complete. train_loss = 4.717768902778626
Epoch [78/500] Batch[600/1720] complete. train_loss = 4.799310153325399
Epoch [78/500] Batch[800/1720] complete. train_loss = 4.852437235116959
Epoch [78/500] Batch[1000/1720] complete. train_loss = 4.905330392360687
Epoch [78/500] Batch[1200/1720] complete. train_loss = 4.959801187912623
Epoch [78/500] Batch[1400/1720] complete. train_loss = 5.008390976020268
Epoch [78/500] Batch[1600/1720] complete. train_loss = 5.059178072214126
Epoch [78/500] Batch[1720/1720] complete. valid_loss = 35.090385055541994
Epoch [79/500] Batch[200/1720] complete. train_loss = 4.539277030229568
Epoch [79/500] Batch[400/1720] complete. train_loss = 4.620335571765899
Epoch [79/500] Batch[600/1720] complete. train_loss = 4.691815671126048
Epoch [79/500] Batch[800/1720] complete. train_loss = 4.757081240415573
Epoch [79/500] Batch[1000/1720] complete. train_loss = 4.81084953546524
Epoch [79/500] Batch[1200/1720] complete. train_loss = 4.860069724321366
Epoch [79/500] Batch[1400/1720] complete. train_loss = 4.915339872496468
Epoch [79/500] Batch[1600/1720] complete. train_loss = 4.9678615254163745
Epoch [79/500] Batch[1720/1720] complete. valid_loss = 35.39113998413086
Epoch [80/500] Batch[200/1720] complete. train_loss = 4.481407614946366
Epoch [80/500] Batch[400/1720] complete. train_loss = 4.5417057740688325
Epoch [80/500] Batch[600/1720] complete. train_loss = 4.599464418888092
Epoch [80/500] Batch[800/1720] complete. train_loss = 4.663443244099617
Epoch [80/500] Batch[1000/1720] complete. train_loss = 4.720172623157501
Epoch [80/500] Batch[1200/1720] complete. train_loss = 4.773551122347514
Epoch [80/500] Batch[1400/1720] complete. train_loss = 4.81996415070125
Epoch [80/500] Batch[1600/1720] complete. train_loss = 4.871694461405277
Epoch [80/500] Batch[1720/1720] complete. valid_loss = 35.4278003692627
Epoch [81/500] Batch[200/1720] complete. train_loss = 4.394319212436676
Epoch [81/500] Batch[400/1720] complete. train_loss = 4.4605245703458785
Epoch [81/500] Batch[600/1720] complete. train_loss = 4.524236563046773
Epoch [81/500] Batch[800/1720] complete. train_loss = 4.580717734694481
Epoch [81/500] Batch[1000/1720] complete. train_loss = 4.637992322444916
Epoch [81/500] Batch[1200/1720] complete. train_loss = 4.687846709092458
Epoch [81/500] Batch[1400/1720] complete. train_loss = 4.73570696081434
Epoch [81/500] Batch[1600/1720] complete. train_loss = 4.780773060321808
Epoch [81/500] Batch[1720/1720] complete. valid_loss = 35.56448822021484
Epoch [82/500] Batch[200/1720] complete. train_loss = 4.300525557994843
Epoch [82/500] Batch[400/1720] complete. train_loss = 4.395726254582405
Epoch [82/500] Batch[600/1720] complete. train_loss = 4.447241221268972
Epoch [82/500] Batch[800/1720] complete. train_loss = 4.500224869251252
Epoch [82/500] Batch[1000/1720] complete. train_loss = 4.551911983013153
Epoch [82/500] Batch[1200/1720] complete. train_loss = 4.594813015858333
Epoch [82/500] Batch[1400/1720] complete. train_loss = 4.646448025362832
Epoch [82/500] Batch[1600/1720] complete. train_loss = 4.6967246502637865
Epoch [82/500] Batch[1720/1720] complete. valid_loss = 35.76995697021484
Epoch [83/500] Batch[200/1720] complete. train_loss = 4.223898532390595
Epoch [83/500] Batch[400/1720] complete. train_loss = 4.290481812953949
Epoch [83/500] Batch[600/1720] complete. train_loss = 4.34283938407898
Epoch [83/500] Batch[800/1720] complete. train_loss = 4.402339732050896
Epoch [83/500] Batch[1000/1720] complete. train_loss = 4.457211494922638
Epoch [83/500] Batch[1200/1720] complete. train_loss = 4.513562111457189
Epoch [83/500] Batch[1400/1720] complete. train_loss = 4.560492901802063
Epoch [83/500] Batch[1600/1720] complete. train_loss = 4.608537630140781
Epoch [83/500] Batch[1720/1720] complete. valid_loss = 35.6972354888916
Epoch [84/500] Batch[200/1720] complete. train_loss = 4.125700240135193
Epoch [84/500] Batch[400/1720] complete. train_loss = 4.201599420905113
Epoch [84/500] Batch[600/1720] complete. train_loss = 4.269236606756846
Epoch [84/500] Batch[800/1720] complete. train_loss = 4.325981956720352
Epoch [84/500] Batch[1000/1720] complete. train_loss = 4.381979813575745
Epoch [84/500] Batch[1200/1720] complete. train_loss = 4.4261110883951185
Epoch [84/500] Batch[1400/1720] complete. train_loss = 4.470972872972489
Epoch [84/500] Batch[1600/1720] complete. train_loss = 4.518695724159479
Epoch [84/500] Batch[1720/1720] complete. valid_loss = 36.063227844238284
Epoch [85/500] Batch[200/1720] complete. train_loss = 4.057384314537049
Epoch [85/500] Batch[400/1720] complete. train_loss = 4.1460769957304
Epoch [85/500] Batch[600/1720] complete. train_loss = 4.201310442288716
Epoch [85/500] Batch[800/1720] complete. train_loss = 4.26289535164833
Epoch [85/500] Batch[1000/1720] complete. train_loss = 4.312676807403564
Epoch [85/500] Batch[1200/1720] complete. train_loss = 4.361162950197856
Epoch [85/500] Batch[1400/1720] complete. train_loss = 4.404485943317414
Epoch [85/500] Batch[1600/1720] complete. train_loss = 4.451487421989441
Epoch [85/500] Batch[1720/1720] complete. valid_loss = 36.16760597229004
Epoch [86/500] Batch[200/1720] complete. train_loss = 3.9772926425933837
Epoch [86/500] Batch[400/1720] complete. train_loss = 4.036267439723015
Epoch [86/500] Batch[600/1720] complete. train_loss = 4.101963754494985
Epoch [86/500] Batch[800/1720] complete. train_loss = 4.162414923608303
Epoch [86/500] Batch[1000/1720] complete. train_loss = 4.219115237236023
Epoch [86/500] Batch[1200/1720] complete. train_loss = 4.272544516722362
Epoch [86/500] Batch[1400/1720] complete. train_loss = 4.32177722964968
Epoch [86/500] Batch[1600/1720] complete. train_loss = 4.370097939968109
Epoch [86/500] Batch[1720/1720] complete. valid_loss = 35.983673095703125
Epoch [87/500] Batch[200/1720] complete. train_loss = 3.9162032532691957
Epoch [87/500] Batch[400/1720] complete. train_loss = 3.988612414598465
Epoch [87/500] Batch[600/1720] complete. train_loss = 4.038469185829163
Epoch [87/500] Batch[800/1720] complete. train_loss = 4.0984279185533525
Epoch [87/500] Batch[1000/1720] complete. train_loss = 4.15531248140335
Epoch [87/500] Batch[1200/1720] complete. train_loss = 4.205288301110268
Epoch [87/500] Batch[1400/1720] complete. train_loss = 4.252232382127217
Epoch [87/500] Batch[1600/1720] complete. train_loss = 4.297187742143869
Epoch [87/500] Batch[1720/1720] complete. valid_loss = 36.41389961242676
Epoch [88/500] Batch[200/1720] complete. train_loss = 3.867997461557388
Epoch [88/500] Batch[400/1720] complete. train_loss = 3.924585052728653
Epoch [88/500] Batch[600/1720] complete. train_loss = 3.9903943157196045
Epoch [88/500] Batch[800/1720] complete. train_loss = 4.042338182926178
Epoch [88/500] Batch[1000/1720] complete. train_loss = 4.089407270908356
Epoch [88/500] Batch[1200/1720] complete. train_loss = 4.139730939070383
Epoch [88/500] Batch[1400/1720] complete. train_loss = 4.191273930243083
Epoch [88/500] Batch[1600/1720] complete. train_loss = 4.232456199228763
Epoch [88/500] Batch[1720/1720] complete. valid_loss = 36.54594688415527
Epoch [89/500] Batch[200/1720] complete. train_loss = 3.8042071640491484
Epoch [89/500] Batch[400/1720] complete. train_loss = 3.875245885848999
Epoch [89/500] Batch[600/1720] complete. train_loss = 3.920481770435969
Epoch [89/500] Batch[800/1720] complete. train_loss = 3.976990418732166
Epoch [89/500] Batch[1000/1720] complete. train_loss = 4.026875823497773
Epoch [89/500] Batch[1200/1720] complete. train_loss = 4.072639157970746
Epoch [89/500] Batch[1400/1720] complete. train_loss = 4.118551398856299
Epoch [89/500] Batch[1600/1720] complete. train_loss = 4.159726363420487
Epoch [89/500] Batch[1720/1720] complete. valid_loss = 36.91437301635742
Epoch [90/500] Batch[200/1720] complete. train_loss = 3.7227490723133085
Epoch [90/500] Batch[400/1720] complete. train_loss = 3.8013287514448164
Epoch [90/500] Batch[600/1720] complete. train_loss = 3.8613562949498497
Epoch [90/500] Batch[800/1720] complete. train_loss = 3.906844763457775
Epoch [90/500] Batch[1000/1720] complete. train_loss = 3.9558806793689727
Epoch [90/500] Batch[1200/1720] complete. train_loss = 4.009857246081034
Epoch [90/500] Batch[1400/1720] complete. train_loss = 4.056016862903323
Epoch [90/500] Batch[1600/1720] complete. train_loss = 4.097087582796812
Epoch [90/500] Batch[1720/1720] complete. valid_loss = 37.13030853271484
Epoch [91/500] Batch[200/1720] complete. train_loss = 3.711896824836731
